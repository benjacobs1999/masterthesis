{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.autograd.profiler as profiler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import osqp\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "import time\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "class SimpleProblem(ABC):\n",
    "    \"\"\"\n",
    "    minimize_y 1/2 * y^T Q y + p^Ty\n",
    "    s.t.       Ay =  b\n",
    "               Gy <= d\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, Q, p, A, G, b, d, valid_frac=0.0833, test_frac=0.0833):\n",
    "        self._Q = torch.tensor(Q)\n",
    "        self._p = torch.tensor(p)\n",
    "        self._A = torch.tensor(A)\n",
    "        self._G = torch.tensor(G)\n",
    "        self._b = torch.tensor(b) # equality RHS\n",
    "        self._d = torch.tensor(d) # inequality RHS\n",
    "\n",
    "        self._eq_cm = self._A\n",
    "        self._ineq_cm = self._G\n",
    "        self._eq_rhs = self._b\n",
    "        self._ineq_rhs = self._d\n",
    "\n",
    "        self._valid_frac = valid_frac\n",
    "        self._test_frac = test_frac\n",
    "\n",
    "        self._Y = None\n",
    "        self._ydim = Q.shape[0]\n",
    "\n",
    "        ### For Pytorch\n",
    "        self._device = None\n",
    "\n",
    "        #! Implement in child!\n",
    "        self._X = None\n",
    "        self._num = None\n",
    "        self._neq = None\n",
    "        self._nineq = None\n",
    "        self._xdim = None\n",
    "\n",
    "\n",
    "    ##### ABSTRACT METHODS #####\n",
    "\n",
    "    @abstractmethod\n",
    "    def eq_resid(self, X, Y):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def ineq_resid(self, X, Y):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def opt_solve(self, X, solver_type=\"osqp\", tol=1e-4):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def calc_Y(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"SimpleProblem-{}-{}-{}-{}\".format(\n",
    "            str(self.ydim), str(self.nineq), str(self.neq), str(self.num)\n",
    "        )\n",
    "    \n",
    "    ##### REG METHODS #####\n",
    "\n",
    "    @property\n",
    "    def eq_cm(self):\n",
    "        return self._eq_cm\n",
    "\n",
    "    @property\n",
    "    def ineq_cm(self):\n",
    "        return self._ineq_cm\n",
    "    \n",
    "    @property\n",
    "    def eq_rhs(self):\n",
    "        return self._eq_rhs\n",
    "    \n",
    "    @property\n",
    "    def ineq_rhs(self):\n",
    "        return self._ineq_rhs\n",
    "\n",
    "    @property\n",
    "    def Q(self):\n",
    "        return self._Q\n",
    "\n",
    "    @property\n",
    "    def p(self):\n",
    "        return self._p\n",
    "\n",
    "    @property\n",
    "    def A(self):\n",
    "        return self._A\n",
    "\n",
    "    @property\n",
    "    def G(self):\n",
    "        return self._G\n",
    "\n",
    "    @property\n",
    "    def b(self):\n",
    "        return self._b\n",
    "\n",
    "    @property\n",
    "    def d(self):\n",
    "        return self._d\n",
    "\n",
    "    @property\n",
    "    def X(self):\n",
    "        return self._X\n",
    "\n",
    "    @property\n",
    "    def Y(self):\n",
    "        return self._Y\n",
    "\n",
    "    @property\n",
    "    def partial_vars(self):\n",
    "        return self._partial_vars\n",
    "\n",
    "    @property\n",
    "    def other_vars(self):\n",
    "        return self._other_vars\n",
    "\n",
    "    @property\n",
    "    def partial_unknown_vars(self):\n",
    "        return self._partial_vars\n",
    "\n",
    "    @property\n",
    "    def Q_np(self):\n",
    "        return self.Q.detach().cpu().numpy()\n",
    "\n",
    "    @property\n",
    "    def p_np(self):\n",
    "        return self.p.detach().cpu().numpy()\n",
    "\n",
    "    @property\n",
    "    def A_np(self):\n",
    "        return self.A.detach().cpu().numpy()\n",
    "\n",
    "    @property\n",
    "    def G_np(self):\n",
    "        return self.G.detach().cpu().numpy()\n",
    "\n",
    "    @property\n",
    "    def b_np(self):\n",
    "        return self.b.detach().cpu().numpy()\n",
    "\n",
    "    @property\n",
    "    def d_np(self):\n",
    "        return self.d.detach().cpu().numpy()\n",
    "\n",
    "    @property\n",
    "    def X_np(self):\n",
    "        return self.X.detach().cpu().numpy()\n",
    "\n",
    "    @property\n",
    "    def Y_np(self):\n",
    "        return self.Y.detach().cpu().numpy()\n",
    "\n",
    "    @property\n",
    "    def xdim(self):\n",
    "        return self._xdim\n",
    "\n",
    "    @property\n",
    "    def ydim(self):\n",
    "        return self._ydim\n",
    "\n",
    "    @property\n",
    "    def num(self):\n",
    "        return self._num\n",
    "\n",
    "    @property\n",
    "    def neq(self):\n",
    "        return self._neq\n",
    "\n",
    "    @property\n",
    "    def nineq(self):\n",
    "        return self._nineq\n",
    "\n",
    "    @property\n",
    "    def nknowns(self):\n",
    "        return self._nknowns\n",
    "\n",
    "    @property\n",
    "    def valid_frac(self):\n",
    "        return self._valid_frac\n",
    "\n",
    "    @property\n",
    "    def test_frac(self):\n",
    "        return self._test_frac\n",
    "\n",
    "    @property\n",
    "    def train_frac(self):\n",
    "        return 1 - self.valid_frac - self.test_frac\n",
    "    \n",
    "    @property\n",
    "    def train_indices(self):\n",
    "        return list(range(int(self.num * self.train_frac)))\n",
    "    \n",
    "    @property\n",
    "    def valid_indices(self):\n",
    "        return list(range(int(self.num * self.train_frac), int(self.num * (self.train_frac + self.valid_frac))))\n",
    "    \n",
    "    @property\n",
    "    def test_indices(self):\n",
    "        return list(range(int(self.num * (self.train_frac + self.valid_frac)), self.num))\n",
    "\n",
    "    @property\n",
    "    def trainX(self):\n",
    "        return self.X[: int(self.num * self.train_frac)]\n",
    "\n",
    "    @property\n",
    "    def validX(self):\n",
    "        return self.X[\n",
    "            int(self.num * self.train_frac) : int(\n",
    "                self.num * (self.train_frac + self.valid_frac)\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def testX(self):\n",
    "        return self.X[int(self.num * (self.train_frac + self.valid_frac)) :]\n",
    "\n",
    "    @property\n",
    "    def trainY(self):\n",
    "        return self.Y[: int(self.num * self.train_frac)]\n",
    "\n",
    "    @property\n",
    "    def validY(self):\n",
    "        return self.Y[\n",
    "            int(self.num * self.train_frac) : int(\n",
    "                self.num * (self.train_frac + self.valid_frac)\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def testY(self):\n",
    "        return self.Y[int(self.num * (self.train_frac + self.valid_frac)) :]\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return self._device\n",
    "\n",
    "    def obj_fn(self, Y):\n",
    "        return (0.5 * (Y @ self.Q) * Y +  self.p * Y).sum(dim=1)\n",
    "\n",
    "    def ineq_dist(self, X, Y):\n",
    "        resids = self.ineq_resid(X, Y)\n",
    "        return torch.clamp(resids, 0)\n",
    "\n",
    "    def eq_grad(self, X, Y):\n",
    "        return 2 * (Y @ self.A.T - X) @ self.A\n",
    "\n",
    "    def ineq_grad(self, X, Y):\n",
    "        ineq_dist = self.ineq_dist(X, Y)\n",
    "        return 2 * ineq_dist @ self.G\n",
    "\n",
    "    def ineq_partial_grad(self, X, Y):\n",
    "        G_effective = self.G[:, self.partial_vars] - self.G[:, self.other_vars] @ (\n",
    "            self._A_other_inv @ self._A_partial\n",
    "        )\n",
    "        h_effective = self.h - (X @ self._A_other_inv.T) @ self.G[:, self.other_vars].T\n",
    "        grad = (\n",
    "            2\n",
    "            * torch.clamp(Y[:, self.partial_vars] @ G_effective.T - h_effective, 0)\n",
    "            @ G_effective\n",
    "        )\n",
    "        Y = torch.zeros(X.shape[0], self.ydim, device=self.device)\n",
    "        Y[:, self.partial_vars] = grad\n",
    "        Y[:, self.other_vars] = -(grad @ self._A_partial.T) @ self._A_other_inv.T\n",
    "        return Y\n",
    "\n",
    "    # Processes intermediate neural network output\n",
    "    def process_output(self, X, Y):\n",
    "        return Y\n",
    "\n",
    "    # Solves for the full set of variables\n",
    "    def complete_partial(self, X, Z):\n",
    "        Y = torch.zeros(X.shape[0], self.ydim, device=self.device)\n",
    "        Y[:, self.partial_vars] = Z\n",
    "        Y[:, self.other_vars] = (X - Z @ self._A_partial.T) @ self._A_other_inv.T\n",
    "        return Y\n",
    "\n",
    "class OriginalQPProblem(SimpleProblem):\n",
    "    def __init__(self, Q, p, A, G, b, d, valid_frac=0.1, test_frac=0.1):\n",
    "        super().__init__(Q, p, A, G, b, d, valid_frac, test_frac)\n",
    "\n",
    "        self._X = self._b\n",
    "        self._num = self._X.shape[0]\n",
    "        self._neq = self._A.shape[0]\n",
    "        self._nineq = self._G.shape[0]\n",
    "        self._xdim = self._X.shape[1]\n",
    "\n",
    "        self.A_transpose = self._A.T\n",
    "        self.G_transpose = self._G.T\n",
    "\n",
    "\n",
    "    def eq_resid(self, X, Y):\n",
    "        # Here, X is the RHS of the equality constraints\n",
    "        return X - Y @ self.A.T\n",
    "\n",
    "    def ineq_resid(self, X, Y):\n",
    "        return Y @ self.G.T - self.d\n",
    "    \n",
    "    def ineq_dist(self, X, Y):\n",
    "        resids = self.ineq_resid(X, Y)\n",
    "        return torch.clamp(resids, 0)\n",
    "    \n",
    "    def opt_solve(self, X, solver_type=\"osqp\", tol=1e-4):\n",
    "        if solver_type == \"osqp\":\n",
    "            print(\"running osqp\")\n",
    "            Q, p, A, G, d = self.Q_np, self.p_np, self.A_np, self.G_np, self.d_np\n",
    "            X_np = X.detach().cpu().numpy()\n",
    "            Y = []\n",
    "            total_time = 0\n",
    "            for Xi in X_np:\n",
    "                solver = osqp.OSQP()\n",
    "                my_A = np.vstack([A, G])\n",
    "                my_l = np.hstack([Xi, -np.ones(d.shape[0]) * np.inf])\n",
    "                my_u = np.hstack([Xi, d])\n",
    "                solver.setup(\n",
    "                    P=csc_matrix(Q),\n",
    "                    q=p,\n",
    "                    A=csc_matrix(my_A),\n",
    "                    l=my_l,\n",
    "                    u=my_u,\n",
    "                    verbose=False,\n",
    "                    eps_prim_inf=tol,\n",
    "                )\n",
    "                start_time = time.time()\n",
    "                results = solver.solve()\n",
    "                end_time = time.time()\n",
    "\n",
    "                total_time += end_time - start_time\n",
    "                if results.info.status == \"solved\":\n",
    "                    Y.append(results.x)\n",
    "                else:\n",
    "                    Y.append(np.ones(self.ydim) * np.nan)\n",
    "\n",
    "                sols = np.array(Y)\n",
    "                parallel_time = total_time / len(X_np)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        return sols, total_time, parallel_time\n",
    "\n",
    "    def calc_Y(self):\n",
    "        Y = self.opt_solve(self.X)[0]\n",
    "        feas_mask = ~np.isnan(Y).all(axis=1)\n",
    "        self._num = feas_mask.sum()\n",
    "        self._X = self._X[feas_mask]\n",
    "        self._Y = torch.tensor(Y[feas_mask])\n",
    "        return Y\n",
    "\n",
    "class QPProblemVaryingG(SimpleProblem):\n",
    "    def __init__(self, X, Q, p, A, G, b, d, row_indices, col_indices, valid_frac=0.1, test_frac=0.1):\n",
    "        super().__init__(Q, p, A, G, b, d, valid_frac, test_frac)\n",
    "        # X are the varying values of G\n",
    "        self._X = X\n",
    "        self._num = self._X.shape[0]\n",
    "        self._neq = self._A.shape[0]\n",
    "        self._nineq = self._G.shape[0]\n",
    "        self._xdim = self._X.shape[1]\n",
    "\n",
    "        self.row_indices = row_indices\n",
    "        self.col_indices = col_indices\n",
    "\n",
    "    def eq_resid(self, X, Y):\n",
    "        # Here, X is part of the inequality constraint matrix. So we don't use it\n",
    "        return self.b - Y @ self.A.T\n",
    "\n",
    "    def ineq_resid(self, X, Y):\n",
    "        # Here, X is part of the inequality constraint matrix. So, we need to plug X into the inequality constraint matrix.\n",
    "        G = self.G.expand(X.shape[0], -1, -1).clone()\n",
    "        G[:, self.row_indices, self.col_indices] = X\n",
    "        return torch.bmm(G, Y.unsqueeze(-1)).squeeze(-1) - self.d\n",
    "    \n",
    "    def ineq_dist(self, X, Y):\n",
    "        resids = self.ineq_resid(X, Y)\n",
    "        return torch.clamp(resids, 0)\n",
    "    \n",
    "    def opt_solve(self, X, solver_type=\"osqp\", tol=1e-4):\n",
    "        \"\"\"We change op_solve so that the varying G matrices are taken from the input X.\n",
    "        \"\"\"\n",
    "        if solver_type == \"osqp\":\n",
    "            print(\"running osqp\")\n",
    "            Q, p, b, d = self.Q_np, self.p_np, self.b_np, self.d_np\n",
    "            G = self.G.expand(X.shape[0], -1, -1).clone()\n",
    "            G[:, self.row_indices, self.col_indices] = X\n",
    "            G = G\n",
    "            A = self.A_np\n",
    "            Y = []\n",
    "            total_time = 0\n",
    "\n",
    "            for Gi in G:\n",
    "                \n",
    "                solver = osqp.OSQP()\n",
    "                my_A = np.vstack([A, Gi])\n",
    "                my_l = np.hstack([b, -np.ones(d.shape[0]) * np.inf])\n",
    "                my_u = np.hstack([b, d])\n",
    "                solver.setup(\n",
    "                    P=csc_matrix(Q),\n",
    "                    q=p,\n",
    "                    A=csc_matrix(my_A),\n",
    "                    l=my_l,\n",
    "                    u=my_u,\n",
    "                    verbose=False,\n",
    "                    eps_prim_inf=tol,\n",
    "                )\n",
    "                start_time = time.time()\n",
    "                results = solver.solve()\n",
    "                end_time = time.time()\n",
    "\n",
    "                total_time += end_time - start_time\n",
    "                if results.info.status == \"solved\":\n",
    "                    Y.append(results.x)\n",
    "                else:\n",
    "                    Y.append(np.ones(self.ydim) * np.nan)\n",
    "\n",
    "            sols = np.array(Y)\n",
    "            parallel_time = total_time / len(G)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        return sols, total_time, parallel_time\n",
    "\n",
    "    def calc_Y(self):\n",
    "        Y = self.opt_solve(self.X)[0]\n",
    "        feas_mask = ~np.isnan(Y).all(axis=1)\n",
    "        self._num = feas_mask.sum()\n",
    "        self._X = self._X[feas_mask]\n",
    "        self._Y = torch.tensor(Y[feas_mask])\n",
    "        return Y\n",
    "\n",
    "class QPProblemVaryingGbd(SimpleProblem):\n",
    "    def __init__(self, Q, p, A, G_base, G_varying, b, d, n_varying_rows, valid_frac=0.1, test_frac=0.1):\n",
    "        super().__init__(Q, p, A, G_varying, b, d, valid_frac, test_frac)\n",
    "        self.G_base = torch.tensor(G_base)\n",
    "        self.n_varying_rows = n_varying_rows\n",
    "        # Flatten the rows of G that are varying, to be added to the NN input.\n",
    "        G_flattened = self.G[:, :n_varying_rows, :].flatten(start_dim=1)\n",
    "        self._X = torch.concat([G_flattened, self.b, self.d], dim=1)\n",
    "        self._num = self._X.shape[0]\n",
    "        self._neq = self._A.shape[0]\n",
    "        # G now has num_samples in first dimension, num_constraints in second dimension. Take second dimension!\n",
    "        self._nineq = self._G.shape[1]\n",
    "        self._xdim = self._X.shape[1]\n",
    "\n",
    "    def eq_resid(self, X, Y):\n",
    "        \"\"\"B is now varying, we should extract it from X\"\"\"\n",
    "        G, b, d = self.rebuild_Gbd_from_X(X)\n",
    "        return b - Y @ self.A.T\n",
    "\n",
    "    def rebuild_Gbd_from_X(self, X):\n",
    "        # Reshape X to match the first self.n_varying_rows rows of G\n",
    "        G_size = self.n_varying_rows*self.ydim\n",
    "        b_size = self.neq\n",
    "        flattened_G = X[:, :G_size]\n",
    "        b = X[:, G_size:G_size+b_size]\n",
    "        d = X[:, G_size+b_size:]\n",
    "        custom_G = flattened_G.reshape(X.shape[0], self.n_varying_rows, self._ydim)  # Reshape for the batch size\n",
    "\n",
    "        # Take only the first sample of G and clone it for modification\n",
    "        G = self.G_base.clone()  # Shape is (M, P)\n",
    "\n",
    "        # Repeat G for the batch size to avoid memory overlap\n",
    "        G = G.unsqueeze(0).repeat(X.shape[0], 1, 1)  # Shape is (batch_size, M, P)\n",
    "\n",
    "        # Assign custom_G to the first self.n_varying_rows rows of G\n",
    "        G[:, :self.n_varying_rows, :] = custom_G  # Ensure dimensions match\n",
    "        return G, b, d\n",
    "    \n",
    "    def ineq_resid(self, X, Y):\n",
    "        \"\"\"\n",
    "        For the ineq resid, we need to extract the first n rows of the G matrix from it's flattened form X, and plug them into G.\n",
    "        \"\"\"\n",
    "\n",
    "        G, b, d = self.rebuild_Gbd_from_X(X)\n",
    "\n",
    "        # resid = Y @ G.transpose(1, 2) - h\n",
    "        residual = torch.bmm(Y.unsqueeze(1), G.transpose(1, 2)).squeeze(1) - d\n",
    "\n",
    "        # Compute inequality residual\n",
    "        return residual\n",
    "    \n",
    "    def opt_solve(self, X, solver_type=\"osqp\", tol=1e-4):\n",
    "        \"\"\"We change op_solve so that the varying G matrices are taken from the input X.\n",
    "        \"\"\"\n",
    "        if solver_type == \"osqp\":\n",
    "            print(\"running osqp\")\n",
    "            Q, p, b, d = self.Q_np, self.p_np, self.b_np, self.d_np\n",
    "            G, b, d = self.rebuild_Gbd_from_X(X)\n",
    "            G_np, b_np, d_np = G.detach().cpu().numpy(), b.detach().cpu().numpy(), d.detach().cpu().numpy()\n",
    "            A = self.A_np\n",
    "            Y = []\n",
    "            total_time = 0\n",
    "            for idx, Gi in enumerate(G_np):\n",
    "                solver = osqp.OSQP()\n",
    "                my_A = np.vstack([A, Gi])\n",
    "                my_l = np.hstack([b_np[idx], -np.ones(d_np[idx].shape[0]) * np.inf])\n",
    "                my_u = np.hstack([b_np[idx], d_np[idx]])\n",
    "                solver.setup(\n",
    "                    P=csc_matrix(Q),\n",
    "                    q=p,\n",
    "                    A=csc_matrix(my_A),\n",
    "                    l=my_l,\n",
    "                    u=my_u,\n",
    "                    verbose=False,\n",
    "                    eps_prim_inf=tol,\n",
    "                )\n",
    "                start_time = time.time()\n",
    "                results = solver.solve()\n",
    "                end_time = time.time()\n",
    "\n",
    "                total_time += end_time - start_time\n",
    "                if results.info.status == \"solved\":\n",
    "                    Y.append(results.x)\n",
    "                else:\n",
    "                    Y.append(np.ones(self.ydim) * np.nan)\n",
    "\n",
    "            sols = np.array(Y)\n",
    "            parallel_time = total_time / len(X)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        return sols, total_time, parallel_time\n",
    "\n",
    "    def calc_Y(self):\n",
    "        Y = self.opt_solve(self.X)[0]\n",
    "        feas_mask = ~np.isnan(Y).all(axis=1)\n",
    "        self._num = feas_mask.sum()\n",
    "        self._X = self._X[feas_mask]\n",
    "        self._Y = torch.tensor(Y[feas_mask])\n",
    "        return Y\n",
    "    \n",
    "\n",
    "class ScaledLPProblem(SimpleProblem):\n",
    "    def __init__(self, Q, p, A, G, b, d, obj_coeff, valid_frac=0.1, test_frac=0.1):\n",
    "        super().__init__(Q, p, A, G, b, d, valid_frac, test_frac)\n",
    "\n",
    "        self._X = self._b\n",
    "        self._c = torch.tensor(obj_coeff)\n",
    "        self._num = self._X.shape[0]\n",
    "        self._neq = self._A.shape[0]\n",
    "        self._nineq = self._G.shape[0]\n",
    "        self._xdim = self._X.shape[1]\n",
    "\n",
    "    def eq_resid(self, X, Y):\n",
    "        return X - Y @ self.A.T\n",
    "\n",
    "    def ineq_resid(self, X, Y):\n",
    "        return Y @ self.G.T - self.d\n",
    "\n",
    "    def obj_fn(self, Y):\n",
    "        return Y @ self._c.T\n",
    "\n",
    "    \n",
    "    def opt_solve(self, X, solver_type=\"osqp\", tol=1e-4):\n",
    "        if solver_type == \"osqp\":\n",
    "            print(\"running osqp\")\n",
    "            Q, p, A, G, d = self.Q_np, self.p_np, self.A_np, self.G_np, self.d_np\n",
    "            c = self._c.numpy()\n",
    "            X_np = X.detach().cpu().numpy()\n",
    "            Y = []\n",
    "            total_time = 0\n",
    "            zero_Q = np.zeros((c.shape[0], c.shape[0]))\n",
    "\n",
    "            for Xi in X_np:\n",
    "                solver = osqp.OSQP()\n",
    "                my_A = np.vstack([A, G])\n",
    "                my_l = np.hstack([Xi, -np.ones(d.shape[0]) * np.inf])\n",
    "                my_u = np.hstack([Xi, d])\n",
    "                solver.setup(\n",
    "                    q=c,\n",
    "                    A=csc_matrix(my_A),\n",
    "                    l=my_l,\n",
    "                    u=my_u,\n",
    "                    verbose=False,\n",
    "                    eps_prim_inf=tol,\n",
    "                )\n",
    "                start_time = time.time()\n",
    "                results = solver.solve()\n",
    "                end_time = time.time()\n",
    "\n",
    "                total_time += end_time - start_time\n",
    "                if results.info.status == \"solved\":\n",
    "                    Y.append(results.x)\n",
    "                else:\n",
    "                    Y.append(np.ones(self.ydim) * np.nan)\n",
    "\n",
    "                sols = np.array(Y)\n",
    "                parallel_time = total_time / len(X_np)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        return sols, total_time, parallel_time\n",
    "\n",
    "    def calc_Y(self):\n",
    "        Y = self.opt_solve(self.X)[0]\n",
    "        feas_mask = ~np.isnan(Y).all(axis=1)\n",
    "        self._num = feas_mask.sum()\n",
    "        self._X = self._X[feas_mask]\n",
    "        self._Y = torch.tensor(Y[feas_mask])\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_QP_dataset(num_var, num_ineq, num_eq, num_examples):\n",
    "    np.random.seed(17)\n",
    "    Q = np.diag(np.random.random(num_var))\n",
    "    p = np.random.random(num_var)\n",
    "    A = np.random.normal(loc=0, scale=1., size=(num_eq, num_var))\n",
    "    X = np.random.uniform(-1, 1, size=(num_examples, num_eq))\n",
    "    G = np.random.normal(loc=0, scale=1., size=(num_ineq, num_var))\n",
    "    h = np.sum(np.abs(G@np.linalg.pinv(A)), axis=1)\n",
    "\n",
    "    problem = OriginalQPProblem(Q, p, A, G, X, h)\n",
    "    problem.calc_Y()\n",
    "    print(len(problem.Y))\n",
    "\n",
    "    with open(\"./QP_data/QP_simple_dataset_var{}_ineq{}_eq{}_ex{}\".format(num_var, num_ineq, num_eq, num_examples), 'wb') as f:\n",
    "        pickle.dump(problem, f)\n",
    "    \n",
    "    return problem\n",
    "\n",
    "def create_varying_G_dataset(num_var, num_ineq, num_eq, num_examples, vary):\n",
    "    \"\"\"Creates a modified QP data set that differs in the inequality constraint matrix, instead of the RHS variables.\n",
    "    \"\"\"\n",
    "    np.random.seed(17)\n",
    "    Q = np.diag(np.random.random(num_var))\n",
    "    p = np.random.random(num_var)\n",
    "    A = np.random.normal(loc=0, scale=1., size=(num_eq, num_var))\n",
    "    # X is the same for all samples:\n",
    "    b = np.random.uniform(-1, 1, size=(num_eq))\n",
    "    G = np.random.normal(loc=0, scale=1., size=(num_ineq, num_var))\n",
    "    d = np.sum(np.abs(G@np.linalg.pinv(A)), axis=1)\n",
    "\n",
    "    X = np.random.normal(loc=0, scale=1., size=(num_examples, num_ineq))\n",
    "\n",
    "    # Try first with changing a single row!\n",
    "    if vary == 'row':\n",
    "        row_indices = [0] * num_ineq\n",
    "        col_indices = list(range(num_ineq))\n",
    "    if vary == 'column':\n",
    "        col_indices = [0] * num_ineq\n",
    "        row_indices = list(range(num_ineq))\n",
    "    if vary == 'random':\n",
    "        col_indices = np.random.choice(num_var, num_ineq, replace=False)\n",
    "        row_indices = np.random.choice(num_ineq, num_ineq, replace=True)\n",
    "\n",
    "    problem = QPProblemVaryingG(X=torch.tensor(X), Q=Q, p=p, A=A, G=G, b=b, d=d, row_indices=row_indices, col_indices=col_indices)\n",
    "    problem.calc_Y()\n",
    "    print(len(problem.Y))\n",
    "\n",
    "    with open(\"./QP_data/Varying_G_type={}_dataset_var{}_ineq{}_eq{}_ex{}\".format(vary, num_var, num_ineq, num_eq, num_examples), 'wb') as f:\n",
    "        pickle.dump(problem, f)\n",
    "    \n",
    "    return problem\n",
    "\n",
    "def create_varying_G_b_d_dataset(num_var, num_ineq, num_eq, num_examples, num_varying_rows):\n",
    "    \"\"\"Creates a modified QP data set that differs in the inequality constraint matrix, instead of the RHS variables.\n",
    "    \"\"\"\n",
    "    np.random.seed(17)\n",
    "    Q = np.diag(np.random.random(num_var))\n",
    "    p = np.random.random(num_var)\n",
    "    A = np.random.normal(loc=0, scale=1., size=(num_eq, num_var))\n",
    "    # X is the same for all samples:\n",
    "    B = np.random.uniform(-1, 1, size=(num_examples, num_eq))\n",
    "    G_base = np.random.normal(loc=0, scale=1., size=(num_ineq, num_var))\n",
    "\n",
    "    G_list = []\n",
    "    # For each sample, create a different inequality constraint matrix\n",
    "    for _ in range(num_examples):\n",
    "        G_sample = G_base.copy()\n",
    "        # Vary the first n rows, (specified by num_varying_rows).\n",
    "        G_sample[:num_varying_rows, :] = np.random.normal(loc=0, scale=1., size=(num_varying_rows, num_var))\n",
    "        G_list.append(G_sample)\n",
    "    \n",
    "    # Create H matrix for each example\n",
    "    D_list = []\n",
    "    for Gi in G_list:\n",
    "        d = np.sum(np.abs(Gi @ np.linalg.pinv(A)), axis=1)  # Compute bounds for all inequalities\n",
    "        D_list.append(d)  # Resulting shape will be (num_ineq,)\n",
    "\n",
    "    G = np.array(G_list)\n",
    "    D = np.stack(D_list, axis=0)  # Shape (num_examples, num_ineq)\n",
    "    problem = QPProblemVaryingGbd(Q=Q, p=p, A=A, G_base=G_base, G_varying=G, b=B, d=D, n_varying_rows=num_varying_rows)\n",
    "    problem.calc_Y()\n",
    "    print(len(problem.Y))\n",
    "\n",
    "    with open(\"./QP_data/modified/MODIFIED_random_simple_dataset_var{}_ineq{}_eq{}_ex{}\".format(num_var, num_ineq, num_eq, num_examples), 'wb') as f:\n",
    "        pickle.dump(problem, f)\n",
    "    \n",
    "    return problem\n",
    "\n",
    "def create_scaled_QP_problem(num_var, num_ineq, num_eq, num_examples, scale='normal'):\n",
    "    if scale == 'normal':\n",
    "        obj_scale = 1\n",
    "        var_scale = 1\n",
    "        rhs_scale = 1\n",
    "    elif scale == 'large':\n",
    "        obj_scale = 1e9\n",
    "        var_scale = 1e3\n",
    "        rhs_scale = 1e3\n",
    "\n",
    "    np.random.seed(17)\n",
    "\n",
    "    Q = np.diag(np.random.random(num_var)) * obj_scale\n",
    "    p = np.random.random(num_var)\n",
    "    A = np.random.normal(loc=0, scale=var_scale, size=(num_eq, num_var))\n",
    "    X = np.random.uniform(-rhs_scale, rhs_scale, size=(num_examples, num_eq))\n",
    "    G = np.random.normal(loc=0, scale=var_scale, size=(num_ineq, num_var))\n",
    "    h = np.sum(np.abs(G@np.linalg.pinv(A)), axis=1)\n",
    "\n",
    "    problem = OriginalQPProblem(Q, p, A, G, X, h)\n",
    "    problem.calc_Y()\n",
    "    print(len(problem.Y))\n",
    "\n",
    "    # with open(\"./QP_data/original/random_simple_dataset_var{}_ineq{}_eq{}_ex{}\".format(num_var, num_ineq, num_eq, num_examples), 'wb') as f:\n",
    "        # pickle.dump(problem, f)\n",
    "    \n",
    "    return problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n"
     ]
    }
   ],
   "source": [
    "DTYPE = torch.float64\n",
    "DEVICE = torch.device=\"cpu\"\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "torch.manual_seed(42)\n",
    "print(f\"Running on {DEVICE}\")\n",
    "        \n",
    "class PrimalDualTrainer():\n",
    "\n",
    "    def __init__(self, data, args, save_dir):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            data (_type_): _description_\n",
    "            args (_type_): _description_\n",
    "            save_dir (_type_): _description_\n",
    "            problem_type (str, optional): Either \"GEP\" or \"Benchmark\". Defaults to \"GEP\".\n",
    "            log (bool, optional): _description_. Defaults to True.\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"X dim: {data.xdim}\")\n",
    "        print(f\"Y dim: {data.ydim}\")\n",
    "\n",
    "        print(f\"Size of mu: {data.nineq}\")\n",
    "        print(f\"Size of lambda: {data.neq}\")\n",
    "\n",
    "        self.data = data\n",
    "        self.args = args\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        self.outer_iterations = args[\"outer_iterations\"]\n",
    "        self.inner_iterations = args[\"inner_iterations\"]\n",
    "        self.tau = args[\"tau\"]\n",
    "        self.rho = args[\"rho\"]\n",
    "        self.rho_max = args[\"rho_max\"]\n",
    "        self.alpha = args[\"alpha\"]\n",
    "        self.batch_size = args[\"batch_size\"]\n",
    "        self.hidden_sizes = args[\"hidden_sizes\"]\n",
    "\n",
    "        self.primal_lr = args[\"primal_lr\"]\n",
    "        self.dual_lr = args[\"dual_lr\"]\n",
    "        self.decay = args[\"decay\"]\n",
    "        self.patience = args[\"patience\"]\n",
    "        \n",
    "        # for logging\n",
    "        self.step = 0\n",
    "\n",
    "        X = data.X\n",
    "\n",
    "        train = data.train_indices\n",
    "        valid = data.valid_indices\n",
    "        test = data.test_indices\n",
    "\n",
    "        # Traning data in a data set\n",
    "        #! Vary per experiment\n",
    "        self.train_dataset = TensorDataset(X[train].to(DEVICE))\n",
    "        self.valid_dataset = TensorDataset(X[valid].to(DEVICE))\n",
    "        self.test_dataset = TensorDataset(X[test].to(DEVICE))\n",
    "\n",
    "        self.train_loader = DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        self.valid_loader = DataLoader(self.valid_dataset, batch_size=1000, shuffle=False)\n",
    "        self.test_loader = DataLoader(self.test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "        self.primal_net = PrimalNet(self.data, self.hidden_sizes).to(dtype=DTYPE, device=DEVICE)\n",
    "        self.dual_net = DualNet(self.data, self.hidden_sizes, self.data.nineq, self.data.neq).to(dtype=DTYPE, device=DEVICE)\n",
    "\n",
    "        self.primal_optim = torch.optim.Adam(self.primal_net.parameters(), lr=self.primal_lr)\n",
    "        self.dual_optim = torch.optim.Adam(self.dual_net.parameters(), lr=self.dual_lr)\n",
    "\n",
    "        # Add schedulers\n",
    "        self.primal_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.primal_optim, mode='min', factor=self.decay, patience=self.patience\n",
    "        )\n",
    "        self.dual_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.dual_optim, mode='min', factor=self.decay, patience=self.patience\n",
    "        )\n",
    "\n",
    "    def train_PDL(self, max_violation_save_thresholds=[0.005, 0.006, 0.007, 0.008, 0.009, 0.01]):\n",
    "        try:\n",
    "            best_val_losses = [0] * len(max_violation_save_thresholds)\n",
    "            prev_v_k = 0\n",
    "            training_time = 0\n",
    "            stats = {}\n",
    "            stats[\"training_time\"] = {}\n",
    "            for k in range(self.outer_iterations):\n",
    "                begin_time = time.time()\n",
    "                frozen_dual_net = copy.deepcopy(self.dual_net)\n",
    "                # self.logger.log_rho_vk(self.rho, prev_v_k, self.step)\n",
    "                for l1 in range(self.inner_iterations):\n",
    "                    self.step += 1\n",
    "                    # Update primal net using primal loss\n",
    "                    self.primal_net.train()\n",
    "\n",
    "                    # Accumulate training loss over all batches\n",
    "                    for Xtrain in self.train_loader:\n",
    "                        Xtrain = Xtrain[0]\n",
    "                        batch_start = time.time()\n",
    "                        self.primal_optim.zero_grad()\n",
    "                        y = self.primal_net(Xtrain)\n",
    "                        with torch.no_grad():\n",
    "                            mu, lamb = frozen_dual_net(Xtrain)\n",
    "                        batch_loss = self.primal_loss(Xtrain, y, mu, lamb).mean()\n",
    "                        batch_loss.backward()\n",
    "                        self.primal_optim.step()\n",
    "                        training_time += time.time() - batch_start\n",
    "\n",
    "\n",
    "                    # Evaluate validation loss every epoch, and update learning rate\n",
    "                    with torch.no_grad():\n",
    "                        self.primal_net.eval()\n",
    "                        frozen_dual_net.eval()\n",
    "                        obj_val_mean, val_loss_mean, ineq_max, ineq_mean, eq_max, eq_mean = self.evaluate(self.valid_dataset.tensors[0], self.primal_net, self.dual_net)    \n",
    "                        \n",
    "                        # Normalize by rho, so that the schedular still works correctly if rho is increased\n",
    "                        self.primal_scheduler.step(torch.sign(val_loss_mean) * (torch.abs(val_loss_mean) / self.rho))\n",
    "\n",
    "                        # Save if best model:\n",
    "                        for i in range(len(max_violation_save_thresholds)):\n",
    "                            if ineq_max < max_violation_save_thresholds[i] \\\n",
    "                            and eq_max < max_violation_save_thresholds[i] \\\n",
    "                            and obj_val_mean < best_val_losses[i]:\n",
    "                                print(f\"Saving new model with obj: {obj_val_mean}, eq_max: {eq_max}, ineq_max: {ineq_max}, eq_mean: {eq_mean}, ineq_mean: {ineq_mean}\")\n",
    "                                with open(os.path.join(self.save_dir, f'{max_violation_save_thresholds[i]}_primal_net.dict'), 'wb') as f:\n",
    "                                    torch.save(self.primal_net.state_dict(), f)\n",
    "                                with open(os.path.join(self.save_dir, f'{max_violation_save_thresholds[i]}_dual_net.dict'), 'wb') as f:\n",
    "                                    torch.save(self.dual_net.state_dict(), f)\n",
    "                                best_val_losses[i] = obj_val_mean\n",
    "\n",
    "                                stats[\"training_time\"][f\"{max_violation_save_thresholds[i]}\"] = training_time\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    # Copy primal net into frozen primal net\n",
    "                    frozen_primal_net = copy.deepcopy(self.primal_net)\n",
    "                    X = self.train_dataset.tensors[0]\n",
    "                    # Calculate v_k\n",
    "                    y = frozen_primal_net(X)\n",
    "                    mu_k, lamb_k = frozen_dual_net(X)\n",
    "                    v_k = self.violation(X, y, mu_k)\n",
    "\n",
    "                for l in range(self.inner_iterations):\n",
    "                    self.step += 1\n",
    "                    # Update dual net using dual loss\n",
    "                    self.dual_net.train()\n",
    "                    frozen_primal_net.train()\n",
    "                    for Xtrain in self.train_loader:\n",
    "                        Xtrain = Xtrain[0]\n",
    "                        batch_start = time.time()\n",
    "                        self.dual_optim.zero_grad()\n",
    "                        mu, lamb = self.dual_net(Xtrain)\n",
    "                        with torch.no_grad():\n",
    "                            mu_k, lamb_k = frozen_dual_net(Xtrain)\n",
    "                            y = frozen_primal_net(Xtrain)\n",
    "                        batch_loss = self.dual_loss(Xtrain, y, mu, lamb, mu_k, lamb_k).mean()\n",
    "                        batch_loss.backward()\n",
    "                        self.dual_optim.step()\n",
    "                        training_time += time.time() - batch_start\n",
    "\n",
    "                    # Evaluate validation loss every epoch, and update learning rate\n",
    "                    with torch.no_grad():\n",
    "                        frozen_primal_net.eval()\n",
    "                        self.dual_net.eval()\n",
    "                        obj_val_mean, val_loss_mean, ineq_max, ineq_mean, eq_max, eq_mean = self.evaluate(self.valid_dataset.tensors[0], self.primal_net, self.dual_net)    \n",
    "                        # Normalize by rho, so that the schedular still works correctly if rho is increased\n",
    "                        self.dual_scheduler.step(torch.sign(val_loss_mean) * (torch.abs(val_loss_mean) / self.rho))\n",
    "\n",
    "                end_time = time.time()\n",
    "                print(\"-\"*40)\n",
    "                print(f\"Epoch {k} done. Time taken: {end_time - begin_time}. Rho: {self.rho}. Primal LR: {self.primal_optim.param_groups[0]['lr']}, Dual LR: {self.dual_optim.param_groups[0]['lr']}\")\n",
    "\n",
    "                # Update rho from the second iteration onward.\n",
    "                if k > 0 and v_k > self.tau * prev_v_k:\n",
    "                    self.rho = np.min([self.alpha * self.rho, self.rho_max])\n",
    "\n",
    "                prev_v_k = v_k\n",
    "            \n",
    "                print(f\"Validation set evaluate:\")\n",
    "                with torch.no_grad():\n",
    "                    self.primal_net.eval()\n",
    "                    self.dual_net.eval()\n",
    "                    obj_val_mean, val_loss_mean, ineq_max, ineq_mean, eq_max, eq_mean = self.evaluate(self.valid_dataset.tensors[0], self.primal_net, self.dual_net)\n",
    "                    print(f\"obj_val_mean: {obj_val_mean}, val_loss_mean: {val_loss_mean}, ineq_max: {ineq_max}, ineq_mean: {ineq_mean}, eq_max: {eq_max}, eq_mean: {eq_mean}\")    \n",
    "                    \n",
    "            print(\"-\"*40)\n",
    "            print(f\"Test set evaluate:\")\n",
    "            with torch.no_grad():\n",
    "                self.primal_net.eval()\n",
    "                self.dual_net.eval()\n",
    "                obj_val_mean, test_loss_mean, ineq_max, ineq_mean, eq_max, eq_mean = self.evaluate(self.test_dataset.tensors[0], self.primal_net, self.dual_net)\n",
    "                print(f\"obj_val_mean: {obj_val_mean}, val_loss_mean: {test_loss_mean}, ineq_max: {ineq_max}, ineq_mean: {ineq_mean}, eq_max: {eq_max}, eq_mean: {eq_mean}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e, flush=True)\n",
    "            # # Ensure writer is closed even if an exception occurs\n",
    "            # if self.logger:\n",
    "            #     self.logger.close()\n",
    "            raise\n",
    "\n",
    "        with open(os.path.join(self.save_dir, 'stats.dict'), 'wb') as f:\n",
    "            pickle.dump(stats, f)\n",
    "        with open(os.path.join(self.save_dir, 'primal_net.dict'), 'wb') as f:\n",
    "            torch.save(self.primal_net.state_dict(), f)\n",
    "        with open(os.path.join(self.save_dir, 'dual_net.dict'), 'wb') as f:\n",
    "            torch.save(self.dual_net.state_dict(), f)\n",
    "\n",
    "        return self.primal_net, self.dual_net, stats\n",
    "\n",
    "    def evaluate(self, X, primal_net, dual_net):        \n",
    "        # Forward pass through networks\n",
    "        Y = primal_net(X)\n",
    "        mu, lamb = dual_net(X)\n",
    "\n",
    "        ineq_dist = self.data.ineq_dist(X, Y)\n",
    "        eq_resid = self.data.eq_resid(X, Y)\n",
    "\n",
    "        # Convert lists to arrays for easier handling\n",
    "        obj_values = self.data.obj_fn(Y).detach()\n",
    "        primal_losses = self.primal_loss(X, Y, mu, lamb).detach()\n",
    "        ineq_max_vals = torch.max(ineq_dist, dim=1)[0].detach()\n",
    "        ineq_mean_vals = torch.mean(ineq_dist, dim=1).detach()\n",
    "        eq_max_vals = torch.max(torch.abs(eq_resid), dim=1)[0].detach()\n",
    "        eq_mean_vals = torch.mean(torch.abs(eq_resid), dim=1).detach()\n",
    "\n",
    "        return torch.mean(obj_values), torch.mean(primal_losses), torch.mean(ineq_max_vals), torch.mean(ineq_mean_vals), torch.mean(eq_max_vals), torch.mean(eq_mean_vals)\n",
    "\n",
    "\n",
    "\n",
    "    def primal_loss(self, x, y, mu, lamb):\n",
    "        obj = self.data.obj_fn(y)\n",
    "        \n",
    "        # g(y)\n",
    "        ineq = self.data.ineq_resid(x, y)\n",
    "        # h(y)\n",
    "        eq = self.data.eq_resid(x, y)\n",
    "\n",
    "        # ! Clamp mu?\n",
    "        # Element-wise clamping of mu_i when g_i (ineq) is negative\n",
    "        # mu = torch.where(ineq < 0, torch.zeros_like(mu), mu)\n",
    "        # ! Clamp ineq_resid?\n",
    "        # ineq = ineq.clamp(min=0)\n",
    "\n",
    "        lagrange_ineq = torch.sum(mu * ineq, dim=1)  # Shape (batch_size,)\n",
    "\n",
    "        lagrange_eq = torch.sum(lamb * eq, dim=1)   # Shape (batch_size,)\n",
    "\n",
    "        violation_ineq = torch.sum(torch.maximum(ineq, torch.zeros_like(ineq)) ** 2, dim=1)\n",
    "        violation_eq = torch.sum(eq ** 2, dim=1)\n",
    "        penalty = self.rho/2 * (violation_ineq + violation_eq)\n",
    "\n",
    "        loss = (obj + (lagrange_ineq + lagrange_eq + penalty))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def dual_loss(self, x, y, mu, lamb, mu_k, lamb_k):\n",
    "        # mu = [batch, g]\n",
    "        # lamb = [batch, h]\n",
    "\n",
    "        # g(y)\n",
    "        ineq = self.data.ineq_resid(x, y) # [batch, g]\n",
    "        # h(y)\n",
    "        eq = self.data.eq_resid(x, y)   # [batch, h]\n",
    "\n",
    "        #! From 2nd PDL paper, fix to 1e-1, not rho\n",
    "        target_mu = torch.maximum(mu_k + self.rho * ineq, torch.zeros_like(ineq))\n",
    "        # target_mu = torch.maximum(mu_k + 1e-1 * ineq, torch.zeros_like(ineq))\n",
    "\n",
    "        dual_resid_ineq = mu - target_mu # [batch, g]\n",
    "\n",
    "        dual_resid_ineq = torch.norm(dual_resid_ineq, dim=1)  # [batch]\n",
    "\n",
    "        # Compute the dual residuals for equality constraints\n",
    "        #! From 2nd PDL paper, fix to 1e-1, not rho\n",
    "        dual_resid_eq = lamb - (lamb_k + self.rho * eq)\n",
    "        # dual_resid_eq = lamb - (lamb_k + 1e-1 * eq)\n",
    "        dual_resid_eq = torch.norm(dual_resid_eq, dim=1)  # Norm along constraint dimension\n",
    "\n",
    "        loss = (dual_resid_ineq + dual_resid_eq)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def violation(self, x, y, mu_k):\n",
    "        # Calculate the equality constraint function h_x(y)\n",
    "        eq = self.data.eq_resid(x, y)  # Assume shape (num_samples, n_eq)\n",
    "        \n",
    "        # Calculate the infinity norm of h_x(y)\n",
    "        eq_inf_norm = torch.abs(eq).max(dim=1).values  # Shape: (num_samples,)\n",
    "\n",
    "        # Calculate the inequality constraint function g_x(y)\n",
    "        ineq = self.data.ineq_resid(x, y)  # Assume shape (num_samples, n_ineq)\n",
    "        \n",
    "        # Calculate sigma_x(y) for each inequality constraint\n",
    "        sigma_y = torch.maximum(ineq, -mu_k / self.rho)  # Element-wise max\n",
    "        \n",
    "        # Calculate the infinity norm of sigma_x(y)\n",
    "        sigma_y_inf_norm = torch.abs(sigma_y).max(dim=1).values  # Shape: (num_samples,)\n",
    "\n",
    "        # Compute v_k as the maximum of the two norms\n",
    "        v_k = torch.maximum(eq_inf_norm, sigma_y_inf_norm)  # Shape: (num_samples,)\n",
    "        \n",
    "        return v_k.max().item()\n",
    "\n",
    "class PrimalNet(nn.Module):\n",
    "    def __init__(self, data, hidden_sizes):\n",
    "        super().__init__()\n",
    "        self._data = data\n",
    "        self._hidden_sizes = hidden_sizes\n",
    "        \n",
    "        # Create the list of layer sizes\n",
    "        layer_sizes = [data.xdim] + self._hidden_sizes + [data.ydim]\n",
    "        layers = []\n",
    "\n",
    "        # Create layers dynamically based on the provided hidden_sizes\n",
    "        for in_size, out_size in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "            layers.append(nn.Linear(in_size, out_size))\n",
    "            if out_size != data.ydim:  # Add ReLU activation for hidden layers only\n",
    "                layers.append(nn.ReLU())\n",
    "\n",
    "        # Initialize all layers\n",
    "        for layer in layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.kaiming_normal_(layer.weight)\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class DualNet(nn.Module):\n",
    "    def __init__(self, data, hidden_sizes, mu_size, lamb_size):\n",
    "        super().__init__()\n",
    "        self._data = data\n",
    "        self._hidden_sizes = hidden_sizes\n",
    "        self._mu_size = mu_size\n",
    "        self._lamb_size = lamb_size\n",
    "\n",
    "        # Create the list of layer sizes\n",
    "        layer_sizes = [data.xdim] + self._hidden_sizes\n",
    "        # layer_sizes = [2*data.xdim + 1000] + self._hidden_sizes\n",
    "        layers = []\n",
    "        # Create layers dynamically based on the provided hidden_sizes\n",
    "        for in_size, out_size in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "            layers.append(nn.Linear(in_size, out_size))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        # Initialize all layers\n",
    "        for layer in layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.kaiming_normal_(layer.weight)\n",
    "\n",
    "        # Add the output layer\n",
    "        self.out_layer = nn.Linear(self._hidden_sizes[-1], self._mu_size + self._lamb_size)\n",
    "        nn.init.zeros_(self.out_layer.weight)  # Initialize output layer weights to 0\n",
    "        nn.init.zeros_(self.out_layer.bias)    # Initialize output layer biases to 0\n",
    "        layers.append(self.out_layer)\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        out_mu = out[:, :self._mu_size]\n",
    "        out_lamb = out[:, self._mu_size:]\n",
    "        return out_mu, out_lamb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_var = 100\n",
    "num_ineq = 50\n",
    "num_eq = 50\n",
    "num_examples = 10000\n",
    "\n",
    "args = {\n",
    "    \"outer_iterations\": 10,\n",
    "    \"inner_iterations\": 500,\n",
    "    \"tau\": 0.8,\n",
    "    \"rho\": 0.5,\n",
    "    \"rho_max\": 5000,\n",
    "    \"alpha\": 10,\n",
    "    \"batch_size\": 100,\n",
    "    \"hidden_sizes\": [500, 500],\n",
    "    \"primal_lr\": 1e-4,\n",
    "    \"dual_lr\": 1e-4,\n",
    "    \"decay\": 0.99,\n",
    "    \"patience\": 10,\n",
    "    \"corrEps\": 1e-4,\n",
    "    \"train\": 0.001,\n",
    "    \"valid\": 0.001,\n",
    "    \"test\": 0.998\n",
    "}\n",
    "\n",
    "save_dir = \"benchmark_experiment_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running osqp\n",
      "10000\n",
      "running osqp\n",
      "10000\n",
      "running osqp\n",
      "10000\n",
      "running osqp\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "original_data = create_QP_dataset(num_var, num_ineq, num_eq, num_examples)\n",
    "varying_cm_row_data = create_varying_G_dataset(num_var, num_ineq, num_eq, num_examples, vary='row')\n",
    "varying_cm_column_data = create_varying_G_dataset(num_var, num_ineq, num_eq, num_examples, vary='column')\n",
    "varying_cm_random_data = create_varying_G_dataset(num_var, num_ineq, num_eq, num_examples, vary='random')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dim: 50\n",
      "Y dim: 100\n",
      "Size of mu: 50\n",
      "Size of lambda: 50\n",
      "----------------------------------------\n",
      "Epoch 0 done. Time taken: 775.1512258052826. Rho: 0.5. Primal LR: 0.0001, Dual LR: 6.361854860638712e-05\n",
      "Validation set evaluate:\n",
      "obj_val_mean: -16.458329635287434, val_loss_mean: -13.759737007095561, ineq_max: 0.7137197410857282, ineq_mean: 0.03306536300423989, eq_max: 0.6119022824228045, eq_mean: 0.17830756601771347\n",
      "Saving new model with obj: -14.48941995040052, eq_max: 0.06487787776394617, ineq_max: 0.16200696198847647, eq_mean: 0.022306579775646845, ineq_mean: 0.0039226063106737995\n",
      "Saving new model with obj: -14.440236794918773, eq_max: 0.06113034792477724, ineq_max: 0.1245159184839725, eq_mean: 0.021086430468376723, ineq_mean: 0.00294780348802249\n",
      "Saving new model with obj: -14.295682306696476, eq_max: 0.06203103653624711, ineq_max: 0.09875123152654931, eq_mean: 0.020167471459301704, ineq_mean: 0.002299832410359756\n",
      "Saving new model with obj: -14.299839324744182, eq_max: 0.06019748192579934, ineq_max: 0.09746828126429713, eq_mean: 0.019411526075692073, ineq_mean: 0.0022862979610700994\n",
      "Saving new model with obj: -14.203534187659692, eq_max: 0.07214845182139092, ineq_max: 0.0888257319500791, eq_mean: 0.02060873687419934, ineq_mean: 0.0021002225684434725\n",
      "----------------------------------------\n",
      "Epoch 1 done. Time taken: 739.3773081302643. Rho: 0.5. Primal LR: 8.26168623835587e-05, Dual LR: 4.04731972678324e-05\n",
      "Validation set evaluate:\n",
      "obj_val_mean: -7.807947137252838, val_loss_mean: -2.2869627374123125, ineq_max: 0.6396985859785828, ineq_mean: 0.0244954561015269, eq_max: 0.16808320351880474, eq_mean: 0.056326426399287984\n",
      "Saving new model with obj: -12.619963414139768, eq_max: 0.024091900901793188, ineq_max: 0.07653154526702508, eq_mean: 0.008144950631839325, ineq_mean: 0.002336831851304634\n",
      "Saving new model with obj: -12.861868346732269, eq_max: 0.024003238737335758, ineq_max: 0.07205782512043218, eq_mean: 0.00779542530667091, ineq_mean: 0.002139038069760108\n",
      "Saving new model with obj: -13.354093226397268, eq_max: 0.024404529004443412, ineq_max: 0.07775667464531116, eq_mean: 0.007783537071647716, ineq_mean: 0.0023029206705717613\n",
      "----------------------------------------\n",
      "Epoch 2 done. Time taken: 767.0393810272217. Rho: 5.0. Primal LR: 5.2559648752556236e-05, Dual LR: 2.549097606963093e-05\n",
      "Validation set evaluate:\n",
      "obj_val_mean: -13.001733747206865, val_loss_mean: -12.524421400247718, ineq_max: 0.17885237030085926, ineq_mean: 0.0047671286834090896, eq_max: 0.01260029995902283, eq_mean: 0.004375496532056278\n",
      "Saving new model with obj: -14.418273752114555, eq_max: 0.013662643226714287, ineq_max: 0.09991177553847552, eq_mean: 0.004523494402423289, ineq_mean: 0.0026129614534247682\n",
      "Saving new model with obj: -14.441717253847584, eq_max: 0.015127081571213086, ineq_max: 0.10358058524775098, eq_mean: 0.004905295769813241, ineq_mean: 0.0027308692241742325\n",
      "Saving new model with obj: -14.450889416376542, eq_max: 0.016129644404657747, ineq_max: 0.10590518436777846, eq_mean: 0.004959903819730272, ineq_mean: 0.002805713081773792\n",
      "Saving new model with obj: -14.438006636474743, eq_max: 0.014217601725744749, ineq_max: 0.09778808826081745, eq_mean: 0.004841732898462702, ineq_mean: 0.002569115643046826\n",
      "Saving new model with obj: -14.439751559953812, eq_max: 0.013463806576962615, ineq_max: 0.09974072306136741, eq_mean: 0.004620285381786991, ineq_mean: 0.0026542173689186347\n",
      "Saving new model with obj: -14.457754046404364, eq_max: 0.013708059550334703, ineq_max: 0.10464102887104444, eq_mean: 0.004758543043555481, ineq_mean: 0.0027948832658835827\n",
      "Saving new model with obj: -14.459089549375712, eq_max: 0.015677646369179964, ineq_max: 0.10624312518842285, eq_mean: 0.005154486044878762, ineq_mean: 0.002855342020760871\n",
      "Saving new model with obj: -14.461419282629194, eq_max: 0.013945326783371036, ineq_max: 0.10448792756886488, eq_mean: 0.004891699628393429, ineq_mean: 0.00279674885776715\n",
      "Saving new model with obj: -14.4536059191813, eq_max: 0.016741657159097124, ineq_max: 0.09887346994990415, eq_mean: 0.005016208458554932, ineq_mean: 0.002640912341535553\n",
      "Saving new model with obj: -14.469922496465879, eq_max: 0.015801143315433308, ineq_max: 0.10694291171245708, eq_mean: 0.005091584713317991, ineq_mean: 0.002884560011894161\n",
      "Saving new model with obj: -14.461126627011614, eq_max: 0.014372283588460221, ineq_max: 0.09835722155813287, eq_mean: 0.004859028404854167, ineq_mean: 0.0026422233393719515\n",
      "Saving new model with obj: -14.463599498274533, eq_max: 0.015407511201468669, ineq_max: 0.09981631199122863, eq_mean: 0.004969321670538935, ineq_mean: 0.0026762585469577807\n",
      "Saving new model with obj: -14.472846066901097, eq_max: 0.01439657629717836, ineq_max: 0.10326947115173965, eq_mean: 0.00469770213580213, ineq_mean: 0.0027951219408532554\n",
      "Saving new model with obj: -14.474935815076822, eq_max: 0.014159083581479081, ineq_max: 0.10094455553517377, eq_mean: 0.004786877883975646, ineq_mean: 0.0027497810348308224\n",
      "Saving new model with obj: -14.48263930674571, eq_max: 0.015189603229975564, ineq_max: 0.10781149861514813, eq_mean: 0.005151867255071853, ineq_mean: 0.0029508312775185655\n",
      "Saving new model with obj: -14.476286915120578, eq_max: 0.014459196376415953, ineq_max: 0.09963148110484953, eq_mean: 0.004924414500957058, ineq_mean: 0.002702476996440605\n",
      "Saving new model with obj: -14.476835352016245, eq_max: 0.015669760110231586, ineq_max: 0.09761092833006026, eq_mean: 0.005113632514487858, ineq_mean: 0.00266303737438793\n",
      "Saving new model with obj: -14.47775874545065, eq_max: 0.01483508409984899, ineq_max: 0.0988642803962944, eq_mean: 0.005057173701957209, ineq_mean: 0.002699072962063606\n",
      "Saving new model with obj: -14.482062705283374, eq_max: 0.014799958402905995, ineq_max: 0.09958602688072299, eq_mean: 0.00494446021832443, ineq_mean: 0.002758851709844404\n",
      "Saving new model with obj: -14.4834777400535, eq_max: 0.014578086189521642, ineq_max: 0.0996343989572936, eq_mean: 0.005044969748772882, ineq_mean: 0.0027401938854907664\n",
      "Saving new model with obj: -14.4834777400535, eq_max: 0.014578086189521642, ineq_max: 0.0996343989572936, eq_mean: 0.005044969748772882, ineq_mean: 0.0027401938854907664\n",
      "Saving new model with obj: -14.49314256701523, eq_max: 0.01582480126247177, ineq_max: 0.10467169836334239, eq_mean: 0.0054240238862670155, ineq_mean: 0.0028941965352725784\n",
      "Saving new model with obj: -14.49314256701523, eq_max: 0.01582480126247177, ineq_max: 0.10467169836334239, eq_mean: 0.0054240238862670155, ineq_mean: 0.0028941965352725784\n",
      "Saving new model with obj: -14.442667103240726, eq_max: 0.01784422032394944, ineq_max: 0.08764515778761452, eq_mean: 0.005825635162517331, ineq_mean: 0.0024405311152306277\n",
      "Saving new model with obj: -14.445922813371952, eq_max: 0.01708190405067217, ineq_max: 0.08718936354490696, eq_mean: 0.005668809499218959, ineq_mean: 0.002456057642446684\n",
      "Saving new model with obj: -14.446685633012544, eq_max: 0.01778143928483512, ineq_max: 0.08958608116923045, eq_mean: 0.006042338091737269, ineq_mean: 0.0025447962537256162\n",
      "----------------------------------------\n",
      "Epoch 3 done. Time taken: 729.1464829444885. Rho: 5.0. Primal LR: 3.31033088321014e-05, Dual LR: 1.6216989001100652e-05\n",
      "Validation set evaluate:\n",
      "obj_val_mean: -8.429110315989574, val_loss_mean: 205.34666244039562, ineq_max: 1.0118489829699984, ineq_mean: 0.035330419980182486, eq_max: 0.015248357859507613, eq_mean: 0.004846573877963621\n",
      "----------------------------------------\n",
      "Epoch 4 done. Time taken: 722.079381942749. Rho: 50.0. Primal LR: 2.1059844619672853e-05, Dual LR: 1.0213842899856094e-05\n",
      "Validation set evaluate:\n",
      "obj_val_mean: -10.021195598544397, val_loss_mean: 7.025610819726163, ineq_max: 0.17593250929583218, ineq_mean: 0.008539988591554325, eq_max: 0.005130926557492722, eq_mean: 0.0016833393158195945\n",
      "----------------------------------------\n",
      "Epoch 5 done. Time taken: 790.7209739685059. Rho: 50.0. Primal LR: 1.3397967485796171e-05, Dual LR: 6.497898609824964e-06\n",
      "Validation set evaluate:\n",
      "obj_val_mean: -13.959122382552739, val_loss_mean: -9.647921428548125, ineq_max: 0.13026106729578774, ineq_mean: 0.004892982657075066, eq_max: 0.004514204690114764, eq_mean: 0.00156746696934494\n",
      "----------------------------------------\n",
      "Epoch 6 done. Time taken: 779.4417328834534. Rho: 50.0. Primal LR: 8.438356532646986e-06, Dual LR: 4.0925300976303945e-06\n",
      "Validation set evaluate:\n",
      "obj_val_mean: -14.467662401232076, val_loss_mean: 7.175294300042081, ineq_max: 0.11932182954093862, ineq_mean: 0.003531850084928026, eq_max: 0.003074604310335418, eq_mean: 0.0009700719611624969\n",
      "----------------------------------------\n",
      "Epoch 7 done. Time taken: 781.986261844635. Rho: 500.0. Primal LR: 5.368359952302261e-06, Dual LR: 2.6036082493920133e-06\n",
      "Validation set evaluate:\n",
      "obj_val_mean: -14.421846138393303, val_loss_mean: 0.5218692673276278, ineq_max: 0.09081860667148492, ineq_mean: 0.0026321112812657415, eq_max: 0.0013056998493968966, eq_mean: 0.0004322326522522284\n",
      "----------------------------------------\n",
      "Epoch 8 done. Time taken: 788.2063722610474. Rho: 500.0. Primal LR: 3.3811199587650214e-06, Dual LR: 1.6398140018627685e-06\n",
      "Validation set evaluate:\n",
      "obj_val_mean: -14.472639549740128, val_loss_mean: 150.35400154649813, ineq_max: 0.10572188188562945, ineq_mean: 0.0030312951235646353, eq_max: 0.0011311183777449711, eq_mean: 0.0003863496858782457\n",
      "----------------------------------------\n",
      "Epoch 9 done. Time taken: 759.3869128227234. Rho: 5000.0. Primal LR: 2.1510194444071802e-06, Dual LR: 1.043225867829407e-06\n",
      "Validation set evaluate:\n",
      "obj_val_mean: -14.473226660000494, val_loss_mean: 147.17765506825378, ineq_max: 0.10521744395000299, ineq_mean: 0.003005137137719725, eq_max: 0.0010268045988677831, eq_mean: 0.00034461323315866855\n",
      "----------------------------------------\n",
      "Test set evaluate:\n",
      "obj_val_mean: -14.476559665198877, val_loss_mean: 151.38129322951286, ineq_max: 0.09821015050420254, ineq_mean: 0.0027327821812460395, eq_max: 0.0037302242881419824, eq_mean: 0.0011890202951488785\n",
      "X dim: 50\n",
      "Y dim: 100\n",
      "Size of mu: 50\n",
      "Size of lambda: 50\n",
      "----------------------------------------\n",
      "Epoch 0 done. Time taken: 779.1899259090424. Rho: 0.5. Primal LR: 0.0001, Dual LR: 6.361854860638712e-05\n",
      "Validation set evaluate:\n",
      "obj_val_mean: -16.80319288860789, val_loss_mean: -14.26750874292627, ineq_max: 0.7769205747000602, ineq_mean: 0.030957368517348146, eq_max: 0.6315568549402011, eq_mean: 0.16976616091394836\n",
      "Saving new model with obj: -14.888973456310785, eq_max: 0.0784865607220427, ineq_max: 0.17344981394037234, eq_mean: 0.025655626316021793, ineq_mean: 0.00402291430145162\n",
      "----------------------------------------\n",
      "Epoch 1 done. Time taken: 754.5581560134888. Rho: 0.5. Primal LR: 8.097278682212587e-05, Dual LR: 4.04731972678324e-05\n",
      "Validation set evaluate:\n",
      "obj_val_mean: -12.197206864348447, val_loss_mean: -5.917941780127338, ineq_max: 0.6860267623303995, ineq_mean: 0.02742381158355313, eq_max: 0.1526050455314475, eq_mean: 0.048774420053740004\n",
      "----------------------------------------\n",
      "Epoch 2 done. Time taken: 779.0253717899323. Rho: 5.0. Primal LR: 5.1513711742380364e-05, Dual LR: 2.549097606963093e-05\n",
      "Validation set evaluate:\n",
      "obj_val_mean: -14.68824928606088, val_loss_mean: -13.421104543884184, ineq_max: 0.3462448629493961, ineq_mean: 0.008980535349097171, eq_max: 0.01490864971170038, eq_mean: 0.004271908542568571\n",
      "Saving new model with obj: -14.934739641913678, eq_max: 0.012962757467790626, ineq_max: 0.16632956319918116, eq_mean: 0.004009078186541472, ineq_mean: 0.0037732721091926873\n",
      "Saving new model with obj: -14.9113476094376, eq_max: 0.012494215135223457, ineq_max: 0.12943853699602992, eq_mean: 0.003961581751319068, ineq_mean: 0.0028919073266044652\n",
      "Saving new model with obj: -14.833463499416903, eq_max: 0.012944210667305072, ineq_max: 0.098019105675561, eq_mean: 0.0038628086153082225, ineq_mean: 0.0022109742224966818\n",
      "----------------------------------------\n",
      "Epoch 3 done. Time taken: 779.7303218841553. Rho: 5.0. Primal LR: 3.277227574378038e-05, Dual LR: 1.6216989001100652e-05\n",
      "Validation set evaluate:\n",
      "obj_val_mean: -14.075118408507606, val_loss_mean: -5.791467680516752, ineq_max: 0.2206288287251525, ineq_mean: 0.006673411569890018, eq_max: 0.013402877574865782, eq_mean: 0.004150648550714635\n",
      "Saving new model with obj: -14.540090272654632, eq_max: 0.010433260853251008, ineq_max: 0.0843771196472293, eq_mean: 0.0032683988245498234, ineq_mean: 0.002138133974804266\n",
      "Saving new model with obj: -14.545643397996397, eq_max: 0.010045898791561777, ineq_max: 0.07307230546347258, eq_mean: 0.0031667764153580657, ineq_mean: 0.0017964009669487913\n",
      "Saving new model with obj: -14.545643397996397, eq_max: 0.010045898791561777, ineq_max: 0.07307230546347258, eq_mean: 0.0031667764153580657, ineq_mean: 0.0017964009669487913\n",
      "Saving new model with obj: -14.590780893888251, eq_max: 0.009969483462766313, ineq_max: 0.08066879024303372, eq_mean: 0.003110075175908269, ineq_mean: 0.001979078003420773\n",
      "Saving new model with obj: -14.604518673558873, eq_max: 0.009783256650093325, ineq_max: 0.07640805644964248, eq_mean: 0.0030953653278461284, ineq_mean: 0.0018312775539402824\n",
      "Saving new model with obj: -14.604518673558873, eq_max: 0.009783256650093325, ineq_max: 0.07640805644964248, eq_mean: 0.0030953653278461284, ineq_mean: 0.0018312775539402824\n",
      "Saving new model with obj: -14.630200893378376, eq_max: 0.009498379095375384, ineq_max: 0.07868355432532317, eq_mean: 0.0029831461737618464, ineq_mean: 0.001870099012436535\n",
      "Saving new model with obj: -14.630200893378376, eq_max: 0.009498379095375384, ineq_max: 0.07868355432532317, eq_mean: 0.0029831461737618464, ineq_mean: 0.001870099012436535\n",
      "Saving new model with obj: -14.649991054827822, eq_max: 0.009120561069740046, ineq_max: 0.08012090722291794, eq_mean: 0.0028632279769164807, ineq_mean: 0.0018896400689170235\n",
      "Saving new model with obj: -14.674770255273272, eq_max: 0.009342544981370075, ineq_max: 0.08520605161792937, eq_mean: 0.002909622673950832, ineq_mean: 0.0020172924197150123\n",
      "Saving new model with obj: -14.678132860579048, eq_max: 0.009377981274523264, ineq_max: 0.08248043113703651, eq_mean: 0.0029251509331206034, ineq_mean: 0.0019286312019481302\n",
      "Saving new model with obj: -14.700018572234425, eq_max: 0.008835067607623545, ineq_max: 0.08762517617487042, eq_mean: 0.0028138764983328367, ineq_mean: 0.0020520275580029512\n",
      "Saving new model with obj: -14.715121507301381, eq_max: 0.008672834786313118, ineq_max: 0.0887796705221636, eq_mean: 0.002768483673840435, ineq_mean: 0.0020711873027671216\n",
      "Saving new model with obj: -14.719358401093762, eq_max: 0.00864889375182509, ineq_max: 0.08908333446661817, eq_mean: 0.002730561741403382, ineq_mean: 0.002073210692433906\n",
      "Saving new model with obj: -14.725025790721338, eq_max: 0.008835487093559163, ineq_max: 0.08970898346783215, eq_mean: 0.0026842758675681053, ineq_mean: 0.0020834222864367148\n",
      "Saving new model with obj: -14.738599282255477, eq_max: 0.008498684583454406, ineq_max: 0.08971163057890198, eq_mean: 0.0026803259830913287, ineq_mean: 0.0020608225120935155\n",
      "Saving new model with obj: -14.935874527824927, eq_max: 0.006886219625702566, ineq_max: 0.18068882758236504, eq_mean: 0.00228286464811598, ineq_mean: 0.004153407028015489\n",
      "Saving new model with obj: -14.937286265484218, eq_max: 0.007228873779092474, ineq_max: 0.18199130986116377, eq_mean: 0.002201210056446653, ineq_mean: 0.00418105941487263\n",
      "Saving new model with obj: -14.939554981381175, eq_max: 0.006912897900875006, ineq_max: 0.1847132173564117, eq_mean: 0.00218316797167226, ineq_mean: 0.004236636954019979\n",
      "Saving new model with obj: -14.941321910504577, eq_max: 0.006948769676839704, ineq_max: 0.18460474116114936, eq_mean: 0.0021829376729564655, ineq_mean: 0.004240891115176656\n",
      "Saving new model with obj: -14.942947671402806, eq_max: 0.006929759674799634, ineq_max: 0.18683473570192052, eq_mean: 0.0021539418958051596, ineq_mean: 0.004280239703082243\n",
      "Saving new model with obj: -14.943491256551656, eq_max: 0.006942317138617492, ineq_max: 0.18717104307252813, eq_mean: 0.0021999613861189795, ineq_mean: 0.004291216528984947\n",
      "Saving new model with obj: -14.945059065977661, eq_max: 0.007031260543209034, ineq_max: 0.1885013501852057, eq_mean: 0.0021814584881100813, ineq_mean: 0.00432898138004895\n",
      "Saving new model with obj: -14.945747967173109, eq_max: 0.006952386636245588, ineq_max: 0.1892637290853567, eq_mean: 0.002199011347170762, ineq_mean: 0.004340026130454487\n",
      "Saving new model with obj: -14.947322459391195, eq_max: 0.007134140419627345, ineq_max: 0.19101197056843075, eq_mean: 0.0022082242567302165, ineq_mean: 0.004386504051201323\n",
      "Saving new model with obj: -14.951328375827169, eq_max: 0.006943750569191397, ineq_max: 0.1943708620117697, eq_mean: 0.0022104026847175945, ineq_mean: 0.0044654802094938354\n",
      "Saving new model with obj: -14.952641548568637, eq_max: 0.0069177209111554935, ineq_max: 0.19522116719703037, eq_mean: 0.0021823235790907054, ineq_mean: 0.004462138836349624\n",
      "Saving new model with obj: -14.954169796927864, eq_max: 0.007043781474991303, ineq_max: 0.19725802273150747, eq_mean: 0.00221861388507089, ineq_mean: 0.004515735068776088\n",
      "Saving new model with obj: -14.954504734414911, eq_max: 0.006899298350018687, ineq_max: 0.19671100814283876, eq_mean: 0.0021471373775850703, ineq_mean: 0.00450001521977142\n",
      "Saving new model with obj: -14.955168605048419, eq_max: 0.0065328376000442995, ineq_max: 0.19767264590141684, eq_mean: 0.002096407984791419, ineq_mean: 0.004530751056323211\n",
      "Saving new model with obj: -14.956130905812286, eq_max: 0.006815433294679656, ineq_max: 0.1985434029782255, eq_mean: 0.0021110189027242804, ineq_mean: 0.004553704601805513\n",
      "Saving new model with obj: -14.957166284055115, eq_max: 0.006767572574068522, ineq_max: 0.19901647682655063, eq_mean: 0.0022141685888010477, ineq_mean: 0.004560903833137583\n",
      "----------------------------------------\n",
      "Epoch 4 done. Time taken: 3869.9710369110107. Rho: 50.0. Primal LR: 2.0640753711741364e-05, Dual LR: 1.0213842899856094e-05\n",
      "Validation set evaluate:\n",
      "obj_val_mean: -15.026099547748741, val_loss_mean: -7.098422944408911, ineq_max: 0.2700878703287187, ineq_mean: 0.0062084032360433476, eq_max: 0.005796386866769554, eq_mean: 0.0018084033716349575\n",
      "----------------------------------------\n",
      "Epoch 5 done. Time taken: 795.7017748355865. Rho: 50.0. Primal LR: 1.3131347932828827e-05, Dual LR: 6.497898609824964e-06\n",
      "Validation set evaluate:\n",
      "obj_val_mean: -14.896096210524588, val_loss_mean: 55.36339346625826, ineq_max: 0.21603676513270587, ineq_mean: 0.0050237920892342545, eq_max: 0.006126715717348728, eq_mean: 0.0018783053319197025\n",
      "----------------------------------------\n",
      "Epoch 6 done. Time taken: 762.8992671966553. Rho: 500.0. Primal LR: 8.270433237647311e-06, Dual LR: 4.0925300976303945e-06\n",
      "Validation set evaluate:\n",
      "obj_val_mean: -14.655023861479489, val_loss_mean: 70.44304299282481, ineq_max: 0.27914379690843405, ineq_mean: 0.006294711660475634, eq_max: 0.004507715345124556, eq_mean: 0.0014370476297835034\n",
      "----------------------------------------\n",
      "Epoch 7 done. Time taken: 779.1265079975128. Rho: 500.0. Primal LR: 5.261529589251446e-06, Dual LR: 2.6036082493920133e-06\n",
      "Validation set evaluate:\n",
      "obj_val_mean: -15.057798794007484, val_loss_mean: 903.170385943172, ineq_max: 0.2937187116715907, ineq_mean: 0.006782663257165352, eq_max: 0.004342547562815132, eq_mean: 0.0013862216051368681\n",
      "----------------------------------------\n",
      "Epoch 8 done. Time taken: 769.5528919696808. Rho: 5000.0. Primal LR: 3.3138356715855973e-06, Dual LR: 1.6398140018627685e-06\n",
      "Validation set evaluate:\n",
      "obj_val_mean: -14.97980305539476, val_loss_mean: 772.4284558015183, ineq_max: 0.2494103478688046, ineq_mean: 0.0056433973203437425, eq_max: 0.0040982590129697676, eq_mean: 0.0012956539137306802\n",
      "----------------------------------------\n",
      "Epoch 9 done. Time taken: 783.0406107902527. Rho: 5000.0. Primal LR: 2.1082141574634774e-06, Dual LR: 1.043225867829407e-06\n",
      "Validation set evaluate:\n",
      "obj_val_mean: -15.053018092047393, val_loss_mean: 919.8845693664429, ineq_max: 0.29899787860652555, ineq_mean: 0.006911188170000386, eq_max: 0.004143647631875525, eq_mean: 0.0013094617986623535\n",
      "----------------------------------------\n",
      "Test set evaluate:\n",
      "obj_val_mean: -15.005919394313844, val_loss_mean: 894.3032503310559, ineq_max: 0.2809214888022104, ineq_mean: 0.006558387199423204, eq_max: 0.004627365502923894, eq_mean: 0.0014984399829319297\n"
     ]
    }
   ],
   "source": [
    "# original_trainer = PrimalDualTrainer(original_data, args, os.path.join(save_dir, 'original'))\n",
    "# original_primal_net, original_dual_net, _ = original_trainer.train_PDL()\n",
    "\n",
    "max_violation_save_thresholds = [0.07, 0.08, 0.09, 0.1, 0.15, 0.2]\n",
    "\n",
    "# row_trainer = PrimalDualTrainer(varying_cm_row_data, args, os.path.join(save_dir, 'row'))\n",
    "# row_primal_net, row_dual_net, _ = row_trainer.train_PDL(max_violation_save_thresholds)\n",
    "\n",
    "column_trainer = PrimalDualTrainer(varying_cm_column_data, args, os.path.join(save_dir, 'column'))\n",
    "col_primal_net, col_dual_net, _ = column_trainer.train_PDL(max_violation_save_thresholds)\n",
    "\n",
    "random_trainer = PrimalDualTrainer(varying_cm_random_data, args, os.path.join(save_dir, 'random'))\n",
    "random_primal_net, random_dual_net, _ = random_trainer.train_PDL(max_violation_save_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.03574072137141 -14.159263032697682 0.05836505624044085 0.00017314761295659365 4.273874887204891e-06 0.0013226164497767041 0.0004215035947090046\n",
      "-15.571241360476339 -15.346537498605803 0.014434519866945456 0.029326313612115122 0.0008174214563382847 0.0019247002016841645 0.0005937570470690621\n",
      "-15.353276156344776 -14.371511671264603 0.06354776121051121 0.02001070985463688 0.0004715649132288072 0.0008491038598132157 0.00028472452067880653\n",
      "-15.609351985154028 -14.481196481463954 0.07228137394973655 0.05245784645211027 0.0012259314204511058 0.0015708231500230776 0.0004784480383306505\n"
     ]
    }
   ],
   "source": [
    "for model, data in [(original_primal_net, original_data), (row_primal_net, varying_cm_row_data), (col_primal_net, varying_cm_column_data), (random_primal_net, varying_cm_random_data)]:\n",
    "    Y_pred = model(data.X)\n",
    "    obj_known = data.obj_fn(data.Y).detach().cpu().numpy()\n",
    "    obj_pred = data.obj_fn(Y_pred).detach().cpu().numpy()\n",
    "    obj_gap = ((obj_known - obj_pred)/obj_known).mean()\n",
    "\n",
    "    ineq_dist = data.ineq_dist(data.X, Y_pred)\n",
    "    eq_resid = data.eq_resid(data.X, Y_pred)\n",
    "\n",
    "    ineq_max_vals = torch.max(ineq_dist, dim=1)[0].detach().cpu().numpy().mean()\n",
    "    ineq_mean_vals = torch.mean(ineq_dist, dim=1).detach().cpu().numpy().mean()\n",
    "    eq_max_vals = torch.max(torch.abs(eq_resid), dim=1)[0].detach().cpu().numpy().mean()\n",
    "    eq_mean_vals = torch.mean(torch.abs(eq_resid), dim=1).detach().cpu().numpy().mean()\n",
    "    \n",
    "    print(obj_known.mean(), obj_pred.mean(), obj_gap, ineq_max_vals, ineq_mean_vals, eq_max_vals, eq_mean_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': {}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"benchmark_experiment_output/original/stats.dict\", \"rb\") as f:\n",
    "    stats = pickle.load(f)\n",
    "    print(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
