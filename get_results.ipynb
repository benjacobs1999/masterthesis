{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimalNet(nn.Module):\n",
    "    def __init__(self, data, hidden_sizes):\n",
    "        super().__init__()\n",
    "        self._data = data\n",
    "        self._hidden_sizes = hidden_sizes\n",
    "        \n",
    "        # Create the list of layer sizes\n",
    "        layer_sizes = [data.xdim] + self._hidden_sizes + [data.ydim]\n",
    "        layers = []\n",
    "\n",
    "        # Create layers dynamically based on the provided hidden_sizes\n",
    "        for in_size, out_size in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "            layers.append(nn.Linear(in_size, out_size))\n",
    "            if out_size != data.ydim:  # Add ReLU activation for hidden layers only\n",
    "                layers.append(nn.ReLU())\n",
    "\n",
    "        # Initialize all layers\n",
    "        for layer in layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.kaiming_normal_(layer.weight)\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class DualNet(nn.Module):\n",
    "    def __init__(self, data, hidden_sizes, mu_size, lamb_size):\n",
    "        super().__init__()\n",
    "        self._data = data\n",
    "        self._hidden_sizes = hidden_sizes\n",
    "        self._mu_size = mu_size\n",
    "        self._lamb_size = lamb_size\n",
    "\n",
    "        # Create the list of layer sizes\n",
    "        layer_sizes = [data.xdim] + self._hidden_sizes\n",
    "        # layer_sizes = [2*data.xdim + 1000] + self._hidden_sizes\n",
    "        layers = []\n",
    "        # Create layers dynamically based on the provided hidden_sizes\n",
    "        for in_size, out_size in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "            layers.append(nn.Linear(in_size, out_size))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        # Initialize all layers\n",
    "        for layer in layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.kaiming_normal_(layer.weight)\n",
    "\n",
    "        # Add the output layer\n",
    "        self.out_layer = nn.Linear(self._hidden_sizes[-1], self._mu_size + self._lamb_size)\n",
    "        nn.init.zeros_(self.out_layer.weight)  # Initialize output layer weights to 0\n",
    "        nn.init.zeros_(self.out_layer.bias)    # Initialize output layer biases to 0\n",
    "        layers.append(self.out_layer)\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        out_mu = out[:, :self._mu_size]\n",
    "        out_lamb = out[:, self._mu_size:]\n",
    "        return out_mu, out_lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"QP_data/Dual_QP_simple_dataset_var100_ineq50_eq50_ex10000\", 'rb') as f:\n",
    "    original_data = pickle.load(f)\n",
    "\n",
    "with open(\"QP_data/Varying_G_type=row_dataset_var100_ineq50_eq50_ex10000\", 'rb') as f:\n",
    "    varying_cm_row_data = pickle.load(f)\n",
    "\n",
    "with open(\"QP_data/Varying_G_type=column_dataset_var100_ineq50_eq50_ex10000\", 'rb') as f:\n",
    "    varying_cm_column_data = pickle.load(f)\n",
    "\n",
    "with open(\"QP_data/Varying_G_type=random_dataset_var100_ineq50_eq50_ex10000\", 'rb') as f:\n",
    "    varying_cm_random_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_primal_net = PrimalNet(original_data, [500, 500])\n",
    "row_primal_net = PrimalNet(varying_cm_row_data, [500, 500])\n",
    "col_primal_net = PrimalNet(varying_cm_column_data, [500, 500])\n",
    "random_primal_net = PrimalNet(varying_cm_random_data, [500, 500])\n",
    "# Load state dictionaries.\n",
    "original_primal_state_dict = torch.load(\"benchmark_experiment_output/original/0.006_primal_net.dict\", weights_only=True)\n",
    "row_primal_state_dict = torch.load(\"benchmark_experiment_output/row/0.15_primal_net.dict\", weights_only=True)\n",
    "col_primal_state_dict = torch.load(\"benchmark_experiment_output/column/0.08_primal_net.dict\", weights_only=True)\n",
    "random_primal_state_dict = torch.load(\"benchmark_experiment_output/random/0.08_primal_net.dict\", weights_only=True)\n",
    "\n",
    "# Load the state dictionaries into the networks.\n",
    "original_primal_net.load_state_dict(original_primal_state_dict)\n",
    "row_primal_net.load_state_dict(row_primal_state_dict)\n",
    "col_primal_net.load_state_dict(col_primal_state_dict)\n",
    "random_primal_net.load_state_dict(random_primal_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10000,) (1000,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m obj_known \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mobj_fn(data\u001b[38;5;241m.\u001b[39mY)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      5\u001b[0m obj_pred \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mobj_fn(Y_pred)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m----> 6\u001b[0m obj_gap \u001b[38;5;241m=\u001b[39m ((\u001b[43mobj_known\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobj_pred\u001b[49m)\u001b[38;5;241m/\u001b[39mobj_known)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      8\u001b[0m ineq_dist \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mineq_dist(X, Y_pred)\n\u001b[1;32m      9\u001b[0m eq_resid \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39meq_resid(X, Y_pred)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10000,) (1000,) "
     ]
    }
   ],
   "source": [
    "for model, data in [(original_primal_net, original_data), (row_primal_net, varying_cm_row_data), (col_primal_net, varying_cm_column_data), (random_primal_net, varying_cm_random_data)]:\n",
    "    X = data.X[data.test_indices]\n",
    "    Y_pred = model(X)\n",
    "    obj_known = data.obj_fn(data.Y[data.test_indices]).detach().cpu().numpy()\n",
    "    obj_pred = data.obj_fn(Y_pred).detach().cpu().numpy()\n",
    "    obj_gap = ((obj_known - obj_pred)/obj_known).mean()\n",
    "\n",
    "    ineq_dist = data.ineq_dist(X, Y_pred)\n",
    "    eq_resid = data.eq_resid(X, Y_pred)\n",
    "\n",
    "    ineq_max_vals = torch.max(ineq_dist, dim=1)[0].detach().cpu().numpy().mean()\n",
    "    ineq_mean_vals = torch.mean(ineq_dist, dim=1).detach().cpu().numpy().mean()\n",
    "    eq_max_vals = torch.max(torch.abs(eq_resid), dim=1)[0].detach().cpu().numpy().mean()\n",
    "    eq_mean_vals = torch.mean(torch.abs(eq_resid), dim=1).detach().cpu().numpy().mean()\n",
    "    \n",
    "    print(obj_known.mean(), obj_pred.mean(), obj_gap, ineq_max_vals, ineq_mean_vals, eq_max_vals, eq_mean_vals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
