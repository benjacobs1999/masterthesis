{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import scipy\n",
    "import torch\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "from gep_problem import GEPProblem\n",
    "from gep_config_parser import *\n",
    "from gep_primal_dual_main_refactored import prep_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing the config file\n"
     ]
    }
   ],
   "source": [
    "CONFIG_FILE_NAME        = \"config.toml\"\n",
    "VISUALIZATION_FILE_NAME = \"visualization.toml\"\n",
    "SAMPLE_DURATION = 24\n",
    "# SAMPLE_DURATION = 120\n",
    "\n",
    "## Step 1: parse the input data\n",
    "print(\"Parsing the config file\")\n",
    "\n",
    "data = parse_config(CONFIG_FILE_NAME)\n",
    "experiment = data[\"experiment\"]\n",
    "outputs_config = data[\"outputs_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrangling the input data\n",
      "Creating problem instance\n",
      "Populating ineq constraints\n",
      "Populating eq constraints\n",
      "Creating objective coefficients\n",
      "Creating input for NN: X\n",
      "Size of train set: 0\n",
      "Size of val set: 0\n",
      "Size of test set: 365\n"
     ]
    }
   ],
   "source": [
    "experiment_instance = experiment[\"experiments\"][0]\n",
    "data = prep_data(experiment_instance, train=0.002, valid=0.002, test=0.996, sample_duration=SAMPLE_DURATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! My ALM functions:\n",
    "def obj_fn_ALM(Yi):\n",
    "    # Objective function evaluated for Y\n",
    "    # return (\n",
    "    #     0.5 * Yi.T @ self.Q_np @ Yi + self.p_np.T @ Yi\n",
    "    # )  # Ensure Q_np: (100, 100), p_np: (100,)\n",
    "\n",
    "    return data.obj_fn(torch.tensor(Yi).unsqueeze(0)).squeeze().numpy()\n",
    "\n",
    "def eq_resid_ALM(Yi, eq_cm, eq_rhs):\n",
    "    # Equality residuals (X - A * Y)\n",
    "    # return Xi - self.A_np @ Yi  # A_np: (50, 100), X: (50,), Y: (100,)\n",
    "    Yi = torch.tensor(Yi).unsqueeze(0)\n",
    "    return data.eq_resid(Yi, eq_cm, eq_rhs).squeeze().numpy()\n",
    "\n",
    "def ineq_resid_ALM(Yi, ineq_cm, ineq_rhs):\n",
    "    # Inequality residuals (G * Y - h)\n",
    "    # return self.G_np @ Yi - self.h_np  # G_np: (50, 100), h_np: (50,)\n",
    "    Yi = torch.tensor(Yi).unsqueeze(0)\n",
    "    return data.ineq_resid(Yi, ineq_cm, ineq_rhs).squeeze().numpy()\n",
    "\n",
    "def L_rho(Yi, eq_cm, ineq_cm, eq_rhs, ineq_rhs, m, l, rho):\n",
    "    # Compute inequality and equality residuals\n",
    "    ineq_resid = ineq_resid_ALM(Yi, ineq_cm, ineq_rhs)# Should be (50,)\n",
    "    eq_resid = eq_resid_ALM(Yi, eq_cm, eq_rhs)  # Should be (50,)\n",
    "\n",
    "    # Augmented Lagrangian computation\n",
    "    return (\n",
    "        obj_fn_ALM(Yi)\n",
    "        + m.T @ ineq_resid  # Linear term for inequality\n",
    "        + l.T @ eq_resid  # Linear term for equality\n",
    "        + (rho / 2)\n",
    "        * (\n",
    "            np.linalg.norm(np.maximum(ineq_resid, 0), 2) ** 2\n",
    "            + np.linalg.norm(eq_resid, 2) ** 2\n",
    "        )\n",
    "    )\n",
    "\n",
    "def solve_instance(i, Xi, eq_cm, ineq_cm, eq_rhs, ineq_rhs, tol=1e-4):\n",
    "        \"\"\"\n",
    "        Solve ALM for a single instance.\n",
    "        \"\"\"\n",
    "        mu_k = np.zeros(data.nineq)  # (50,)\n",
    "        lamb_k = np.zeros(data.neq)  # (50,)\n",
    "        rho = 1\n",
    "        tau = 0.5\n",
    "        alpha = 10\n",
    "        K = 20\n",
    "\n",
    "        epsilon = 1e-4\n",
    "        rho_max = 5000\n",
    "        # print(f\"sample {i+1} of {833}\")\n",
    "        start_time = time.time()\n",
    "        # Initial primal point\n",
    "        Yi = np.random.uniform(-1, 1, data.ydim)  # Shape (100,)\n",
    "\n",
    "        for k in range(K):\n",
    "            print(f\"{k+1}/{K}\")\n",
    "            # Minimize L_rho for current `mu_k` and `lambda_k`\n",
    "            res = scipy.optimize.minimize(\n",
    "                fun=L_rho,\n",
    "                x0=Yi,\n",
    "                args=(eq_cm, ineq_cm, eq_rhs, ineq_rhs, mu_k, lamb_k, rho),\n",
    "                tol=tol,\n",
    "                method=\"CG\",\n",
    "                scaling=True,\n",
    "            )\n",
    "            y_k = res.x  # Solution for this iteration, shape (100,)\n",
    "\n",
    "            eq_resid = eq_resid_ALM(y_k, eq_cm, eq_rhs)\n",
    "            ineq_resid = ineq_resid_ALM(y_k, ineq_cm, ineq_rhs)\n",
    "\n",
    "            # Update dual variables using y_k\n",
    "            mu_k = np.maximum(mu_k + rho * ineq_resid, 0)\n",
    "            lamb_k = lamb_k + rho * eq_resid\n",
    "\n",
    "            # Calculate v_k to check for convergence\n",
    "            inf_norm_eq_resid = np.max(np.abs(eq_resid))\n",
    "            sigma = np.maximum(ineq_resid, -mu_k / rho)\n",
    "            inf_norm_sigma = np.max(np.abs(sigma))\n",
    "            v_k = max(inf_norm_eq_resid, inf_norm_sigma)\n",
    "\n",
    "            if v_k < epsilon:\n",
    "                print(f\"Converged for instance {i+1} at iteration {k+1}\")\n",
    "                break\n",
    "\n",
    "            if k >= 1 and v_k > (tau * prev_v_k):\n",
    "                rho = min(alpha * rho, rho_max)\n",
    "            prev_v_k = v_k\n",
    "            Yi = y_k  # Use the current solution as the initial guess for the next iteration\n",
    "            print(f\"obj_fn:{obj_fn_ALM(Yi)}\")\n",
    "            print(f\"dual obj_fn:{(data.dual_obj_fn(eq_rhs, ineq_rhs, torch.tensor(mu_k.tolist()).unsqueeze(0), torch.tensor(lamb_k.tolist()).unsqueeze(0))).item()}\")\n",
    "            print(f\"v_k:{v_k}\")\n",
    "\n",
    "            rhs_eq = eq_rhs\n",
    "            rhs_ineq = ineq_rhs\n",
    "\n",
    "            print(f\"mu mean:{mu_k.mean()}\")\n",
    "\n",
    "            print(f\"lamb mean:{lamb_k.mean()}\")\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(obj_fn_ALM(Yi))\n",
    "        return y_k, mu_k, lamb_k, end_time - start_time\n",
    "\n",
    "def ALM_solve(X, tol=1e-4):\n",
    "    X_np = X.detach().cpu().numpy() if hasattr(X, \"detach\") else X\n",
    "\n",
    "    # Parallel processing\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        results = list(executor.map(solve_instance, range(len(X_np)), X_np))\n",
    "\n",
    "    # Unpack results\n",
    "    Y, times = zip(*results)\n",
    "    total_time = sum(times)\n",
    "    parallel_time = total_time / len(X_np)\n",
    "    sols = np.array(Y)\n",
    "\n",
    "    return sols, total_time, parallel_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/20\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "minimize() got an unexpected keyword argument 'scaling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m eq_rhs \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39meq_rhs[:\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      5\u001b[0m ineq_rhs \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mineq_rhs[:\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m y, mu, lamb, time_taken \u001b[38;5;241m=\u001b[39m \u001b[43msolve_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meq_cm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mineq_cm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meq_rhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mineq_rhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 60\u001b[0m, in \u001b[0;36msolve_instance\u001b[0;34m(i, Xi, eq_cm, ineq_cm, eq_rhs, ineq_rhs, tol)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mK\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Minimize L_rho for current `mu_k` and `lambda_k`\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mL_rho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mYi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43meq_cm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mineq_cm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meq_rhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mineq_rhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamb_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCG\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m y_k \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mx  \u001b[38;5;66;03m# Solution for this iteration, shape (100,)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m eq_resid \u001b[38;5;241m=\u001b[39m eq_resid_ALM(y_k, eq_cm, eq_rhs)\n",
      "\u001b[0;31mTypeError\u001b[0m: minimize() got an unexpected keyword argument 'scaling'"
     ]
    }
   ],
   "source": [
    "X = data.trainX\n",
    "eq_cm = data.eq_cm[:1]\n",
    "ineq_cm = data.ineq_cm[:1]\n",
    "eq_rhs = data.eq_rhs[:1]\n",
    "ineq_rhs = data.ineq_rhs[:1]\n",
    "y, mu, lamb, time_taken = solve_instance(0, X, eq_cm, ineq_cm, eq_rhs, ineq_rhs, tol=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimality gap (%): 20.447602219037215\n",
      "0.23243173084665614\n",
      "0.017345356135724313\n",
      "0.0027242787257553878\n"
     ]
    }
   ],
   "source": [
    "OPTIMAL_OBJ = 8.18648032e+08 # First sample\n",
    "\n",
    "print(f\"Optimality gap (%): {abs(obj_fn_ALM(y) - OPTIMAL_OBJ) / OPTIMAL_OBJ * 100}\")\n",
    "# print(mu)\n",
    "# print(lamb)\n",
    "\n",
    "g = ineq_resid_ALM(y, ineq_cm, ineq_rhs)\n",
    "h = eq_resid_ALM(y, eq_cm, eq_rhs)\n",
    "\n",
    "# print(g > 0)\n",
    "print(g[(g>0)].max())\n",
    "print(g[(g>0)].mean())\n",
    "print(np.abs(h).mean())\n",
    "\n",
    "# print(g)\n",
    "# print(mu[g < 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
