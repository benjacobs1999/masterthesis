{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n",
      "Parsing the config file\n",
      "Initializing the solver\n",
      "Using Gurobi\n",
      "Parsing the config file\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import scipy\n",
    "import torch\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "from old_gep_code.gep_problem import GEPProblem\n",
    "from gep_config_parser import *\n",
    "from old_gep_code.gep_primal_dual_main import prep_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing the config file\n"
     ]
    }
   ],
   "source": [
    "CONFIG_FILE_NAME        = \"config.toml\"\n",
    "VISUALIZATION_FILE_NAME = \"visualization.toml\"\n",
    "SAMPLE_DURATION = 12\n",
    "# SAMPLE_DURATION = 120\n",
    "\n",
    "## Step 1: parse the input data\n",
    "print(\"Parsing the config file\")\n",
    "\n",
    "data = parse_config(CONFIG_FILE_NAME)\n",
    "experiment = data[\"experiment\"]\n",
    "outputs_config = data[\"outputs_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrangling the input data\n",
      "Creating problem instance\n",
      "Size of train set: 0\n",
      "Size of val set: 0\n",
      "Size of test set: 365\n",
      "Size of mu: 573\n",
      "Size of lambda: 72\n",
      "Number of variables (size of y): 144\n",
      "Number of inputs (size of X): 219\n"
     ]
    }
   ],
   "source": [
    "experiment_instance = experiment[\"experiments\"][0]\n",
    "data = prep_data(experiment_instance, shuffle=False, train=0.002, valid=0.002, test=0.996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! My ALM functions:\n",
    "def obj_fn_ALM(Yi):\n",
    "    # Objective function evaluated for Y\n",
    "    # return (\n",
    "    #     0.5 * Yi.T @ self.Q_np @ Yi + self.p_np.T @ Yi\n",
    "    # )  # Ensure Q_np: (100, 100), p_np: (100,)\n",
    "\n",
    "    return data.obj_fn(torch.tensor(Yi).unsqueeze(0)).squeeze().numpy()\n",
    "\n",
    "def eq_resid_ALM(Yi, Xi):\n",
    "    # Equality residuals (X - A * Y)\n",
    "    # return Xi - self.A_np @ Yi  # A_np: (50, 100), X: (50,), Y: (100,)\n",
    "    return data.eq_resid(Xi, torch.tensor(Yi).unsqueeze(0)).squeeze().numpy()\n",
    "\n",
    "def ineq_resid_ALM(Yi, Xi):\n",
    "    # Inequality residuals (G * Y - h)\n",
    "    # return self.G_np @ Yi - self.h_np  # G_np: (50, 100), h_np: (50,)\n",
    "    return data.ineq_resid(Xi, torch.tensor(Yi).unsqueeze(0)).squeeze().numpy()\n",
    "\n",
    "def L_rho(Yi, Xi, m, l, rho):\n",
    "    # Compute inequality and equality residuals\n",
    "    ineq_resid = ineq_resid_ALM(Yi, Xi)# Should be (50,)\n",
    "    eq_resid = eq_resid_ALM(Yi, Xi)  # Should be (50,)\n",
    "\n",
    "    # Augmented Lagrangian computation\n",
    "    return (\n",
    "        obj_fn_ALM(Yi)\n",
    "        + m.T @ ineq_resid  # Linear term for inequality\n",
    "        + l.T @ eq_resid  # Linear term for equality\n",
    "        + (rho / 2)\n",
    "        * (\n",
    "            np.linalg.norm(np.maximum(ineq_resid, 0), 2) ** 2\n",
    "            + np.linalg.norm(eq_resid, 2) ** 2\n",
    "        )\n",
    "    )\n",
    "\n",
    "def solve_instance(i, Xi, tol=1e-4):\n",
    "        \"\"\"\n",
    "        Solve ALM for a single instance.\n",
    "        \"\"\"\n",
    "        mu_k = np.zeros(data.nineq)  # (50,)\n",
    "        lamb_k = np.zeros(data.neq)  # (50,)\n",
    "        rho = 1\n",
    "        tau = 0.5\n",
    "        alpha = 10\n",
    "        K = 20\n",
    "\n",
    "        epsilon = 1e-4\n",
    "        rho_max = 5000\n",
    "        # print(f\"sample {i+1} of {833}\")\n",
    "        start_time = time.time()\n",
    "        # Initial primal point\n",
    "        Yi = np.random.uniform(-1, 1, data.ydim)  # Shape (100,)\n",
    "\n",
    "        for k in range(K):\n",
    "            print(f\"{k+1}/{K}\")\n",
    "            # Minimize L_rho for current `mu_k` and `lambda_k`\n",
    "            res = scipy.optimize.minimize(\n",
    "                fun=L_rho,\n",
    "                x0=Yi,\n",
    "                args=(Xi, mu_k, lamb_k, rho),\n",
    "                tol=tol,\n",
    "                method=\"CG\",\n",
    "            )\n",
    "            y_k = res.x  # Solution for this iteration, shape (100,)\n",
    "\n",
    "            # Update dual variables using y_k\n",
    "            mu_k = np.maximum(mu_k + rho * ineq_resid_ALM(y_k, Xi), 0)\n",
    "            lamb_k = lamb_k + rho * eq_resid_ALM(y_k, Xi)\n",
    "\n",
    "            # Calculate v_k to check for convergence\n",
    "            inf_norm_eq_resid = np.max(np.abs(eq_resid_ALM(y_k, Xi)))\n",
    "            sigma = np.maximum(ineq_resid_ALM(y_k, Xi), -mu_k / rho)\n",
    "            inf_norm_sigma = np.max(np.abs(sigma))\n",
    "            v_k = max(inf_norm_eq_resid, inf_norm_sigma)\n",
    "\n",
    "            if v_k < epsilon:\n",
    "                print(f\"Converged for instance {i+1} at iteration {k+1}\")\n",
    "                break\n",
    "\n",
    "            if k >= 1 and v_k > (tau * prev_v_k):\n",
    "                rho = min(alpha * rho, rho_max)\n",
    "            prev_v_k = v_k\n",
    "            Yi = y_k  # Use the current solution as the initial guess for the next iteration\n",
    "            print(obj_fn_ALM(Yi))\n",
    "            print(v_k)\n",
    "\n",
    "            rhs_eq = data.rhs_eq[0]\n",
    "            rhs_ineq = data.rhs_ineq[0]\n",
    "\n",
    "            # print(mu_k)\n",
    "\n",
    "            # print(lamb_k)\n",
    "\n",
    "            print((data.dual_obj_fn(torch.tensor(mu_k.tolist()).unsqueeze(0), torch.tensor(lamb_k.tolist()).unsqueeze(0), rhs_eq, rhs_ineq)).item())\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(obj_fn_ALM(Yi))\n",
    "        return y_k, mu_k, lamb_k, end_time - start_time\n",
    "\n",
    "def ALM_solve(X, tol=1e-4):\n",
    "    X_np = X.detach().cpu().numpy() if hasattr(X, \"detach\") else X\n",
    "\n",
    "    # Parallel processing\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        results = list(executor.map(solve_instance, range(len(X_np)), X_np))\n",
    "\n",
    "    # Unpack results\n",
    "    Y, times = zip(*results)\n",
    "    total_time = sum(times)\n",
    "    parallel_time = total_time / len(X_np)\n",
    "    sols = np.array(Y)\n",
    "\n",
    "    return sols, total_time, parallel_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 429 is different from 573)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mtrainX\n\u001b[0;32m----> 2\u001b[0m y, mu, lamb, time_taken \u001b[38;5;241m=\u001b[39m \u001b[43msolve_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 58\u001b[0m, in \u001b[0;36msolve_instance\u001b[0;34m(i, Xi, tol)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mK\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Minimize L_rho for current `mu_k` and `lambda_k`\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mL_rho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mYi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mXi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamb_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCG\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m y_k \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mx  \u001b[38;5;66;03m# Solution for this iteration, shape (100,)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Update dual variables using y_k\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/scipy/optimize/_minimize.py:706\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    704\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_powell(fun, x0, args, callback, bounds, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 706\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_cg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    708\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_bfgs(fun, x0, args, jac, callback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/scipy/optimize/_optimize.py:1723\u001b[0m, in \u001b[0;36m_minimize_cg\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, c1, c2, **unknown_options)\u001b[0m\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxiter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1721\u001b[0m     maxiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x0) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[0;32m-> 1723\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_scalar_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1726\u001b[0m f \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun\n\u001b[1;32m   1727\u001b[0m myfprime \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mgrad\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/scipy/optimize/_optimize.py:288\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    284\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43mScalarFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:166\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl \u001b[38;5;241m=\u001b[39m update_fun\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Gradient evaluation\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(grad):\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:262\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:163\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "Cell \u001b[0;32mIn[9], line 28\u001b[0m, in \u001b[0;36mL_rho\u001b[0;34m(Yi, Xi, m, l, rho)\u001b[0m\n\u001b[1;32m     23\u001b[0m eq_resid \u001b[38;5;241m=\u001b[39m eq_resid_ALM(Yi, Xi)  \u001b[38;5;66;03m# Should be (50,)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Augmented Lagrangian computation\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     obj_fn_ALM(Yi)\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mineq_resid\u001b[49m  \u001b[38;5;66;03m# Linear term for inequality\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;241m+\u001b[39m l\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m eq_resid  \u001b[38;5;66;03m# Linear term for equality\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;241m+\u001b[39m (rho \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;241m*\u001b[39m (\n\u001b[1;32m     32\u001b[0m         np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(np\u001b[38;5;241m.\u001b[39mmaximum(ineq_resid, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(eq_resid, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     34\u001b[0m     )\n\u001b[1;32m     35\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 429 is different from 573)"
     ]
    }
   ],
   "source": [
    "X = data.trainX\n",
    "y, mu, lamb, time_taken = solve_instance(0, X, tol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimality gap (%): 0.0008450506876519232\n"
     ]
    }
   ],
   "source": [
    "OPTIMAL_OBJ = 8.18648032e+08 # First sample\n",
    "\n",
    "print(f\"Optimality gap (%): {abs(obj_fn_ALM(y) - OPTIMAL_OBJ) / OPTIMAL_OBJ * 100}\")\n",
    "# print(mu)\n",
    "# print(lamb)\n",
    "\n",
    "g = ineq_resid_ALM(y, X)\n",
    "h = eq_resid_ALM(y, X)\n",
    "\n",
    "# print(g)\n",
    "# print(mu[g < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dual_obj_fn(mu, lamb, rhs_eq, rhs_ineq):\n",
    "    \"\"\" Objective function of the dual problem.\n",
    "    max -mu^T d - lamb^T b\n",
    "\n",
    "    Args:\n",
    "        mu (_type_): Dual variable for inequality constraints\n",
    "        lamb (_type_): Dual variable for equality constraints\n",
    "        rhs_ineq (_type_): Constants at the right-hand side of the inequality constraints\n",
    "        rhs_eq (_type_): Constants at the right-hand side of the equality constraints\n",
    "\n",
    "    Returns:\n",
    "        _type_: Dual objective value\n",
    "    \"\"\"\n",
    "    ineq_term = torch.sum(mu * rhs_ineq, dim=1)\n",
    "    \n",
    "    eq_term = torch.sum(lamb * rhs_eq, dim=1)\n",
    "\n",
    "    return -(ineq_term + eq_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828113204.1399043\n"
     ]
    }
   ],
   "source": [
    "rhs_eq = data.rhs_eq[0]\n",
    "rhs_ineq = data.rhs_ineq[0]\n",
    "\n",
    "print((data.dual_obj_fn(torch.tensor(mu.tolist()).unsqueeze(0), torch.tensor(lamb.tolist()).unsqueeze(0), rhs_eq, rhs_ineq)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
