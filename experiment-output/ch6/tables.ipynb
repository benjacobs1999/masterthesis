{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'simple': {'obj': [-1328.131182337341,\n",
       "   -1646.084331887411,\n",
       "   -14147.795381650087,\n",
       "   -5609.650842847485,\n",
       "   -16158.08999932075],\n",
       "  'known_obj': [-15.037240915640544,\n",
       "   -15.037240915640544,\n",
       "   -15.037240915640544,\n",
       "   -15.037240915640544,\n",
       "   -15.037240915640544],\n",
       "  'opt_gap': [-8744.36099506512,\n",
       "   -10863.43555703428,\n",
       "   -94153.19499255384,\n",
       "   -37259.73654047795,\n",
       "   -107712.75419794535],\n",
       "  'ineq_max': [0.01680701524556039,\n",
       "   0.020797784714214118,\n",
       "   0.03499553406049418,\n",
       "   0.02380447189877212,\n",
       "   0.018363942571592826],\n",
       "  'ineq_mean': [0.0016263657114894976,\n",
       "   0.0023613674324203214,\n",
       "   0.0025684040018297155,\n",
       "   0.0034214609907723837,\n",
       "   0.0027961065415661674],\n",
       "  'eq_max': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  'eq_mean': [0.0, 0.0, 0.0, 0.0, 0.0]},\n",
       " 'plain': {'obj': [830078572046.8887,\n",
       "   840901026473.9683,\n",
       "   839805885523.9711,\n",
       "   820386304497.4811,\n",
       "   824215545349.2648],\n",
       "  'known_obj': [29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353],\n",
       "  'opt_gap': [29751317171.590843,\n",
       "   29464166535.909016,\n",
       "   29792199664.725727,\n",
       "   29336423454.767902,\n",
       "   29601556943.72398],\n",
       "  'ineq_max': [272586.8618455237,\n",
       "   240540.34213094786,\n",
       "   229754.41546957605,\n",
       "   236529.56628996282,\n",
       "   196958.41830701468],\n",
       "  'ineq_mean': [17939.254887170864,\n",
       "   16720.86884146563,\n",
       "   16010.725497672083,\n",
       "   16177.774530438584,\n",
       "   13326.897789855877],\n",
       "  'eq_max': [11423445.799946802,\n",
       "   11355344.665577576,\n",
       "   11566565.928608973,\n",
       "   11104311.12358142,\n",
       "   11065045.650581801],\n",
       "  'eq_mean': [6404095.82120339,\n",
       "   6486995.330226969,\n",
       "   6536126.292767099,\n",
       "   6271351.227013684,\n",
       "   6305108.1273871055]},\n",
       " 'repair1': {'obj': [-0.1957984415784642,\n",
       "   0.0171952221712586,\n",
       "   0.2132787968645877,\n",
       "   0.3908661613649867,\n",
       "   16.497790587710956],\n",
       "  'known_obj': [29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353],\n",
       "  'opt_gap': [-100.01096761058761,\n",
       "   -99.99900997178626,\n",
       "   -99.98943503440086,\n",
       "   -99.98234470588949,\n",
       "   -99.99466185911342],\n",
       "  'ineq_max': [2.84851418081077e-07,\n",
       "   0.0,\n",
       "   3.998029034209222e-08,\n",
       "   1.9247350713174136e-08,\n",
       "   0.002526266177279645],\n",
       "  'ineq_mean': [1.5506253320618644e-08,\n",
       "   0.0,\n",
       "   1.9339760089816346e-09,\n",
       "   1.2527228753511068e-09,\n",
       "   0.0002689533286880946],\n",
       "  'eq_max': [10.00000713391808,\n",
       "   10.00000422398477,\n",
       "   10.000010857002948,\n",
       "   9.99999554938512,\n",
       "   10.004090553235548],\n",
       "  'eq_mean': [2.509604949094903,\n",
       "   2.509601270991766,\n",
       "   2.5096040290342776,\n",
       "   2.5095964672265088,\n",
       "   2.5117446439046054]},\n",
       " 'repair2': {'obj': [0.45737342555593463,\n",
       "   -6.109274727024225,\n",
       "   -0.1927079819941081,\n",
       "   0.8462141506754401,\n",
       "   -0.012907440911862156],\n",
       "  'known_obj': [29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353],\n",
       "  'opt_gap': [-99.97948083603735,\n",
       "   -100.6741998690034,\n",
       "   -100.02424560377571,\n",
       "   -99.95840913986619,\n",
       "   -100.0012171258434],\n",
       "  'ineq_max': [3.0885243945303432e-09,\n",
       "   4.07789735845326e-08,\n",
       "   0.0020684645286609127,\n",
       "   1.8071924195190724e-05,\n",
       "   2.2867697179300773e-06],\n",
       "  'ineq_mean': [1.4066919470755526e-10,\n",
       "   1.744785543590065e-09,\n",
       "   8.653357504511098e-05,\n",
       "   7.529968414662802e-07,\n",
       "   1.871762777632408e-07],\n",
       "  'eq_max': [9.999999918808703,\n",
       "   10.000000459082365,\n",
       "   10.00002597809124,\n",
       "   10.00008185401255,\n",
       "   10.000004353254715],\n",
       "  'eq_mean': [2.5095986164127058,\n",
       "   2.5097129862780343,\n",
       "   2.5097840073168785,\n",
       "   2.509639970282044,\n",
       "   2.5096020450344896]}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from networks import DualNet, DualNetEndToEnd, PrimalNet, PrimalNetEndToEnd, PrimalNetEndToEnd2\n",
    "import torch\n",
    "\n",
    "def evaluate(data, primal_net, test_indices):        \n",
    "    X = data.X[test_indices]\n",
    "    Y_target = data.opt_targets[\"y_operational\"][test_indices]\n",
    "    \n",
    "    # Forward pass through networks\n",
    "    Y = primal_net(X)\n",
    "\n",
    "    ineq_dist = data.ineq_dist(X, Y)\n",
    "    eq_resid = data.eq_resid(X, Y)\n",
    "\n",
    "    relative_ineq_dist = data.relative_ineq_dist(X, Y)\n",
    "    relative_eq_resid = data.relative_eq_resid(X, Y)\n",
    "\n",
    "    # Convert lists to arrays for easier handling\n",
    "    obj_values = data.obj_fn(X, Y).detach().numpy()\n",
    "    ineq_max_vals = torch.max(ineq_dist, dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    ineq_mean_vals = torch.mean(ineq_dist, dim=1).detach().numpy()\n",
    "    eq_max_vals = torch.max(torch.abs(eq_resid), dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    eq_mean_vals = torch.mean(torch.abs(eq_resid), dim=1).detach().numpy()\n",
    "\n",
    "    relative_ineq_max_vals = torch.max(relative_ineq_dist, dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    relative_ineq_mean_vals = torch.mean(relative_ineq_dist, dim=1).detach().numpy()\n",
    "    relative_eq_max_vals = torch.max(torch.abs(relative_eq_resid), dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    relative_eq_mean_vals = torch.mean(torch.abs(relative_eq_resid), dim=1).detach().numpy()\n",
    "\n",
    "    known_obj = data.obj_fn(X, Y_target).detach().numpy()\n",
    "    # obj_values is negative\n",
    "    opt_gap = (obj_values - known_obj)/np.abs(known_obj) * 100\n",
    "\n",
    "    return np.mean(obj_values), np.mean(known_obj), np.mean(opt_gap), np.mean(ineq_max_vals), np.mean(relative_ineq_max_vals), np.mean(ineq_mean_vals), np.mean(relative_ineq_mean_vals), np.mean(eq_max_vals), np.mean(relative_eq_max_vals), np.mean(eq_mean_vals), np.mean(relative_eq_mean_vals)\n",
    "\n",
    "def dual_evaluate_QP(data, dual_net):\n",
    "    X = data.X[data.test_indices]\n",
    "    target_mu = data.mu[data.test_indices]\n",
    "    target_lamb = data.lamb[data.test_indices]\n",
    "    # Forward pass through networks\n",
    "    mu, lamb = dual_net(X)\n",
    "\n",
    "    obj_values = data.dual_obj_fn(X, mu, lamb).detach().numpy()\n",
    "    known_obj = data.dual_obj_fn(X, target_mu, target_lamb).detach().numpy()\n",
    "    dual_ineq_dist = data.dual_ineq_dist(mu, lamb)\n",
    "    dual_eq_resid = data.dual_eq_resid(mu, lamb)\n",
    "\n",
    "    opt_gap = (obj_values - known_obj)/np.abs(known_obj) * 100\n",
    "\n",
    "    ineq_max_vals = torch.max(dual_ineq_dist, dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    # eq_max_vals = torch.max(torch.abs(dual_eq_resid), dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    ineq_mean_vals = torch.mean(dual_ineq_dist, dim=1).detach().numpy()\n",
    "    # eq_mean_vals = torch.mean(torch.abs(dual_eq_resid), dim=1).detach().numpy()\n",
    "\n",
    "    return np.mean(obj_values), np.mean(known_obj), np.mean(opt_gap), np.mean(ineq_max_vals), np.mean(ineq_mean_vals), np.mean([0.0]), np.mean([0.0])\n",
    "\n",
    "def dual_evaluate(data, dual_net, test_indices):\n",
    "    X = data.X[test_indices]\n",
    "    Y_target = data.opt_targets[\"y_operational\"][test_indices]\n",
    "    # target_mu = data.mu[test_indices]\n",
    "    # target_lamb = data.lamb[test_indices]\n",
    "    target_mu = data.opt_targets[\"mu_operational\"][test_indices]  \n",
    "    target_lamb = data.opt_targets[\"lamb_operational\"][test_indices]\n",
    "\n",
    "\n",
    "    # Forward pass through networks\n",
    "    dual_net.eval()\n",
    "    mu, lamb = dual_net(X)\n",
    "\n",
    "    obj_values = data.dual_obj_fn(X, mu, lamb).detach().numpy()\n",
    "    known_obj = data.dual_obj_fn(X, target_mu, target_lamb).detach().numpy()\n",
    "    # known_obj = data.obj_fn(X, Y_target).detach().numpy()\n",
    "\n",
    "    # print(np.allclose(known_dual_obj, known_obj, 1e-10))\n",
    "\n",
    "    # dual_ineq_dist = data.dual_ineq_dist(mu, lamb)\n",
    "    dual_ineq_resid = data.dual_ineq_resid(mu, lamb)\n",
    "    dual_ineq_dist = torch.clamp(dual_ineq_resid, 0)\n",
    "    dual_eq_resid = data.dual_eq_resid(mu, lamb)\n",
    "\n",
    "    opt_gap = (obj_values - known_obj)/np.abs(known_obj) * 100\n",
    "\n",
    "    ineq_max_vals = torch.max(dual_ineq_dist, dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    eq_max_vals = torch.max(torch.abs(dual_eq_resid), dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    ineq_mean_vals = torch.mean(dual_ineq_dist, dim=1).detach().numpy()\n",
    "    eq_mean_vals = torch.mean(torch.abs(dual_eq_resid), dim=1).detach().numpy()\n",
    "\n",
    "    return np.mean(obj_values), np.mean(known_obj), np.mean(opt_gap), np.mean(ineq_max_vals), np.mean(ineq_mean_vals), np.mean(eq_max_vals), np.mean(eq_mean_vals)\n",
    "\n",
    "repeats = 5\n",
    "stats_dict = {}\n",
    "\n",
    "# Get the quality of dual solutions of QP:\n",
    "dual_stats_dict = {}\n",
    "for experiment in [\"simple\"]:\n",
    "    dual_stats_dict[experiment] = {\"obj\": [], \"known_obj\": [], \"opt_gap\": [], \"ineq_max\": [], \"ineq_mean\": [], \"eq_max\": [], \"eq_mean\": []}\n",
    "    for repeat in range(repeats):\n",
    "        directory = f\"experiment-output/ch4/ch4-reproduction/{experiment}/repeat:{repeat}\"\n",
    "        data_path = f\"data/QP_data/QP_type:{experiment}_var:100_ineq:50_eq:50_num_samples:10000.pkl\"\n",
    "\n",
    "        qp_args = json.load(open('config.json'))\n",
    "        data = pickle.load(open(data_path, 'rb'))\n",
    "        dual_net = DualNet(qp_args, data=data)\n",
    "        dual_net.load_state_dict(torch.load(os.path.join(directory, 'dual_weights.pth'), weights_only=True))\n",
    "\n",
    "        obj_val, known_obj, opt_gap, ineq_max, ineq_mean, eq_max, eq_mean = dual_evaluate_QP(data, dual_net)\n",
    "        dual_stats_dict[experiment][\"obj\"].append(obj_val)\n",
    "        dual_stats_dict[experiment][\"known_obj\"].append(known_obj)\n",
    "        dual_stats_dict[experiment][\"opt_gap\"].append(opt_gap)\n",
    "        dual_stats_dict[experiment][\"ineq_max\"].append(ineq_max)\n",
    "        dual_stats_dict[experiment][\"ineq_mean\"].append(ineq_mean)\n",
    "        dual_stats_dict[experiment][\"eq_max\"].append(eq_max)\n",
    "        dual_stats_dict[experiment][\"eq_mean\"].append(eq_mean)\n",
    "\n",
    "\n",
    "data_path = \"experiment-output/ch7/ED_NB-G-F_GB2-G2-F2_L3_c0_s0_p0_smp15.pkl\"\n",
    "data = pickle.load(open(data_path, 'rb'))\n",
    "\n",
    "indices = torch.arange(data.X.shape[0])\n",
    "\n",
    "# ---- 7.1 -----    \n",
    "# Get the quality of dual solutions of ED:\n",
    "for run, (path, name) in enumerate(zip(\n",
    "    [\"experiment-output/ch5/plain-PDL/learn_primal:True_train:0.8_rho:0.5_rhomax:5000_alpha:10_L:10-1746265816-296861\", \n",
    "    \"experiment-output/ch5/repair-1/learn_primal:True_train:0.8_rho:0.5_rhomax:5000_alpha:10_L:10-1746429988-424426\",\n",
    "    \"experiment-output/ch5/repair-2/learn_primal:True_train:0.8_rho:0.5_rhomax:5000_alpha:10_L:10-1746434902-974866\"],\n",
    "    [\"plain\", \"repair1\", \"repair2\"])):\n",
    "    dual_stats_dict[name] = {\"obj\": [], \"known_obj\": [], \"opt_gap\": [], \"ineq_max\": [], \"ineq_mean\": [], \"eq_max\": [], \"eq_mean\": []}\n",
    "    for repeat in range(repeats):\n",
    "        directory = os.path.join(path, f\"repeat:{repeat}\")\n",
    "        with open(os.path.join(path, 'args.json'), 'r') as f:\n",
    "            args = json.load(f)\n",
    "        # Compute sizes for each set\n",
    "        train_size = int(args[\"train\"] * data.X.shape[0])\n",
    "        valid_size = int(args[\"valid\"] * data.X.shape[0])\n",
    "\n",
    "        \n",
    "\n",
    "        train_indices = indices[:train_size]\n",
    "        valid_indices = indices[train_size:train_size+valid_size]\n",
    "        test_indices = indices[train_size+valid_size:]\n",
    "\n",
    "\n",
    "        data = pickle.load(open(data_path, 'rb'))\n",
    "        dual_net = DualNet(args, data=data)\n",
    "        dual_net.load_state_dict(torch.load(os.path.join(directory, 'dual_weights.pth'), weights_only=True))\n",
    "\n",
    "        obj_val, known_obj, opt_gap, ineq_max, ineq_mean, eq_max, eq_mean = dual_evaluate(data, dual_net, test_indices)\n",
    "        dual_stats_dict[name][\"obj\"].append(obj_val)\n",
    "        dual_stats_dict[name][\"known_obj\"].append(known_obj)\n",
    "        dual_stats_dict[name][\"opt_gap\"].append(opt_gap)\n",
    "        dual_stats_dict[name][\"ineq_max\"].append(ineq_max)\n",
    "        dual_stats_dict[name][\"ineq_mean\"].append(ineq_mean)\n",
    "        dual_stats_dict[name][\"eq_max\"].append(eq_max)\n",
    "        dual_stats_dict[name][\"eq_mean\"].append(eq_mean)\n",
    "\n",
    "dual_stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted (scientific) table:\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "Statistic & simple & plain & repair1 & repair2 \\\\\n",
      "\\midrule\n",
      "Predicted Obj & -7.8 (6.2) e3 & 8.3 (0.8) e11 & 3.4 (6.6) e0 & -1.0 (2.6) e0 \\\\\n",
      "OptGap (\\%) & -5.2 (4.2) e4 & 3.0 (0.2) e10 & -10.0 (0.0) e1 & -1.0 (0.0) e2 \\\\\n",
      "IneqMax & 2.3 (6.5) e-2 & 2.4 (2.4) e5 & 5.1 (1.0) e-4 & 4.2 (8.3) e-4 \\\\\n",
      "IneqMean & 2.6 (5.8) e-3 & 1.6 (1.5) e4 & 5.4 (1.1) e-5 & 1.7 (3.5) e-5 \\\\\n",
      "EqMax & 0.0 (0.0) e0 & 1.1 (0.2) e7 & 1.0 (0.0) e1 & 1.0 (0.0) e1 \\\\\n",
      "EqMean & 0.0 (0.0) e0 & 6.4 (1.0) e6 & 2.5 (0.0) e0 & 2.5 (0.0) e0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "Original mean (std) table:\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "Statistic & simple & plain & repair1 & repair2 \\\\\n",
      "\\midrule\n",
      "Predicted Obj & -7777.950 (6240.243) & 831077466778.315 (8186236329.250) & 3.385 (6.559) & -1.002 (2.579) \\\\\n",
      "OptGap (\\%) & -51746.696 (41619.766) & 29589132754.143 (171565067.315) & -99.995 (0.010) & -100.128 (0.274) \\\\\n",
      "IneqMax & 0.023 (0.006) & 235273.921 (24166.547) & 0.001 (0.001) & 0.000 (0.001) \\\\\n",
      "IneqMean & 0.003 (0.001) & 16035.104 (1513.367) & 0.000 (0.000) & 0.000 (0.000) \\\\\n",
      "EqMax & 0.000 (0.000) & 11302942.634 (191213.848) & 10.001 (0.002) & 10.000 (0.000) \\\\\n",
      "EqMean & 0.000 (0.000) & 6400735.360 (101653.924) & 2.510 (0.001) & 2.510 (0.000) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def format_sci_mean_std(mean, std):\n",
    "    \"\"\"Format mean and std as 'mantissa (std) e exponent' with 1 decimal, mantissa always in [1.0, 10.0).\"\"\"\n",
    "    def get_mantissa_exp(val):\n",
    "        if val == 0:\n",
    "            return 0.0, 0\n",
    "        exponent = int(np.floor(np.log10(abs(val))))\n",
    "        mantissa = val / (10 ** exponent)\n",
    "        return mantissa, exponent\n",
    "\n",
    "    # Use mean or std for exponent reference\n",
    "    ref_val = mean if mean != 0 else std\n",
    "    mantissa_mean, exponent = get_mantissa_exp(ref_val)\n",
    "    mantissa_std = std / (10 ** exponent) if ref_val != 0 else 0.0\n",
    "    return f\"{mantissa_mean:.1f} ({mantissa_std:.1f}) e{exponent}\"\n",
    "\n",
    "def format_orig_mean_std(mean, std):\n",
    "    \"\"\"Format mean and std as 'mean (std)' with 3 decimals.\"\"\"\n",
    "    return f\"{mean:.3f} ({std:.3f})\"\n",
    "\n",
    "# Prepare final summary for LaTeX export\n",
    "summary = {\n",
    "    \"Predicted Obj\": [],\n",
    "    \"OptGap (\\%)\": [],\n",
    "    \"IneqMax\": [],\n",
    "    \"IneqMean\": [],\n",
    "    \"EqMax\": [],\n",
    "    \"EqMean\": [],\n",
    "}\n",
    "summary_orig = {\n",
    "    \"Predicted Obj\": [],\n",
    "    \"OptGap (\\%)\": [],\n",
    "    \"IneqMax\": [],\n",
    "    \"IneqMean\": [],\n",
    "    \"EqMax\": [],\n",
    "    \"EqMean\": [],\n",
    "}\n",
    "\n",
    "for experiment, metrics in dual_stats_dict.items():\n",
    "    # Predicted Obj (scientific)\n",
    "    mean = np.mean(metrics['obj'])\n",
    "    std = np.std(metrics['obj'])\n",
    "    summary[\"Predicted Obj\"].append(format_sci_mean_std(mean, std))\n",
    "    summary_orig[\"Predicted Obj\"].append(format_orig_mean_std(mean, std))\n",
    "    # OptGap (scientific)\n",
    "    mean = np.mean(metrics['opt_gap'])\n",
    "    std = np.std(metrics['opt_gap'])\n",
    "    summary[\"OptGap (\\%)\"].append(format_sci_mean_std(mean, std))\n",
    "    summary_orig[\"OptGap (\\%)\"].append(format_orig_mean_std(mean, std))\n",
    "    # IneqMax (scientific)\n",
    "    mean = np.mean(metrics['ineq_max'])\n",
    "    std = np.std(metrics['ineq_max'])\n",
    "    summary[\"IneqMax\"].append(format_sci_mean_std(mean, std))\n",
    "    summary_orig[\"IneqMax\"].append(format_orig_mean_std(mean, std))\n",
    "    # IneqMean (scientific)\n",
    "    mean = np.mean(metrics['ineq_mean'])\n",
    "    std = np.std(metrics['ineq_mean'])\n",
    "    summary[\"IneqMean\"].append(format_sci_mean_std(mean, std))\n",
    "    summary_orig[\"IneqMean\"].append(format_orig_mean_std(mean, std))\n",
    "    # EqMax (scientific)\n",
    "    mean = np.mean(metrics['eq_max'])\n",
    "    std = np.std(metrics['eq_max'])\n",
    "    summary[\"EqMax\"].append(format_sci_mean_std(mean, std))\n",
    "    summary_orig[\"EqMax\"].append(format_orig_mean_std(mean, std))\n",
    "    # EqMean (scientific)\n",
    "    mean = np.mean(metrics['eq_mean'])\n",
    "    std = np.std(metrics['eq_mean'])\n",
    "    summary[\"EqMean\"].append(format_sci_mean_std(mean, std))\n",
    "    summary_orig[\"EqMean\"].append(format_orig_mean_std(mean, std))\n",
    "\n",
    "# Formatted table\n",
    "df = pd.DataFrame(summary)\n",
    "df_T = df.T\n",
    "df_T.columns = list(dual_stats_dict.keys())  # Set experiment names as columns\n",
    "df_T = df_T.reset_index().rename(columns={'index': 'Statistic'})\n",
    "\n",
    "# Unformatted mean/std table\n",
    "df_orig = pd.DataFrame(summary_orig)\n",
    "df_orig_T = df_orig.T\n",
    "df_orig_T.columns = list(dual_stats_dict.keys())\n",
    "df_orig_T = df_orig_T.reset_index().rename(columns={'index': 'Statistic'})\n",
    "\n",
    "# Print LaTeX tables\n",
    "print(\"Formatted (scientific) table:\")\n",
    "print(df_T.to_latex(index=False, escape=False))\n",
    "\n",
    "print(\"\\nOriginal mean (std) table:\")\n",
    "print(df_orig_T.to_latex(index=False, escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completion': {'obj': [28415.2342771398,\n",
       "   28276.766905426706,\n",
       "   28453.742061615216,\n",
       "   28284.535654657113,\n",
       "   28438.550995380392],\n",
       "  'known_obj': [29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353],\n",
       "  'opt_gap': [-56.21245468110735,\n",
       "   -59.473604765918445,\n",
       "   -52.62728674649323,\n",
       "   -62.60254343063131,\n",
       "   -50.55739209099471],\n",
       "  'ineq_max': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  'ineq_mean': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  'eq_max': [9.795400321540753e-17,\n",
       "   9.703148459371286e-17,\n",
       "   9.667414521768291e-17,\n",
       "   9.726586724075517e-17,\n",
       "   9.681970465135701e-17],\n",
       "  'eq_mean': [1.141142976140631e-17,\n",
       "   1.131934072525713e-17,\n",
       "   1.126416558133277e-17,\n",
       "   1.1350389642146944e-17,\n",
       "   1.1279303302139569e-17]},\n",
       " 'classification': {'obj': [29202.436281227412,\n",
       "   29043.63723645002,\n",
       "   29177.512451691306,\n",
       "   25260.95882888781,\n",
       "   27609.171883932922],\n",
       "  'known_obj': [29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353],\n",
       "  'opt_gap': [-3.895719443955351,\n",
       "   -10.456889630670855,\n",
       "   -3.858369773376157,\n",
       "   -5.313672953063946,\n",
       "   -80.08537510464912],\n",
       "  'ineq_max': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  'ineq_mean': [0.0, 0.0, 0.0, 0.0, 0.0],\n",
       "  'eq_max': [9.860648008489786e-17,\n",
       "   9.832121137799071e-17,\n",
       "   9.961582501007165e-17,\n",
       "   9.3392254822909e-17,\n",
       "   9.62625254484156e-17],\n",
       "  'eq_mean': [1.1295981082850462e-17,\n",
       "   1.123211924309567e-17,\n",
       "   1.1439051614343984e-17,\n",
       "   1.0327902872458173e-17,\n",
       "   1.1053342405498998e-17]}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- 7.5 -----    \n",
    "# Get the quality of dual solutions:\n",
    "from networks import DualClassificationNetEndToEnd\n",
    "\n",
    "\n",
    "dual_stats_dict = {}\n",
    "for run, (path, name) in enumerate(zip(\n",
    "    [\n",
    "        \"experiment-output/ch6/3-nodes/dual-completion/newest_run\", \n",
    "        \"experiment-output/ch6/3-nodes/dual-classification/newest_run\"\n",
    "    ],\n",
    "    [\n",
    "        \"completion\",\n",
    "        \"classification\"\n",
    "    ])):\n",
    "    dual_stats_dict[name] = {\"obj\": [], \"known_obj\": [], \"opt_gap\": [], \"ineq_max\": [], \"ineq_mean\": [], \"eq_max\": [], \"eq_mean\": []}\n",
    "    for repeat in range(repeats):\n",
    "        directory = os.path.join(path, f\"repeat:{repeat}\")\n",
    "        with open(os.path.join(path, 'args.json'), 'r') as f:\n",
    "            args = json.load(f)\n",
    "        # Compute sizes for each set\n",
    "        train_size = int(args[\"train\"] * data.X.shape[0])\n",
    "        valid_size = int(args[\"valid\"] * data.X.shape[0])\n",
    "\n",
    "        train_indices = indices[:train_size]\n",
    "        valid_indices = indices[train_size:train_size+valid_size]\n",
    "        test_indices = indices[train_size+valid_size:]\n",
    "\n",
    "\n",
    "        data = pickle.load(open(data_path, 'rb'))\n",
    "        if run == 0:\n",
    "            dual_net = DualNetEndToEnd(args, data=data)\n",
    "        else:\n",
    "            dual_net = DualClassificationNetEndToEnd(args, data=data)\n",
    "        dual_net.load_state_dict(torch.load(os.path.join(directory, 'dual_weights.pth'), weights_only=True))\n",
    "\n",
    "        obj_val, known_obj, opt_gap, ineq_max, ineq_mean, eq_max, eq_mean = dual_evaluate(data, dual_net, test_indices)\n",
    "        dual_stats_dict[name][\"obj\"].append(obj_val)\n",
    "        dual_stats_dict[name][\"known_obj\"].append(known_obj)\n",
    "        dual_stats_dict[name][\"opt_gap\"].append(opt_gap)\n",
    "        dual_stats_dict[name][\"ineq_max\"].append(ineq_max)\n",
    "        dual_stats_dict[name][\"ineq_mean\"].append(ineq_mean)\n",
    "        dual_stats_dict[name][\"eq_max\"].append(eq_max)\n",
    "        dual_stats_dict[name][\"eq_mean\"].append(eq_mean)\n",
    "\n",
    "dual_stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "Predicted Obj & OptGap (\\%) & IneqMax & IneqMean & EqMax & EqMean \\\\\n",
      "\\midrule\n",
      "28373.766(77.050) & -56.295(4.388) & 0.000(0.000) & 0.000(0.000) & 0.000(0.000) & 0.000(0.000) \\\\\n",
      "28058.743(1520.487) & -20.722(29.780) & 0.000(0.000) & 0.000(0.000) & 0.000(0.000) & 0.000(0.000) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare final summary for LaTeX export\n",
    "summary = {\n",
    "    # \"Optimal Obj\": [],\n",
    "    \"Predicted Obj\": [],\n",
    "    \"OptGap (\\%)\": [],\n",
    "    \"IneqMax\": [],\n",
    "    \"IneqMean\": [],\n",
    "    \"EqMax\": [],\n",
    "    \"EqMean\": [],\n",
    "}\n",
    "\n",
    "for experiment, metrics in dual_stats_dict.items():\n",
    "    # summary[\"Optimal Obj\"].append(f\"{np.mean(metrics['known_obj']):.3e}\")\n",
    "    summary[\"Predicted Obj\"].append(f\"{np.mean(metrics['obj']):.3f}({np.std(metrics['obj']):.3f})\")\n",
    "    summary[\"OptGap (\\%)\"].append(f\"{np.mean(metrics['opt_gap']):.3f}({np.std(metrics['opt_gap']):.3f})\")\n",
    "    summary[\"IneqMax\"].append(\n",
    "        f\"{np.mean(metrics['ineq_max']):.3f}({np.std(metrics['ineq_max']):.3f})\"\n",
    "    )\n",
    "    summary[\"IneqMean\"].append(\n",
    "        f\"{np.mean(metrics['ineq_mean']):.3f}({np.std(metrics['ineq_mean']):.3f})\"\n",
    "    )\n",
    "    summary[\"EqMax\"].append(\n",
    "        f\"{np.mean(metrics['eq_max']):.3f}({np.std(metrics['eq_max']):.3f})\"\n",
    "    )\n",
    "    summary[\"EqMean\"].append(\n",
    "        f\"{np.mean(metrics['eq_mean']):.3f}({np.std(metrics['eq_mean']):.3f})\"\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(summary)\n",
    "\n",
    "# For LaTeX export\n",
    "latex_table = df.to_latex(index=False, escape=False)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "Experiment & Run 1 & Run 2 & Run 3 & Run 4 & Run 5 \\\\\n",
      "\\midrule\n",
      "completion & -56.212455 & -59.473605 & -52.627287 & -62.602543 & -50.557392 \\\\\n",
      "classification & -3.895719 & -10.456890 & -3.858370 & -5.313673 & -80.085375 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select the experiments you want\n",
    "experiments = ['completion', 'classification']  # or any two you want\n",
    "\n",
    "# Build the table data\n",
    "opt_gap_data = []\n",
    "for exp in experiments:\n",
    "    # Get the list of opt_gap values for this experiment\n",
    "    gaps = dual_stats_dict[exp]['opt_gap']\n",
    "    # Format as strings if you want, or just keep as floats\n",
    "    opt_gap_data.append(gaps)\n",
    "\n",
    "# Create DataFrame: rows=experiments, columns=run indices\n",
    "df_optgap = pd.DataFrame(opt_gap_data, index=experiments, columns=[f'Run {i+1}' for i in range(5)])\n",
    "\n",
    "# Reset index to have 'Experiment' as a column\n",
    "df_optgap = df_optgap.reset_index().rename(columns={'index': 'Experiment'})\n",
    "\n",
    "# For LaTeX export\n",
    "latex_table = df_optgap.to_latex(index=False, escape=False)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
