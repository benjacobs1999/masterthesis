{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/QP_data/QP_type:simple_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:simple_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:simple_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:simple_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:simple_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:row_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:row_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:row_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:row_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:row_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:column_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:column_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:column_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:column_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:column_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:random_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:random_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:random_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:random_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:random_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:obj_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:obj_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:obj_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:obj_var:100_ineq:50_eq:50_num_samples:10000.pkl\n",
      "data/QP_data/QP_type:obj_var:100_ineq:50_eq:50_num_samples:10000.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'simple': {'predicted_obj': [-14.919759138518534,\n",
       "   -15.041652945077244,\n",
       "   -14.964690095515898,\n",
       "   -14.975709280914536,\n",
       "   -14.81955487375971],\n",
       "  'known_obj': [-15.037454693695281,\n",
       "   -15.037454693695281,\n",
       "   -15.037454693695281,\n",
       "   -15.037454693695281,\n",
       "   -15.037454693695281],\n",
       "  'opt_gap': [0.7834218060544529,\n",
       "   -0.02859135175651931,\n",
       "   0.48513927982729277,\n",
       "   0.41104900085924667,\n",
       "   1.4500587540260403],\n",
       "  'ineq_max': [0.010907337533850765,\n",
       "   0.04222041990634877,\n",
       "   0.03255320309219123,\n",
       "   0.0010520906696660055,\n",
       "   0.008160390830264408],\n",
       "  'ineq_mean': [0.0006831285436810389,\n",
       "   0.003626927635663962,\n",
       "   0.001268154386377111,\n",
       "   3.705330681345522e-05,\n",
       "   0.0002051003682463282],\n",
       "  'eq_max': [0.010984893116720263,\n",
       "   0.04380366856908005,\n",
       "   0.022784673071669762,\n",
       "   0.007089928758906608,\n",
       "   0.004828305966934044],\n",
       "  'eq_mean': [0.0034382708048531444,\n",
       "   0.014072168316595473,\n",
       "   0.007165308147830592,\n",
       "   0.002215102025881409,\n",
       "   0.001481273069295882]},\n",
       " 'row': {'predicted_obj': [-14.681999863879154,\n",
       "   -15.679442497244125,\n",
       "   -15.583915341198805,\n",
       "   -14.78452415323714,\n",
       "   -15.02410255376576],\n",
       "  'known_obj': [-15.570036790032356,\n",
       "   -15.570036790032356,\n",
       "   -15.570036790032356,\n",
       "   -15.570036790032356,\n",
       "   -15.570036790032356],\n",
       "  'opt_gap': [5.702337690855594,\n",
       "   -0.7022573073856384,\n",
       "   -0.08873232515478359,\n",
       "   5.043761751832975,\n",
       "   3.5050465160580826],\n",
       "  'ineq_max': [0.062130981021967006,\n",
       "   0.14040325017696387,\n",
       "   0.1272530133724783,\n",
       "   0.06136819975398563,\n",
       "   0.07824417756488149],\n",
       "  'ineq_mean': [0.00315673970034435,\n",
       "   0.00763534357779616,\n",
       "   0.006062762199486128,\n",
       "   0.0028824617682257233,\n",
       "   0.004156206474302241],\n",
       "  'eq_max': [0.10421950946028966,\n",
       "   0.10633555742275577,\n",
       "   0.0655691604329295,\n",
       "   0.10218166914607536,\n",
       "   0.10959622928146683],\n",
       "  'eq_mean': [0.03308930603193491,\n",
       "   0.032395708223509415,\n",
       "   0.021479403205260227,\n",
       "   0.03199108424912478,\n",
       "   0.034330724304339526]},\n",
       " 'column': {'predicted_obj': [-14.453865318013777,\n",
       "   -15.336186427901898,\n",
       "   -15.236326235388862,\n",
       "   -14.446427403748974,\n",
       "   -14.412874738120214],\n",
       "  'known_obj': [-15.357705690362502,\n",
       "   -15.357705690362502,\n",
       "   -15.357705690362502,\n",
       "   -15.357705690362502,\n",
       "   -15.357705690362502],\n",
       "  'opt_gap': [5.8420586743325815,\n",
       "   0.1357689202619822,\n",
       "   0.7838037215633988,\n",
       "   5.890878973087652,\n",
       "   6.109489923122062],\n",
       "  'ineq_max': [0.07206536209361691,\n",
       "   0.2902505922889743,\n",
       "   0.1219904629866737,\n",
       "   0.06961760560266718,\n",
       "   0.0710153251925725],\n",
       "  'ineq_mean': [0.002500033313315738,\n",
       "   0.01642493509578692,\n",
       "   0.0050433166862338796,\n",
       "   0.0029588488379934355,\n",
       "   0.0036972560427965097],\n",
       "  'eq_max': [0.10506056351930793,\n",
       "   0.037644188521544136,\n",
       "   0.009989951955202013,\n",
       "   0.0945549295961548,\n",
       "   0.10022505645950093],\n",
       "  'eq_mean': [0.033219482845951956,\n",
       "   0.010279549977294796,\n",
       "   0.003288856615676127,\n",
       "   0.0300872869852074,\n",
       "   0.03198683939419891]},\n",
       " 'random': {'predicted_obj': [-14.34346929978217,\n",
       "   -15.576764300591183,\n",
       "   -15.526241779419825,\n",
       "   -14.003755095800576,\n",
       "   -14.36763472643956],\n",
       "  'known_obj': [-15.60240406100253,\n",
       "   -15.60240406100253,\n",
       "   -15.60240406100253,\n",
       "   -15.60240406100253,\n",
       "   -15.60240406100253],\n",
       "  'opt_gap': [8.041091638877752,\n",
       "   0.16402790329014857,\n",
       "   0.48821960894014393,\n",
       "   10.22656658377374,\n",
       "   7.886492262392314],\n",
       "  'ineq_max': [0.05665715732111185,\n",
       "   0.11752013657528795,\n",
       "   0.1309863972499092,\n",
       "   0.006041938490682296,\n",
       "   0.05627521204947508],\n",
       "  'ineq_mean': [0.0018267385091117663,\n",
       "   0.006496694902554846,\n",
       "   0.00685620678541874,\n",
       "   0.00014471035590884142,\n",
       "   0.001767943179140034],\n",
       "  'eq_max': [0.11175942883953421,\n",
       "   0.031106200977830144,\n",
       "   0.02713258677102538,\n",
       "   0.007701409333366542,\n",
       "   0.11144356821084679],\n",
       "  'eq_mean': [0.03582423958042557,\n",
       "   0.00941378854848068,\n",
       "   0.009502935318760045,\n",
       "   0.0026446427213367486,\n",
       "   0.03547626157093288]},\n",
       " 'obj': {'predicted_obj': [-14.462426173491702,\n",
       "   -14.613160000384456,\n",
       "   -14.594237661112373,\n",
       "   -14.198156739328853,\n",
       "   -14.299737823159601],\n",
       "  'known_obj': [-15.629650866217737,\n",
       "   -15.629650866217737,\n",
       "   -15.629650866217737,\n",
       "   -15.629650866217737,\n",
       "   -15.629650866217737],\n",
       "  'opt_gap': [7.494249994393734,\n",
       "   6.550219555142768,\n",
       "   6.672450479490562,\n",
       "   9.197066000876882,\n",
       "   8.52151313651507],\n",
       "  'ineq_max': [0.016742338393466106,\n",
       "   0.105761084492329,\n",
       "   0.04687264993898416,\n",
       "   0.0037946822082089984,\n",
       "   0.008882590000894908],\n",
       "  'ineq_mean': [0.00104078369486003,\n",
       "   0.005457645051455339,\n",
       "   0.0020750724528386818,\n",
       "   0.00010479251333643241,\n",
       "   0.0003846377962196646],\n",
       "  'eq_max': [0.014686376743584287,\n",
       "   0.021941377357625354,\n",
       "   0.0109505542896621,\n",
       "   0.00990364501885927,\n",
       "   0.009487037401592518],\n",
       "  'eq_mean': [0.0047725919126144125,\n",
       "   0.0069925142054711046,\n",
       "   0.0032931674218275465,\n",
       "   0.002849131271276089,\n",
       "   0.0032807282502644746]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from networks import DualNet, DualNetEndToEnd, PrimalNet, PrimalNetEndToEnd\n",
    "import torch\n",
    "\n",
    "def evaluate(data, primal_net):        \n",
    "    X = data.X[data.test_indices]\n",
    "    Y_target = data.Y[data.test_indices]\n",
    "    # Forward pass through networks\n",
    "    Y = primal_net(X)\n",
    "\n",
    "    ineq_dist = data.ineq_dist(X, Y)\n",
    "    eq_resid = data.eq_resid(X, Y)\n",
    "\n",
    "    # Convert lists to arrays for easier handling\n",
    "    obj_values = data.obj_fn(X, Y).detach().numpy()\n",
    "    ineq_max_vals = torch.max(ineq_dist, dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    ineq_mean_vals = torch.mean(ineq_dist, dim=1).detach().numpy()\n",
    "    eq_max_vals = torch.max(torch.abs(eq_resid), dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    eq_mean_vals = torch.mean(torch.abs(eq_resid), dim=1).detach().numpy()\n",
    "    known_obj = data.obj_fn(X, Y_target).detach().numpy()\n",
    "    # obj_values is negative\n",
    "    opt_gap = (obj_values - known_obj)/np.abs(known_obj) * 100\n",
    "\n",
    "    return np.mean(obj_values), np.mean(known_obj), np.mean(opt_gap), np.mean(ineq_max_vals), np.mean(ineq_mean_vals), np.mean(eq_max_vals), np.mean(eq_mean_vals)\n",
    "\n",
    "def dual_evaluate(data, dual_net):\n",
    "    X = data.X[data.test_indices]\n",
    "    target_mu = data.mu[data.test_indices]\n",
    "    target_lamb = data.lamb[data.test_indices]\n",
    "    # Forward pass through networks\n",
    "    mu, lamb = dual_net(X)\n",
    "\n",
    "    obj_values = data.dual_obj_fn(X, mu, lamb).detach().numpy()\n",
    "    known_obj = data.dual_obj_fn(X, target_mu, target_lamb).detach().numpy()\n",
    "    dual_ineq_dist = data.dual_ineq_dist(mu, lamb)\n",
    "    dual_eq_resid = data.dual_eq_resid(mu, lamb)\n",
    "\n",
    "    opt_gap = (obj_values - known_obj)/np.abs(known_obj) * 100\n",
    "\n",
    "    ineq_max_vals = torch.max(dual_ineq_dist, dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    # eq_max_vals = torch.max(torch.abs(dual_eq_resid), dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    ineq_mean_vals = torch.mean(dual_ineq_dist, dim=1).detach().numpy()\n",
    "    # eq_mean_vals = torch.mean(torch.abs(dual_eq_resid), dim=1).detach().numpy()\n",
    "\n",
    "    return np.mean(obj_values), np.mean(known_obj), np.mean(opt_gap), np.mean(ineq_max_vals), np.mean(ineq_mean_vals), np.mean([0.0]), np.mean([0.0])\n",
    "\n",
    "repeats = 5\n",
    "stats_dict = {}\n",
    "\n",
    "for experiment in [\"simple\", \"row\", \"column\", \"random\", \"obj\"]:\n",
    "    stats_dict[experiment] = {\"predicted_obj\": [], \"known_obj\": [], \"opt_gap\": [], \"ineq_max\": [], \"ineq_mean\": [], \"eq_max\": [], \"eq_mean\": []}\n",
    "    random_params = [\"tau_0.9_rho_10.0_rhomax_50000_alpha_1.5\", \"tau_0.9_rho_0.1_rhomax_5000_alpha_1.0\", \"tau_0.7_rho_0.1_rhomax_50000_alpha_2.0\", \"tau_0.5_rho_1.0_rhomax_10000_alpha_10.0\", \"tau_0.9_rho_10.0_rhomax_50000_alpha_10.0\"]\n",
    "    for i, repeat in enumerate(range(repeats)):\n",
    "        \n",
    "        directory = f\"experiment-output/ch4/ch4-reproduction-random-params/{experiment}/{random_params[i]}_repeat:{repeat}\"\n",
    "        # directory = f\"experiment-output/ch5-reproduction-nonconvex/{experiment}/repeat:{repeat}\"\n",
    "        data_path = f\"data/QP_data/QP_type:{experiment}_var:100_ineq:50_eq:50_num_samples:10000.pkl\"\n",
    "        print(data_path)\n",
    "        # List files and extract numeric prefixes\n",
    "        files = os.listdir(directory)\n",
    "        pattern = re.compile(r\"^([\\d.]+)_best_primal_net\\.pth$\")\n",
    "\n",
    "        # Filter and convert to float\n",
    "        numbered_files = [(float(m.group(1)), f) for f in files if (m := pattern.match(f))]\n",
    "\n",
    "        # Get file with smallest number\n",
    "        min_file = min(numbered_files, key=lambda x: x[0])[1]\n",
    "\n",
    "        args = json.load(open('config.json'))\n",
    "        data = pickle.load(open(data_path, 'rb'))\n",
    "        primal_net = PrimalNet(args, data=data)\n",
    "        primal_net.load_state_dict(torch.load(os.path.join(directory, min_file), weights_only=True))\n",
    "\n",
    "        obj_val, known_obj, opt_gap, ineq_max, ineq_mean, eq_max, eq_mean = evaluate(data, primal_net)\n",
    "        stats_dict[experiment][\"predicted_obj\"].append(obj_val)\n",
    "        stats_dict[experiment][\"known_obj\"].append(known_obj)\n",
    "        stats_dict[experiment][\"opt_gap\"].append(opt_gap)\n",
    "        stats_dict[experiment][\"ineq_max\"].append(ineq_max)\n",
    "        stats_dict[experiment][\"ineq_mean\"].append(ineq_mean)\n",
    "        stats_dict[experiment][\"eq_max\"].append(eq_max)\n",
    "        stats_dict[experiment][\"eq_mean\"].append(eq_mean)\n",
    "\n",
    "\n",
    "stats_dict\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "Experiment & Optimal Obj & Predicted Obj & OptGap (\\%) & IneqMax & IneqMean & EqMax & EqMean \\\\\n",
      "\\midrule\n",
      "simple & -15.037 & -14.944(0.074) & 0.620(0.490) & 0.019(0.016) & 0.001(0.001) & 0.018(0.014) & 0.006(0.005) \\\\\n",
      "row & -15.570 & -15.151(0.409) & 2.692(2.627) & 0.094(0.033) & 0.005(0.002) & 0.098(0.016) & 0.031(0.005) \\\\\n",
      "column & -15.358 & -14.777(0.417) & 3.752(2.698) & 0.125(0.085) & 0.006(0.005) & 0.069(0.038) & 0.022(0.012) \\\\\n",
      "random & -15.602 & -14.764(0.656) & 5.361(4.195) & 0.073(0.046) & 0.003(0.003) & 0.058(0.045) & 0.019(0.014) \\\\\n",
      "obj & -15.630 & -14.434(0.163) & 7.687(1.033) & 0.036(0.038) & 0.002(0.002) & 0.013(0.005) & 0.004(0.002) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare final summary for LaTeX export\n",
    "summary = {\n",
    "    \"Experiment\": [],\n",
    "    \"Optimal Obj\": [],\n",
    "    \"Predicted Obj\": [],\n",
    "    \"OptGap (\\%)\": [],\n",
    "    \"IneqMax\": [],\n",
    "    \"IneqMean\": [],\n",
    "    \"EqMax\": [],\n",
    "    \"EqMean\": [],\n",
    "}\n",
    "\n",
    "for experiment, metrics in stats_dict.items():\n",
    "    summary[\"Experiment\"].append(experiment)\n",
    "    summary[\"Optimal Obj\"].append(f\"{np.mean(metrics['known_obj']):.3f}\")\n",
    "    summary[\"Predicted Obj\"].append(f\"{np.mean(metrics['predicted_obj']):.3f}({np.std(metrics['predicted_obj']):.3f})\")\n",
    "    summary[\"OptGap (\\%)\"].append(\n",
    "        f\"{np.mean(metrics['opt_gap']):.3f}({np.std(metrics['opt_gap']):.3f})\"\n",
    "    )\n",
    "    summary[\"IneqMax\"].append(\n",
    "        f\"{np.mean(metrics['ineq_max']):.3f}({np.std(metrics['ineq_max']):.3f})\"\n",
    "    )\n",
    "    summary[\"IneqMean\"].append(\n",
    "        f\"{np.mean(metrics['ineq_mean']):.3f}({np.std(metrics['ineq_mean']):.3f})\"\n",
    "    )\n",
    "    summary[\"EqMax\"].append(\n",
    "        f\"{np.mean(metrics['eq_max']):.3f}({np.std(metrics['eq_max']):.3f})\"\n",
    "    )\n",
    "    summary[\"EqMean\"].append(\n",
    "        f\"{np.mean(metrics['eq_mean']):.3f}({np.std(metrics['eq_mean']):.3f})\"\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(summary)\n",
    "\n",
    "# For LaTeX export\n",
    "latex_table = df.to_latex(index=False, escape=False)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'experiment-output/ch5-reproduction/simple/repeat:0/dual_weights.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(data_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     11\u001b[0m dual_net \u001b[38;5;241m=\u001b[39m DualNet(args, data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m---> 12\u001b[0m dual_net\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdual_weights.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m     14\u001b[0m obj_val, known_obj, opt_gap, ineq_max, ineq_mean, eq_max, eq_mean \u001b[38;5;241m=\u001b[39m dual_evaluate(data, dual_net)\n\u001b[1;32m     15\u001b[0m dual_stats_dict[experiment][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobj\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(obj_val)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/torch/serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/torch/serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/torch/serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'experiment-output/ch5-reproduction/simple/repeat:0/dual_weights.pth'"
     ]
    }
   ],
   "source": [
    "# Get the quality of dual solutions:\n",
    "dual_stats_dict = {}\n",
    "for experiment in [\"simple\"]:\n",
    "    dual_stats_dict[experiment] = {\"obj\": [], \"known_obj\": [], \"opt_gap\": [], \"ineq_max\": [], \"ineq_mean\": [], \"eq_max\": [], \"eq_mean\": []}\n",
    "    for repeat in range(repeats):\n",
    "        directory = f\"experiment-output/ch4/ch4-reproduction/{experiment}/repeat:{repeat}\"\n",
    "        data_path = f\"data/QP_data/QP_type:{experiment}_var:100_ineq:50_eq:50_num_samples:10000.pkl\"\n",
    "\n",
    "        args = json.load(open('config.json'))\n",
    "        data = pickle.load(open(data_path, 'rb'))\n",
    "        dual_net = DualNet(args, data=data)\n",
    "        dual_net.load_state_dict(torch.load(os.path.join(directory, 'dual_weights.pth'), weights_only=True))\n",
    "\n",
    "        obj_val, known_obj, opt_gap, ineq_max, ineq_mean, eq_max, eq_mean = dual_evaluate(data, dual_net)\n",
    "        dual_stats_dict[experiment][\"obj\"].append(obj_val)\n",
    "        dual_stats_dict[experiment][\"known_obj\"].append(known_obj)\n",
    "        dual_stats_dict[experiment][\"opt_gap\"].append(opt_gap)\n",
    "        dual_stats_dict[experiment][\"ineq_max\"].append(ineq_max)\n",
    "        dual_stats_dict[experiment][\"ineq_mean\"].append(ineq_mean)\n",
    "        dual_stats_dict[experiment][\"eq_max\"].append(eq_max)\n",
    "        dual_stats_dict[experiment][\"eq_mean\"].append(eq_mean)\n",
    "\n",
    "dual_stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "Optimal Obj & Predicted Obj & OptGap (\\%) & IneqMax & IneqMean & EqMax & EqMean \\\\\n",
      "\\midrule\n",
      "-15.037 & -7.778e+03(6.240e+03) & -5.175e+04(4.162e+04) & 0.023(0.006) & 0.003(0.001) & 0.000(0.000) & 0.000(0.000) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare final summary for LaTeX export\n",
    "summary = {\n",
    "    \"Optimal Obj\": [],\n",
    "    \"Predicted Obj\": [],\n",
    "    \"OptGap (\\%)\": [],\n",
    "    \"IneqMax\": [],\n",
    "    \"IneqMean\": [],\n",
    "    \"EqMax\": [],\n",
    "    \"EqMean\": [],\n",
    "}\n",
    "\n",
    "for experiment, metrics in dual_stats_dict.items():\n",
    "    summary[\"Optimal Obj\"].append(f\"{np.mean(metrics['known_obj']):.3f}\")\n",
    "    summary[\"Predicted Obj\"].append(f\"{np.mean(metrics['obj']):.3e}({np.std(metrics['obj']):.3e})\")\n",
    "    summary[\"OptGap (\\%)\"].append(f\"{np.mean(metrics['opt_gap']):.3e}({np.std(metrics['opt_gap']):.3e})\")\n",
    "    summary[\"IneqMax\"].append(\n",
    "        f\"{np.mean(metrics['ineq_max']):.3f}({np.std(metrics['ineq_max']):.3f})\"\n",
    "    )\n",
    "    summary[\"IneqMean\"].append(\n",
    "        f\"{np.mean(metrics['ineq_mean']):.3f}({np.std(metrics['ineq_mean']):.3f})\"\n",
    "    )\n",
    "    summary[\"EqMax\"].append(\n",
    "        f\"{np.mean(metrics['eq_max']):.3f}({np.std(metrics['eq_max']):.3f})\"\n",
    "    )\n",
    "    summary[\"EqMean\"].append(\n",
    "        f\"{np.mean(metrics['eq_mean']):.3f}({np.std(metrics['eq_mean']):.3f})\"\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(summary)\n",
    "\n",
    "# For LaTeX export\n",
    "latex_table = df.to_latex(index=False, escape=False)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Detailed evaluation metrics per repeat and problem type.}\n",
      "\\label{tab:detailed-results}\n",
      "\\begin{tabular}{llccccc}\n",
      "\\toprule\n",
      " &  & simple & column & row & random & obj \\\\\n",
      "Repeat & Metric &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{7}{*}{Repeat 0} & Predicted & -14.920 & -14.454 & -14.682 & -14.343 & -14.462 \\\\\n",
      " & Optimal & -15.037 & -15.358 & -15.570 & -15.602 & -15.630 \\\\\n",
      " & Gap (\\%) & 0.783 & 5.842 & 5.702 & 8.041 & 7.494 \\\\\n",
      " & Ineq. Max & 0.011 & 0.072 & 0.062 & 0.057 & 0.017 \\\\\n",
      " & Ineq. Mean & 0.001 & 0.003 & 0.003 & 0.002 & 0.001 \\\\\n",
      " & Eq. Max & 0.011 & 0.105 & 0.104 & 0.112 & 0.015 \\\\\n",
      " & Eq. Mean & 0.003 & 0.033 & 0.033 & 0.036 & 0.005 \\\\\n",
      "\\cline{1-7}\n",
      "\\multirow[t]{7}{*}{Repeat 1} & Predicted & -15.042 & -15.336 & -15.679 & -15.577 & -14.613 \\\\\n",
      " & Optimal & -15.037 & -15.358 & -15.570 & -15.602 & -15.630 \\\\\n",
      " & Gap (\\%) & -0.029 & 0.136 & -0.702 & 0.164 & 6.550 \\\\\n",
      " & Ineq. Max & 0.042 & 0.290 & 0.140 & 0.118 & 0.106 \\\\\n",
      " & Ineq. Mean & 0.004 & 0.016 & 0.008 & 0.006 & 0.005 \\\\\n",
      " & Eq. Max & 0.044 & 0.038 & 0.106 & 0.031 & 0.022 \\\\\n",
      " & Eq. Mean & 0.014 & 0.010 & 0.032 & 0.009 & 0.007 \\\\\n",
      "\\cline{1-7}\n",
      "\\multirow[t]{7}{*}{Repeat 2} & Predicted & -14.965 & -15.236 & -15.584 & -15.526 & -14.594 \\\\\n",
      " & Optimal & -15.037 & -15.358 & -15.570 & -15.602 & -15.630 \\\\\n",
      " & Gap (\\%) & 0.485 & 0.784 & -0.089 & 0.488 & 6.672 \\\\\n",
      " & Ineq. Max & 0.033 & 0.122 & 0.127 & 0.131 & 0.047 \\\\\n",
      " & Ineq. Mean & 0.001 & 0.005 & 0.006 & 0.007 & 0.002 \\\\\n",
      " & Eq. Max & 0.023 & 0.010 & 0.066 & 0.027 & 0.011 \\\\\n",
      " & Eq. Mean & 0.007 & 0.003 & 0.021 & 0.010 & 0.003 \\\\\n",
      "\\cline{1-7}\n",
      "\\multirow[t]{7}{*}{Repeat 3} & Predicted & -14.976 & -14.446 & -14.785 & -14.004 & -14.198 \\\\\n",
      " & Optimal & -15.037 & -15.358 & -15.570 & -15.602 & -15.630 \\\\\n",
      " & Gap (\\%) & 0.411 & 5.891 & 5.044 & 10.227 & 9.197 \\\\\n",
      " & Ineq. Max & 0.001 & 0.070 & 0.061 & 0.006 & 0.004 \\\\\n",
      " & Ineq. Mean & 0.000 & 0.003 & 0.003 & 0.000 & 0.000 \\\\\n",
      " & Eq. Max & 0.007 & 0.095 & 0.102 & 0.008 & 0.010 \\\\\n",
      " & Eq. Mean & 0.002 & 0.030 & 0.032 & 0.003 & 0.003 \\\\\n",
      "\\cline{1-7}\n",
      "\\multirow[t]{7}{*}{Repeat 4} & Predicted & -14.820 & -14.413 & -15.024 & -14.368 & -14.300 \\\\\n",
      " & Optimal & -15.037 & -15.358 & -15.570 & -15.602 & -15.630 \\\\\n",
      " & Gap (\\%) & 1.450 & 6.109 & 3.505 & 7.886 & 8.522 \\\\\n",
      " & Ineq. Max & 0.008 & 0.071 & 0.078 & 0.056 & 0.009 \\\\\n",
      " & Ineq. Mean & 0.000 & 0.004 & 0.004 & 0.002 & 0.000 \\\\\n",
      " & Eq. Max & 0.005 & 0.100 & 0.110 & 0.111 & 0.009 \\\\\n",
      " & Eq. Mean & 0.001 & 0.032 & 0.034 & 0.035 & 0.003 \\\\\n",
      "\\cline{1-7}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Mapping of original metric keys to display names\n",
    "metric_names = {\n",
    "    'predicted_obj': 'Predicted',\n",
    "    'known_obj': 'Optimal',\n",
    "    'opt_gap': 'Gap (\\\\%)',\n",
    "    'ineq_max': 'Ineq. Max',\n",
    "    'ineq_mean': 'Ineq. Mean',\n",
    "    'eq_max': 'Eq. Max',\n",
    "    'eq_mean': 'Eq. Mean'\n",
    "}\n",
    "\n",
    "metrics = list(metric_names.keys())\n",
    "problem_types = list(stats_dict.keys())\n",
    "repeats = range(len(stats_dict[problem_types[0]][metrics[0]]))\n",
    "\n",
    "# Prepare multi-indexed rows: (Repeat, Renamed Metric)\n",
    "rows = []\n",
    "for r in repeats:\n",
    "    for m in metrics:\n",
    "        rows.append((f\"Repeat {r}\", metric_names[m]))\n",
    "\n",
    "# Create DataFrame with multi-index rows and problem type columns\n",
    "df = pd.DataFrame(index=pd.MultiIndex.from_tuples(rows, names=[\"Repeat\", \"Metric\"]),\n",
    "                  columns=problem_types)\n",
    "\n",
    "# Fill in the values\n",
    "for problem in problem_types:\n",
    "    for r in repeats:\n",
    "        for m in metrics:\n",
    "            df.loc[(f\"Repeat {r}\", metric_names[m]), problem] = stats_dict[problem][m][r]\n",
    "\n",
    "# Convert to LaTeX with booktabs\n",
    "latex_table = df.to_latex(\n",
    "    escape=False,\n",
    "    multirow=True,\n",
    "    column_format='ll' + 'c' * len(problem_types),\n",
    "    bold_rows=False,\n",
    "    index_names=True,\n",
    "    header=True,\n",
    "    float_format=\"%.3f\",\n",
    "    caption=\"Detailed evaluation metrics per repeat and problem type.\",\n",
    "    label=\"tab:detailed-results\",\n",
    "    longtable=False,\n",
    "    na_rep=''\n",
    ")\n",
    "\n",
    "print(latex_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
