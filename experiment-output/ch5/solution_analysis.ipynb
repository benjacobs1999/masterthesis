{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-49.90105061012176\n",
      "-58.91226511042528\n",
      "-47.921306094546\n",
      "-45.96869649013062\n",
      "-50.64556047482254\n",
      "0.40812335738910627\n",
      "0.44547749360923233\n",
      "0.40370662507099686\n",
      "0.43780031072718784\n",
      "0.46232394769137786\n",
      "8.256309104656675e-13\n",
      "2.7156688389057762e-11\n",
      "4.394320472737566e-07\n",
      "2.250474916434122e-12\n",
      "3.041330670556621e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'plain': {'diff_p_gt': [10075.475045903975,\n",
       "   10004.315618317654,\n",
       "   10179.293396331419,\n",
       "   10047.53476991365,\n",
       "   10098.479836578315],\n",
       "  'diff_f_lt': [1343.156907958611,\n",
       "   1356.1407105858486,\n",
       "   1367.4201764725065,\n",
       "   1401.2697301379567,\n",
       "   1391.5394267149773],\n",
       "  'diff_md_nt': [18490.90492003821,\n",
       "   18500.852954332062,\n",
       "   18716.054191817708,\n",
       "   18458.031978107476,\n",
       "   18592.37045768122],\n",
       "  'diff_net_flow': [2136.0289176787105,\n",
       "   2161.3123978706903,\n",
       "   2164.63218336952,\n",
       "   2234.156170104473,\n",
       "   2261.4196811809525],\n",
       "  'cheapest_generator_fraction': [-49.90105061012176,\n",
       "   -58.91226511042528,\n",
       "   -47.921306094546,\n",
       "   -45.96869649013062,\n",
       "   -50.64556047482254]},\n",
       " 'repair1': {'diff_p_gt': [3974.1528328290456,\n",
       "   4181.689459800387,\n",
       "   3989.098713051427,\n",
       "   4150.2755811507295,\n",
       "   4240.989190936368],\n",
       "  'diff_f_lt': [3286.6591298079716,\n",
       "   3122.5127037874977,\n",
       "   2861.358196424854,\n",
       "   3023.369516608,\n",
       "   3178.379504149183],\n",
       "  'diff_md_nt': [1620.7183056929,\n",
       "   1787.41541250516,\n",
       "   1527.8617414388193,\n",
       "   1783.1798996898635,\n",
       "   1894.9495669523194],\n",
       "  'diff_net_flow': [4737.525836555615,\n",
       "   4650.847024625747,\n",
       "   4636.702469333379,\n",
       "   4697.672272830583,\n",
       "   4779.999547951483],\n",
       "  'cheapest_generator_fraction': [0.40812335738910627,\n",
       "   0.44547749360923233,\n",
       "   0.40370662507099686,\n",
       "   0.43780031072718784,\n",
       "   0.46232394769137786]},\n",
       " 'repair2': {'diff_p_gt': [105.61077408803767,\n",
       "   113.0041744428258,\n",
       "   212.3127400449814,\n",
       "   99.85479240783803,\n",
       "   137.54372530521675],\n",
       "  'diff_f_lt': [115.69778446636379,\n",
       "   123.41719440692975,\n",
       "   223.35839328587412,\n",
       "   111.00414186456973,\n",
       "   147.4656168805544],\n",
       "  'diff_md_nt': [19.968948073882693,\n",
       "   20.55694775411019,\n",
       "   21.30825582603515,\n",
       "   21.26986594153688,\n",
       "   19.559749288105614],\n",
       "  'diff_net_flow': [231.19049624148698,\n",
       "   246.5652964573544,\n",
       "   445.92839609831105,\n",
       "   220.9794507332311,\n",
       "   294.6469104707917],\n",
       "  'cheapest_generator_fraction': [8.256309104656675e-13,\n",
       "   2.7156688389057762e-11,\n",
       "   4.394320472737566e-07,\n",
       "   2.250474916434122e-12,\n",
       "   3.041330670556621e-08]}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from networks import DualNet, DualNetEndToEnd, PrimalNet, PrimalNetEndToEnd\n",
    "import torch\n",
    "\n",
    "\n",
    "data_path = f\"experiment-output/ch6/ED_NB-G-F_GB2-G2-F2_L3_c0_s0_p0_smp15.pkl\"\n",
    "data = pickle.load(open(data_path, 'rb'))\n",
    "\n",
    "indices = torch.arange(data.X.shape[0])\n",
    "\n",
    "repeats = 5\n",
    "\n",
    "stats_dict = {}\n",
    "\n",
    "for run, (path, name) in enumerate(zip([\n",
    "            # \"experiment-output/ch5/plain-PDL/learn_primal:True_train:0.8_rho:0.5_rhomax:5000_alpha:10_L:10-1746265816-296861\",\n",
    "            # \"experiment-output/ch5/repair-1/learn_primal:True_train:0.8_rho:0.5_rhomax:5000_alpha:10_L:10-1746429988-424426\",\n",
    "            \"experiment-output/ch5/repair-2/learn_primal:True_train:0.8_rho:0.5_rhomax:5000_alpha:10_L:10-1746434902-974866\"],\n",
    "            [\n",
    "                \"plain\",\n",
    "                \"repair1\",\n",
    "                \"repair2\"\n",
    "                ])):\n",
    "    stats_dict[name] = {\"diff_p_gt\": [], \"diff_f_lt\": [], \"diff_md_nt\": [], \"diff_net_flow\": [], \"cheapest_generator_fraction\": []}\n",
    "    with open(os.path.join(path, 'args.json'), 'r') as f:\n",
    "        args = json.load(f)\n",
    "    # Compute sizes for each set\n",
    "    train_size = int(args[\"train\"] * data.X.shape[0])\n",
    "    valid_size = int(args[\"valid\"] * data.X.shape[0])\n",
    "    # print(f\"Train size: {train_size}, Valid size: {valid_size}, Test size: {data.X.shape[0] - train_size - valid_size}\")\n",
    "\n",
    "\n",
    "    # Split the indices\n",
    "    train_indices = indices[:train_size]\n",
    "    valid_indices = indices[train_size:train_size+valid_size]\n",
    "    test_indices = indices[train_size+valid_size:]\n",
    "\n",
    "    for i, repeat in enumerate(range(repeats)):\n",
    "        \n",
    "        directory = os.path.join(path, f\"repeat:{repeat}\")\n",
    "        # directory = f\"experiment-output/ch5-reproduction-nonconvex/{experiment}/repeat:{repeat}\"\n",
    "        # dual_net = DualNet(args, data=data)\n",
    "        # dual_net.load_state_dict(torch.load(os.path.join(directory, 'dual_weights.pth'), weights_only=True))\n",
    "\n",
    "        primal_net = PrimalNetEndToEnd(args, data=data)\n",
    "        primal_net.load_state_dict(torch.load(os.path.join(directory, 'primal_weights.pth'), weights_only=True))\n",
    "        X_test = data.X[test_indices]\n",
    "        Y = primal_net(X_test)\n",
    "        p_gt, f_lt, md_nt = data.split_dec_vars_from_Y(Y)\n",
    "        p_gt_target, f_lt_target, md_nt_target = data.split_dec_vars_from_Y(data.opt_targets[\"y_operational\"][test_indices])\n",
    "        diff_p_gt = p_gt - p_gt_target\n",
    "        diff_f_lt = f_lt - f_lt_target\n",
    "        diff_md_nt = md_nt - md_nt_target\n",
    "\n",
    "        net_flow = data.net_flow(f_lt)\n",
    "        net_flow_target = data.net_flow(f_lt_target)\n",
    "        diff_net_flow = net_flow - net_flow_target\n",
    "\n",
    "        costs = data.cost_vec\n",
    "        generators = [\"BEL-WindOff\", \"BEL-Gas\", \"GER-Gas\", \"GER-SunPV\", \"FRA-Nuclear\", \"FRA-SunPV\"]\n",
    "        cheapest_generators_indices = [0, 3, 5] # BEL-WindOff, GER-SunPV, FRA-SunPV\n",
    "        eq_rhs, ineq_rhs = data.split_X(X_test)\n",
    "        p_gt_ub = ineq_rhs[:, data.capacity_ub_indices]\n",
    "        demand = eq_rhs\n",
    "\n",
    "        effective_demand = demand - net_flow\n",
    "\n",
    "        cap = torch.min(p_gt_ub[:, cheapest_generators_indices], effective_demand)\n",
    "        diff = (cap - p_gt[:, cheapest_generators_indices])\n",
    "        fraction = diff / torch.where(cap == 0, torch.ones_like(cap), cap)\n",
    "        print(fraction.mean().item())\n",
    "\n",
    "        \n",
    "        # cheapest_generator_fraction = data.cost_vec\n",
    "\n",
    "        stats_dict[name][\"diff_p_gt\"].append(diff_p_gt.abs().mean().item())\n",
    "        stats_dict[name][\"diff_f_lt\"].append(diff_f_lt.abs().mean().item())\n",
    "        stats_dict[name][\"diff_md_nt\"].append(diff_md_nt.abs().mean().item())\n",
    "        stats_dict[name][\"diff_net_flow\"].append(diff_net_flow.abs().mean().item())\n",
    "        stats_dict[name][\"cheapest_generator_fraction\"].append(fraction.mean().item())\n",
    "\n",
    "\n",
    "stats_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "Experiment & Production diff. & Unmet demand diff. & Net flow diff. & Expensive generation (\\%) \\\\\n",
      "\\midrule\n",
      "plain & 10081.020(58.306) & 18551.643(93.511) & 2191.510(47.788) & -50.670(4.431) \\\\\n",
      "repair1 & 4107.241(106.727) & 1722.825(131.056) & 4700.549(53.357) & 0.431(0.022) \\\\\n",
      "repair2 & 133.665(41.370) & 20.533(0.694) & 287.862(82.972) & 0.000(0.000) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare separate dictionaries\n",
    "summary = {\"Experiment\": [], \"Production diff.\": [], \"Unmet demand diff.\": [], \"Net flow diff.\": [], \"Expensive generation (\\%)\": []}\n",
    "\n",
    "# {\"diff_p_gt\": [], \"diff_f_lt\": [], \"diff_md_nt\": [], \"diff_net_flow\": [], \"cheapest_generator_fraction\": []}\n",
    "\n",
    "for experiment, metrics in stats_dict.items():\n",
    "    summary[\"Experiment\"].append(experiment)\n",
    "    summary[\"Production diff.\"].append(f\"{np.mean(metrics['diff_p_gt']):.3f}({np.std(metrics['diff_p_gt']):.3f})\")\n",
    "    summary[\"Unmet demand diff.\"].append(f\"{np.mean(metrics['diff_md_nt']):.3f}({np.std(metrics['diff_md_nt']):.3f})\")\n",
    "    summary[\"Net flow diff.\"].append(f\"{np.mean(metrics['diff_net_flow']):.3f}({np.std(metrics['diff_net_flow']):.3f})\")\n",
    "    summary[\"Expensive generation (\\%)\"].append(f\"{np.mean(metrics['cheapest_generator_fraction']):.3f}({np.std(metrics['cheapest_generator_fraction']):.3f})\")\n",
    "    # summary[\"Optimal Obj\"].append(f\"{np.mean(metrics['known_obj']):.3f}\")\n",
    "    # summary[\"Predicted Obj\"].append(f\"{np.mean(metrics['predicted_obj']):.3f}({np.std(metrics['predicted_obj']):.3f})\")\n",
    "    # summary[\"OptGap (%)\"].append(f\"{np.mean(metrics['opt_gap']):.3f}({np.std(metrics['opt_gap']):.3f})\")\n",
    "\n",
    "# Convert to DataFrames\n",
    "df = pd.DataFrame(summary)\n",
    "\n",
    "# Export LaTeX tables\n",
    "latex = df.to_latex(index=False, escape=False)\n",
    "\n",
    "# Print or write to file\n",
    "print(latex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
