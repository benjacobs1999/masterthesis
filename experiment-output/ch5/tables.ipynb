{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plain': {'predicted_obj': [580758.5351998126,\n",
       "   581083.1590021455,\n",
       "   587482.3326299866,\n",
       "   579808.4090965808,\n",
       "   583797.6818510024],\n",
       "  'known_obj': [29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353],\n",
       "  'opt_gap': [27147.033742255993,\n",
       "   27201.863736968095,\n",
       "   27582.622625330096,\n",
       "   27117.294229637882,\n",
       "   27308.003290197455],\n",
       "  'ineq_max': [733.3549474928487,\n",
       "   710.2317741345363,\n",
       "   717.9885632817337,\n",
       "   690.84895627334,\n",
       "   705.2897597300049],\n",
       "  'ineq_mean': [47.901823439143556,\n",
       "   47.49453504264879,\n",
       "   48.11683648239214,\n",
       "   44.95477305810415,\n",
       "   45.72852197144265],\n",
       "  'eq_max': [5275.147910347814,\n",
       "   5282.5232458591245,\n",
       "   5276.657273662975,\n",
       "   5245.223561323329,\n",
       "   5258.769845485163],\n",
       "  'eq_mean': [3265.6219828309813,\n",
       "   3269.086215022933,\n",
       "   3267.721519074557,\n",
       "   3249.5503832912545,\n",
       "   3254.7257394147246],\n",
       "  'relative_ineq_max': [182.44932251039745,\n",
       "   171.48415127667627,\n",
       "   160.9192183306484,\n",
       "   163.51013668670026,\n",
       "   156.25212247976447],\n",
       "  'relative_ineq_mean': [11.04174589474988,\n",
       "   11.065954050466477,\n",
       "   10.254427511118509,\n",
       "   9.928442068845923,\n",
       "   9.745149777999334],\n",
       "  'relative_eq_max': [0.16931810029530966,\n",
       "   0.16971650379147807,\n",
       "   0.16967493579226736,\n",
       "   0.16853649762119352,\n",
       "   0.16939077512677844],\n",
       "  'relative_eq_mean': [0.1356742583549755,\n",
       "   0.13601285484922385,\n",
       "   0.13574221854440105,\n",
       "   0.13521794914834448,\n",
       "   0.13555178321695927]},\n",
       " 'repair1': {'predicted_obj': [77805.52911809871,\n",
       "   82961.72943076577,\n",
       "   75259.51106416658,\n",
       "   82745.77131237618,\n",
       "   86162.92919163732],\n",
       "  'known_obj': [29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353],\n",
       "  'opt_gap': [2391.0785263355797,\n",
       "   2647.2683356662533,\n",
       "   2325.9507748597825,\n",
       "   2566.7315389988535,\n",
       "   2904.905692784076],\n",
       "  'ineq_max': [38.29136223869248,\n",
       "   31.910467032812367,\n",
       "   52.33959099694861,\n",
       "   19.758458439596062,\n",
       "   30.86284923105958],\n",
       "  'ineq_mean': [1.738273979285016,\n",
       "   1.4315782103153671,\n",
       "   2.2617220087691154,\n",
       "   0.8697654294390357,\n",
       "   1.3636967800570399],\n",
       "  'eq_max': [2.428417442729577e-12,\n",
       "   2.5009717028008466e-12,\n",
       "   2.57408087117094e-12,\n",
       "   2.3597475407500776e-12,\n",
       "   2.48113373111788e-12],\n",
       "  'eq_mean': [9.15367481268818e-13,\n",
       "   9.596676604582864e-13,\n",
       "   9.91389918207739e-13,\n",
       "   9.122692432670494e-13,\n",
       "   9.41401928955322e-13],\n",
       "  'relative_ineq_max': [0.002129311425052415,\n",
       "   0.0021572900297028735,\n",
       "   0.002747657540989785,\n",
       "   0.001550800975625759,\n",
       "   0.0018475471817199559],\n",
       "  'relative_ineq_mean': [9.463800971697166e-05,\n",
       "   9.762385241208764e-05,\n",
       "   0.00011981963343291795,\n",
       "   6.718326529931527e-05,\n",
       "   8.133704310873063e-05],\n",
       "  'relative_eq_max': [6.75632950147058e-17,\n",
       "   7.059931703284386e-17,\n",
       "   7.735237325192418e-17,\n",
       "   7.083535737447588e-17,\n",
       "   7.17506682411178e-17],\n",
       "  'relative_eq_mean': [2.595839071023928e-17,\n",
       "   2.7960201383121464e-17,\n",
       "   3.147571334093374e-17,\n",
       "   2.853070103807615e-17,\n",
       "   2.7994772486016254e-17]},\n",
       " 'repair2': {'predicted_obj': [29320.701378953818,\n",
       "   29306.264214554412,\n",
       "   29308.85605040716,\n",
       "   29306.799569512365,\n",
       "   29307.607026679736],\n",
       "  'known_obj': [29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353,\n",
       "   29293.887262458353],\n",
       "  'opt_gap': [1.1146874287282746,\n",
       "   0.5543363309689753,\n",
       "   0.6656681385097288,\n",
       "   0.5687649741900886,\n",
       "   0.6225306390296823],\n",
       "  'ineq_max': [1.4273526771073178e-12,\n",
       "   1.418578257369989e-12,\n",
       "   2.7977262564814467e-12,\n",
       "   1.955934736255075e-12,\n",
       "   2.545391766658797e-12],\n",
       "  'ineq_mean': [6.680325484706176e-14,\n",
       "   6.574462829160778e-14,\n",
       "   1.35983602296378e-13,\n",
       "   8.981048764597144e-14,\n",
       "   1.23968414285692e-13],\n",
       "  'eq_max': [5.956940587878209e-13,\n",
       "   6.201100239360874e-13,\n",
       "   1.4829924286077797e-12,\n",
       "   6.317630982113965e-13,\n",
       "   6.589536048537841e-13],\n",
       "  'eq_mean': [2.0300395265320085e-13,\n",
       "   2.1502696579439273e-13,\n",
       "   5.548158141077686e-13,\n",
       "   2.2066853349910582e-13,\n",
       "   2.3407881738735825e-13],\n",
       "  'relative_ineq_max': [1.428987649690942e-16,\n",
       "   1.4044619330690786e-16,\n",
       "   1.7442697137502448e-16,\n",
       "   1.5239380115862092e-16,\n",
       "   1.6589348471930163e-16],\n",
       "  'relative_ineq_mean': [6.5465553477406036e-18,\n",
       "   6.392056260228964e-18,\n",
       "   8.457283159960972e-18,\n",
       "   7.095430388194482e-18,\n",
       "   7.996551108940433e-18],\n",
       "  'relative_eq_max': [1.8753101671676684e-17,\n",
       "   1.9497481796149596e-17,\n",
       "   5.67113899812761e-17,\n",
       "   1.9744609350432795e-17,\n",
       "   2.1522944453333326e-17],\n",
       "  'relative_eq_mean': [6.5943984280748675e-18,\n",
       "   6.99840014865022e-18,\n",
       "   2.189543771428189e-17,\n",
       "   7.065545392975252e-18,\n",
       "   7.871463152799254e-18]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from networks import DualNet, DualNetEndToEnd, PrimalNet, PrimalNetEndToEnd, PrimalNetEndToEnd2\n",
    "import torch\n",
    "\n",
    "def evaluate(data, primal_net, test_indices):        \n",
    "    X = data.X[test_indices]\n",
    "    Y_target = data.opt_targets[\"y_operational\"][test_indices]\n",
    "    \n",
    "    # Forward pass through networks\n",
    "    Y = primal_net(X)\n",
    "\n",
    "    ineq_dist = data.ineq_dist(X, Y)\n",
    "    eq_resid = data.eq_resid(X, Y)\n",
    "\n",
    "    relative_ineq_dist = data.relative_ineq_dist(X, Y)\n",
    "    relative_eq_resid = data.relative_eq_resid(X, Y)\n",
    "\n",
    "    # Convert lists to arrays for easier handling\n",
    "    obj_values = data.obj_fn(X, Y).detach().numpy()\n",
    "    ineq_max_vals = torch.max(ineq_dist, dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    ineq_mean_vals = torch.mean(ineq_dist, dim=1).detach().numpy()\n",
    "    eq_max_vals = torch.max(torch.abs(eq_resid), dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    eq_mean_vals = torch.mean(torch.abs(eq_resid), dim=1).detach().numpy()\n",
    "\n",
    "    relative_ineq_max_vals = torch.max(relative_ineq_dist, dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    relative_ineq_mean_vals = torch.mean(relative_ineq_dist, dim=1).detach().numpy()\n",
    "    relative_eq_max_vals = torch.max(torch.abs(relative_eq_resid), dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    relative_eq_mean_vals = torch.mean(torch.abs(relative_eq_resid), dim=1).detach().numpy()\n",
    "\n",
    "    known_obj = data.obj_fn(X, Y_target).detach().numpy()\n",
    "    # obj_values is negative\n",
    "    opt_gap = (obj_values - known_obj)/np.abs(known_obj) * 100\n",
    "\n",
    "    return np.mean(obj_values), np.mean(known_obj), np.mean(opt_gap), np.mean(ineq_max_vals), np.mean(relative_ineq_max_vals), np.mean(ineq_mean_vals), np.mean(relative_ineq_mean_vals), np.mean(eq_max_vals), np.mean(relative_eq_max_vals), np.mean(eq_mean_vals), np.mean(relative_eq_mean_vals)\n",
    "\n",
    "def dual_evaluate(data, dual_net, test_indices):\n",
    "    X = data.X[test_indices]\n",
    "    # target_mu = data.mu[test_indices]\n",
    "    # target_lamb = data.lamb[test_indices]\n",
    "    target_mu = data.opt_targets[\"mu_operational\"][test_indices]  \n",
    "    target_lamb = data.opt_targets[\"lamb_operational\"][test_indices]\n",
    "    print(X.dtype)\n",
    "    print(dual_net.net[0].weight.dtype)\n",
    "\n",
    "    # Forward pass through networks\n",
    "    mu, lamb = dual_net(X)\n",
    "\n",
    "    obj_values = data.dual_obj_fn(X, mu, lamb).detach().numpy()\n",
    "    known_obj = data.dual_obj_fn(X, target_mu, target_lamb).detach().numpy()\n",
    "    # dual_ineq_dist = data.dual_ineq_dist(mu, lamb)\n",
    "    dual_ineq_resid = data.dual_ineq_resid(mu, lamb)\n",
    "    dual_ineq_dist = torch.clamp(dual_ineq_resid, 0)\n",
    "    dual_eq_resid = data.dual_eq_resid(mu, lamb)\n",
    "\n",
    "    opt_gap = (obj_values - known_obj)/np.abs(known_obj) * 100\n",
    "\n",
    "    ineq_max_vals = torch.max(dual_ineq_dist, dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    eq_max_vals = torch.max(torch.abs(dual_eq_resid), dim=1)[0].detach().numpy() # First element is the max, second is the index\n",
    "    ineq_mean_vals = torch.mean(dual_ineq_dist, dim=1).detach().numpy()\n",
    "    eq_mean_vals = torch.mean(torch.abs(dual_eq_resid), dim=1).detach().numpy()\n",
    "\n",
    "    return np.mean(obj_values), np.mean(known_obj), np.mean(opt_gap), np.mean(ineq_max_vals), np.mean(ineq_mean_vals), np.mean(eq_max_vals), np.mean(eq_mean_vals)\n",
    "\n",
    "repeats = 5\n",
    "stats_dict = {}\n",
    "\n",
    "# args = json.load(open('config.json'))\n",
    "data_path = f\"experiment-output/ch6/ED_NB-G-F_GB2-G2-F2_L3_c0_s0_p0_smp15.pkl\"\n",
    "data = pickle.load(open(data_path, 'rb'))\n",
    "\n",
    "indices = torch.arange(data.X.shape[0])\n",
    "\n",
    "for run, (path, name) in enumerate(zip([\"experiment-output/ch5/plain-PDL/learn_primal:True_train:0.8_rho:0.5_rhomax:5000_alpha:10_L:10-1746265816-296861\",\n",
    "             \"experiment-output/ch5/repair-1/learn_primal:True_train:0.8_rho:0.5_rhomax:5000_alpha:10_L:10-1746429988-424426\",\n",
    "             \"experiment-output/ch5/repair-2/learn_primal:True_train:0.8_rho:0.5_rhomax:5000_alpha:10_L:10-1746434902-974866\"],\n",
    "            [\"plain\", \"repair1\", \"repair2\"])):\n",
    "    stats_dict[name] = {\"predicted_obj\": [], \"known_obj\": [], \"opt_gap\": [], \"ineq_max\": [], \"ineq_mean\": [], \"eq_max\": [], \"eq_mean\": [], \"relative_ineq_max\": [], \"relative_ineq_mean\": [], \"relative_eq_max\": [], \"relative_eq_mean\": []}\n",
    "    with open(os.path.join(path, 'args.json'), 'r') as f:\n",
    "        args = json.load(f)\n",
    "    # Compute sizes for each set\n",
    "    train_size = int(args[\"train\"] * data.X.shape[0])\n",
    "    valid_size = int(args[\"valid\"] * data.X.shape[0])\n",
    "    # print(f\"Train size: {train_size}, Valid size: {valid_size}, Test size: {data.X.shape[0] - train_size - valid_size}\")\n",
    "\n",
    "\n",
    "    # Split the indices\n",
    "    train_indices = indices[:train_size]\n",
    "    valid_indices = indices[train_size:train_size+valid_size]\n",
    "    test_indices = indices[train_size+valid_size:]\n",
    "\n",
    "    for i, repeat in enumerate(range(repeats)):\n",
    "        \n",
    "        directory = os.path.join(path, f\"repeat:{repeat}\")\n",
    "        # directory = f\"experiment-output/ch5-reproduction-nonconvex/{experiment}/repeat:{repeat}\"\n",
    "        # dual_net = DualNet(args, data=data)\n",
    "        # dual_net.load_state_dict(torch.load(os.path.join(directory, 'dual_weights.pth'), weights_only=True))\n",
    "\n",
    "        primal_net = PrimalNetEndToEnd2(args, data=data)\n",
    "        primal_net.load_state_dict(torch.load(os.path.join(directory, 'primal_weights.pth'), weights_only=True))\n",
    "        # obj_val, known_obj, opt_gap, ineq_max, ineq_mean, eq_max, eq_mean = dual_evaluate(data, dual_net, test_indices)\n",
    "        obj_val, known_obj, opt_gap, ineq_max, relative_ineq_max, ineq_mean, relative_ineq_mean, eq_max, relative_eq_max, eq_mean, relative_eq_mean = evaluate(data, primal_net, test_indices)\n",
    "        stats_dict[name][\"predicted_obj\"].append(obj_val)\n",
    "        stats_dict[name][\"known_obj\"].append(known_obj)\n",
    "        stats_dict[name][\"opt_gap\"].append(opt_gap)\n",
    "        stats_dict[name][\"ineq_max\"].append(ineq_max)\n",
    "        stats_dict[name][\"ineq_mean\"].append(ineq_mean)\n",
    "        stats_dict[name][\"eq_max\"].append(eq_max)\n",
    "        stats_dict[name][\"eq_mean\"].append(eq_mean)\n",
    "        stats_dict[name][\"relative_ineq_max\"].append(relative_ineq_max)\n",
    "        stats_dict[name][\"relative_ineq_mean\"].append(relative_ineq_mean)\n",
    "        stats_dict[name][\"relative_eq_max\"].append(relative_eq_max)\n",
    "        stats_dict[name][\"relative_eq_mean\"].append(relative_eq_mean)\n",
    "\n",
    "\n",
    "stats_dict\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Objective Table\n",
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "Experiment & Optimal Obj & Predicted Obj & OptGap (%) \\\\\n",
      "\\midrule\n",
      "plain & 29293.887 & 582586.024(2784.077) & 27271.364(168.671) \\\\\n",
      "repair1 & 29293.887 & 80987.094(3916.860) & 2567.187(204.781) \\\\\n",
      "repair2 & 29293.887 & 29310.046(5.399) & 0.705(0.209) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "% Regular Constraint Table\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "Experiment & IneqMax & IneqMean & EqMax & EqMean \\\\\n",
      "\\midrule\n",
      "plain & 711.543(14.045) & 46.839(1.263) & 5267.664(13.714) & 3261.341(7.769) \\\\\n",
      "repair1 & 34.633(10.675) & 1.533(0.459) & 0.000(0.000) & 0.000(0.000) \\\\\n",
      "repair2 & 0.000(0.000) & 0.000(0.000) & 0.000(0.000) & 0.000(0.000) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "% Relative Constraint Table\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "Experiment & Relative IneqMax & Relative IneqMean & Relative EqMax & Relative EqMean \\\\\n",
      "\\midrule\n",
      "plain & 166.923(9.203) & 10.407(0.553) & 0.169(0.000) & 0.136(0.000) \\\\\n",
      "repair1 & 0.002(0.000) & 0.000(0.000) & 0.000(0.000) & 0.000(0.000) \\\\\n",
      "repair2 & 0.000(0.000) & 0.000(0.000) & 0.000(0.000) & 0.000(0.000) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare separate dictionaries\n",
    "objective_summary = {\"Experiment\": [], \"Optimal Obj\": [], \"Predicted Obj\": [], \"OptGap (%)\": []}\n",
    "regular_summary = {\"Experiment\": [], \"IneqMax\": [], \"IneqMean\": [], \"EqMax\": [], \"EqMean\": []}\n",
    "relative_summary = {\"Experiment\": [], \"Relative IneqMax\": [], \"Relative IneqMean\": [], \"Relative EqMax\": [], \"Relative EqMean\": []}\n",
    "\n",
    "for experiment, metrics in stats_dict.items():\n",
    "    objective_summary[\"Experiment\"].append(experiment)\n",
    "    objective_summary[\"Optimal Obj\"].append(f\"{np.mean(metrics['known_obj']):.3f}\")\n",
    "    objective_summary[\"Predicted Obj\"].append(f\"{np.mean(metrics['predicted_obj']):.3f}({np.std(metrics['predicted_obj']):.3f})\")\n",
    "    objective_summary[\"OptGap (%)\"].append(f\"{np.mean(metrics['opt_gap']):.3f}({np.std(metrics['opt_gap']):.3f})\")\n",
    "\n",
    "    regular_summary[\"Experiment\"].append(experiment)\n",
    "    regular_summary[\"IneqMax\"].append(f\"{np.mean(metrics['ineq_max']):.3f}({np.std(metrics['ineq_max']):.3f})\")\n",
    "    regular_summary[\"IneqMean\"].append(f\"{np.mean(metrics['ineq_mean']):.3f}({np.std(metrics['ineq_mean']):.3f})\")\n",
    "    regular_summary[\"EqMax\"].append(f\"{np.mean(metrics['eq_max']):.3f}({np.std(metrics['eq_max']):.3f})\")\n",
    "    regular_summary[\"EqMean\"].append(f\"{np.mean(metrics['eq_mean']):.3f}({np.std(metrics['eq_mean']):.3f})\")\n",
    "\n",
    "    relative_summary[\"Experiment\"].append(experiment)\n",
    "    relative_summary[\"Relative IneqMax\"].append(f\"{np.mean(metrics['relative_ineq_max']):.3f}({np.std(metrics['relative_ineq_max']):.3f})\")\n",
    "    relative_summary[\"Relative IneqMean\"].append(f\"{np.mean(metrics['relative_ineq_mean']):.3f}({np.std(metrics['relative_ineq_mean']):.3f})\")\n",
    "    relative_summary[\"Relative EqMax\"].append(f\"{np.mean(metrics['relative_eq_max']):.3f}({np.std(metrics['relative_eq_max']):.3f})\")\n",
    "    relative_summary[\"Relative EqMean\"].append(f\"{np.mean(metrics['relative_eq_mean']):.3f}({np.std(metrics['relative_eq_mean']):.3f})\")\n",
    "\n",
    "# Convert to DataFrames\n",
    "df_obj = pd.DataFrame(objective_summary)\n",
    "df_regular = pd.DataFrame(regular_summary)\n",
    "df_relative = pd.DataFrame(relative_summary)\n",
    "\n",
    "# Export LaTeX tables\n",
    "latex_obj = df_obj.to_latex(index=False, escape=False)\n",
    "latex_regular = df_regular.to_latex(index=False, escape=False)\n",
    "latex_relative = df_relative.to_latex(index=False, escape=False)\n",
    "\n",
    "# Print or write to file\n",
    "print(\"% Objective Table\")\n",
    "print(latex_obj)\n",
    "print(\"\\n% Regular Constraint Table\")\n",
    "print(latex_regular)\n",
    "print(\"\\n% Relative Constraint Table\")\n",
    "print(latex_relative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dual_evaluate() missing 1 required positional argument: 'test_indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m dual_net \u001b[38;5;241m=\u001b[39m DualNet(args, data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[1;32m     12\u001b[0m dual_net\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdual_weights.pth\u001b[39m\u001b[38;5;124m'\u001b[39m), weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m---> 14\u001b[0m obj_val, known_obj, opt_gap, ineq_max, ineq_mean, eq_max, eq_mean \u001b[38;5;241m=\u001b[39m \u001b[43mdual_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdual_net\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m dual_stats_dict[experiment][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobj\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(obj_val)\n\u001b[1;32m     16\u001b[0m dual_stats_dict[experiment][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mknown_obj\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(known_obj)\n",
      "\u001b[0;31mTypeError\u001b[0m: dual_evaluate() missing 1 required positional argument: 'test_indices'"
     ]
    }
   ],
   "source": [
    "# Get the quality of dual solutions:\n",
    "dual_stats_dict = {}\n",
    "for experiment in [\"simple\"]:\n",
    "    dual_stats_dict[experiment] = {\"obj\": [], \"known_obj\": [], \"opt_gap\": [], \"ineq_max\": [], \"ineq_mean\": [], \"eq_max\": [], \"eq_mean\": []}\n",
    "    for repeat in range(repeats):\n",
    "        directory = f\"experiment-output/ch4/ch4-reproduction/{experiment}/repeat:{repeat}\"\n",
    "        data_path = f\"data/QP_data/QP_type:{experiment}_var:100_ineq:50_eq:50_num_samples:10000.pkl\"\n",
    "\n",
    "        args = json.load(open('config.json'))\n",
    "        data = pickle.load(open(data_path, 'rb'))\n",
    "        dual_net = DualNet(args, data=data)\n",
    "        dual_net.load_state_dict(torch.load(os.path.join(directory, 'dual_weights.pth'), weights_only=True))\n",
    "\n",
    "        obj_val, known_obj, opt_gap, ineq_max, ineq_mean, eq_max, eq_mean = dual_evaluate(data, dual_net, data.test_indices)\n",
    "        dual_stats_dict[experiment][\"obj\"].append(obj_val)\n",
    "        dual_stats_dict[experiment][\"known_obj\"].append(known_obj)\n",
    "        dual_stats_dict[experiment][\"opt_gap\"].append(opt_gap)\n",
    "        dual_stats_dict[experiment][\"ineq_max\"].append(ineq_max)\n",
    "        dual_stats_dict[experiment][\"ineq_mean\"].append(ineq_mean)\n",
    "        dual_stats_dict[experiment][\"eq_max\"].append(eq_max)\n",
    "        dual_stats_dict[experiment][\"eq_mean\"].append(eq_mean)\n",
    "\n",
    "dual_stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "Optimal Obj & Predicted Obj & OptGap (\\%) & IneqMax & IneqMean & EqMax & EqMean \\\\\n",
      "\\midrule\n",
      "-15.037 & -7.778e+03(6.240e+03) & -5.175e+04(4.162e+04) & 0.023(0.006) & 0.003(0.001) & 0.000(0.000) & 0.000(0.000) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare final summary for LaTeX export\n",
    "summary = {\n",
    "    \"Optimal Obj\": [],\n",
    "    \"Predicted Obj\": [],\n",
    "    \"OptGap (\\%)\": [],\n",
    "    \"IneqMax\": [],\n",
    "    \"IneqMean\": [],\n",
    "    \"EqMax\": [],\n",
    "    \"EqMean\": [],\n",
    "}\n",
    "\n",
    "for experiment, metrics in dual_stats_dict.items():\n",
    "    summary[\"Optimal Obj\"].append(f\"{np.mean(metrics['known_obj']):.3f}\")\n",
    "    summary[\"Predicted Obj\"].append(f\"{np.mean(metrics['obj']):.3e}({np.std(metrics['obj']):.3e})\")\n",
    "    summary[\"OptGap (\\%)\"].append(f\"{np.mean(metrics['opt_gap']):.3e}({np.std(metrics['opt_gap']):.3e})\")\n",
    "    summary[\"IneqMax\"].append(\n",
    "        f\"{np.mean(metrics['ineq_max']):.3f}({np.std(metrics['ineq_max']):.3f})\"\n",
    "    )\n",
    "    summary[\"IneqMean\"].append(\n",
    "        f\"{np.mean(metrics['ineq_mean']):.3f}({np.std(metrics['ineq_mean']):.3f})\"\n",
    "    )\n",
    "    summary[\"EqMax\"].append(\n",
    "        f\"{np.mean(metrics['eq_max']):.3f}({np.std(metrics['eq_max']):.3f})\"\n",
    "    )\n",
    "    summary[\"EqMean\"].append(\n",
    "        f\"{np.mean(metrics['eq_mean']):.3f}({np.std(metrics['eq_mean']):.3f})\"\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(summary)\n",
    "\n",
    "# For LaTeX export\n",
    "latex_table = df.to_latex(index=False, escape=False)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Detailed evaluation metrics per repeat and problem type.}\n",
      "\\label{tab:detailed-results}\n",
      "\\begin{tabular}{llccccc}\n",
      "\\toprule\n",
      " &  & simple & column & row & random & obj \\\\\n",
      "Repeat & Metric &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{7}{*}{Repeat 0} & Predicted & -14.920 & -14.454 & -14.682 & -14.343 & -14.462 \\\\\n",
      " & Optimal & -15.037 & -15.358 & -15.570 & -15.602 & -15.630 \\\\\n",
      " & Gap (\\%) & 0.783 & 5.842 & 5.702 & 8.041 & 7.494 \\\\\n",
      " & Ineq. Max & 0.011 & 0.072 & 0.062 & 0.057 & 0.017 \\\\\n",
      " & Ineq. Mean & 0.001 & 0.003 & 0.003 & 0.002 & 0.001 \\\\\n",
      " & Eq. Max & 0.011 & 0.105 & 0.104 & 0.112 & 0.015 \\\\\n",
      " & Eq. Mean & 0.003 & 0.033 & 0.033 & 0.036 & 0.005 \\\\\n",
      "\\cline{1-7}\n",
      "\\multirow[t]{7}{*}{Repeat 1} & Predicted & -15.042 & -15.336 & -15.679 & -15.577 & -14.613 \\\\\n",
      " & Optimal & -15.037 & -15.358 & -15.570 & -15.602 & -15.630 \\\\\n",
      " & Gap (\\%) & -0.029 & 0.136 & -0.702 & 0.164 & 6.550 \\\\\n",
      " & Ineq. Max & 0.042 & 0.290 & 0.140 & 0.118 & 0.106 \\\\\n",
      " & Ineq. Mean & 0.004 & 0.016 & 0.008 & 0.006 & 0.005 \\\\\n",
      " & Eq. Max & 0.044 & 0.038 & 0.106 & 0.031 & 0.022 \\\\\n",
      " & Eq. Mean & 0.014 & 0.010 & 0.032 & 0.009 & 0.007 \\\\\n",
      "\\cline{1-7}\n",
      "\\multirow[t]{7}{*}{Repeat 2} & Predicted & -14.965 & -15.236 & -15.584 & -15.526 & -14.594 \\\\\n",
      " & Optimal & -15.037 & -15.358 & -15.570 & -15.602 & -15.630 \\\\\n",
      " & Gap (\\%) & 0.485 & 0.784 & -0.089 & 0.488 & 6.672 \\\\\n",
      " & Ineq. Max & 0.033 & 0.122 & 0.127 & 0.131 & 0.047 \\\\\n",
      " & Ineq. Mean & 0.001 & 0.005 & 0.006 & 0.007 & 0.002 \\\\\n",
      " & Eq. Max & 0.023 & 0.010 & 0.066 & 0.027 & 0.011 \\\\\n",
      " & Eq. Mean & 0.007 & 0.003 & 0.021 & 0.010 & 0.003 \\\\\n",
      "\\cline{1-7}\n",
      "\\multirow[t]{7}{*}{Repeat 3} & Predicted & -14.976 & -14.446 & -14.785 & -14.004 & -14.198 \\\\\n",
      " & Optimal & -15.037 & -15.358 & -15.570 & -15.602 & -15.630 \\\\\n",
      " & Gap (\\%) & 0.411 & 5.891 & 5.044 & 10.227 & 9.197 \\\\\n",
      " & Ineq. Max & 0.001 & 0.070 & 0.061 & 0.006 & 0.004 \\\\\n",
      " & Ineq. Mean & 0.000 & 0.003 & 0.003 & 0.000 & 0.000 \\\\\n",
      " & Eq. Max & 0.007 & 0.095 & 0.102 & 0.008 & 0.010 \\\\\n",
      " & Eq. Mean & 0.002 & 0.030 & 0.032 & 0.003 & 0.003 \\\\\n",
      "\\cline{1-7}\n",
      "\\multirow[t]{7}{*}{Repeat 4} & Predicted & -14.820 & -14.413 & -15.024 & -14.368 & -14.300 \\\\\n",
      " & Optimal & -15.037 & -15.358 & -15.570 & -15.602 & -15.630 \\\\\n",
      " & Gap (\\%) & 1.450 & 6.109 & 3.505 & 7.886 & 8.522 \\\\\n",
      " & Ineq. Max & 0.008 & 0.071 & 0.078 & 0.056 & 0.009 \\\\\n",
      " & Ineq. Mean & 0.000 & 0.004 & 0.004 & 0.002 & 0.000 \\\\\n",
      " & Eq. Max & 0.005 & 0.100 & 0.110 & 0.111 & 0.009 \\\\\n",
      " & Eq. Mean & 0.001 & 0.032 & 0.034 & 0.035 & 0.003 \\\\\n",
      "\\cline{1-7}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Mapping of original metric keys to display names\n",
    "metric_names = {\n",
    "    'predicted_obj': 'Predicted',\n",
    "    'known_obj': 'Optimal',\n",
    "    'opt_gap': 'Gap (\\\\%)',\n",
    "    'ineq_max': 'Ineq. Max',\n",
    "    'ineq_mean': 'Ineq. Mean',\n",
    "    'eq_max': 'Eq. Max',\n",
    "    'eq_mean': 'Eq. Mean'\n",
    "}\n",
    "\n",
    "metrics = list(metric_names.keys())\n",
    "problem_types = list(stats_dict.keys())\n",
    "repeats = range(len(stats_dict[problem_types[0]][metrics[0]]))\n",
    "\n",
    "# Prepare multi-indexed rows: (Repeat, Renamed Metric)\n",
    "rows = []\n",
    "for r in repeats:\n",
    "    for m in metrics:\n",
    "        rows.append((f\"Repeat {r}\", metric_names[m]))\n",
    "\n",
    "# Create DataFrame with multi-index rows and problem type columns\n",
    "df = pd.DataFrame(index=pd.MultiIndex.from_tuples(rows, names=[\"Repeat\", \"Metric\"]),\n",
    "                  columns=problem_types)\n",
    "\n",
    "# Fill in the values\n",
    "for problem in problem_types:\n",
    "    for r in repeats:\n",
    "        for m in metrics:\n",
    "            df.loc[(f\"Repeat {r}\", metric_names[m]), problem] = stats_dict[problem][m][r]\n",
    "\n",
    "# Convert to LaTeX with booktabs\n",
    "latex_table = df.to_latex(\n",
    "    escape=False,\n",
    "    multirow=True,\n",
    "    column_format='ll' + 'c' * len(problem_types),\n",
    "    bold_rows=False,\n",
    "    index_names=True,\n",
    "    header=True,\n",
    "    float_format=\"%.3f\",\n",
    "    caption=\"Detailed evaluation metrics per repeat and problem type.\",\n",
    "    label=\"tab:detailed-results\",\n",
    "    longtable=False,\n",
    "    na_rep=''\n",
    ")\n",
    "\n",
    "print(latex_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
