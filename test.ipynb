{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from gep_config_parser import *\n",
    "from data_wrangling import dataframe_to_dict\n",
    "import pyomo.environ as pyo\n",
    "\n",
    "from gep_main import run_model, prep_data\n",
    "from gep_problem import GEPProblem\n",
    "\n",
    "import torch\n",
    "\n",
    "DTYPE = torch.float64\n",
    "\n",
    "torch.set_default_dtype(DTYPE)\n",
    "\n",
    "# DEVICE = (\n",
    "#     torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "# )\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "CONFIG_FILE_NAME        = \"config.toml\"\n",
    "VISUALIZATION_FILE_NAME = \"visualization.toml\"\n",
    "\n",
    "HIGHS  = \"HiGHS\"\n",
    "GUROBI = \"Gurobi\"\n",
    "\n",
    "SAMPLE_DURATION = 12 # 12 hours\n",
    "\n",
    "## Step 0: Activate environment - ensure consistency accross computers\n",
    "# print(\"Reading the data\")\n",
    "# print(\"Activating the environment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing the config file\n",
      "Initializing the solver\n",
      "Using Gurobi\n",
      "Wrangling the input data\n",
      "Populating the model\n",
      "Adding model variables\n",
      "Formulating the objective\n",
      "Adding model constraints\n",
      "Solving the optimization problem\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter Method to value 2\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter LogFile to value \"outputs/Gurobi/output.txt\"\n",
      "Set parameter Crossover to value 0\n",
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (mac64[arm] - Darwin 22.3.0 22D49)\n",
      "\n",
      "CPU model: Apple M2 Pro\n",
      "Thread count: 10 physical cores, 10 logical processors, using up to 10 threads\n",
      "\n",
      "Non-default parameters:\n",
      "Method  2\n",
      "Crossover  0\n",
      "\n",
      "Optimize a model with 140 rows, 113 columns and 467 nonzeros\n",
      "Model fingerprint: 0x93c00021\n",
      "Coefficient statistics:\n",
      "  Matrix range     [7e-02, 2e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [2e+03, 3e+04]\n",
      "  RHS range        [4e+03, 3e+04]\n",
      "Presolve removed 126 rows and 104 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 14 rows, 9 columns, 42 nonzeros\n",
      "Ordering time: 0.00s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 6.900e+01\n",
      " Factor NZ  : 1.050e+02\n",
      " Factor Ops : 1.015e+03 (less than 1 second per iteration)\n",
      " Threads    : 1\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   8.13919896e+08  8.11280905e+08  1.03e+03 1.66e+02  1.92e+06     0s\n",
      "   1   8.16920646e+08  8.13794391e+08  2.99e+02 1.58e+02  4.40e+05     0s\n",
      "   2   8.20036143e+08  8.16051609e+08  1.24e-11 9.73e-14  1.73e+05     0s\n",
      "   3   8.18705590e+08  8.18338774e+08  3.30e-12 2.27e-13  1.59e+04     0s\n",
      "   4   8.18649113e+08  8.18647717e+08  2.27e-12 8.88e-16  6.07e+01     0s\n",
      "   5   8.18648033e+08  8.18648032e+08  2.05e-12 2.27e-13  6.07e-02     0s\n",
      "   6   8.18648032e+08  8.18648032e+08  6.42e-12 0.00e+00  6.07e-05     0s\n",
      "   7   8.18648032e+08  8.18648032e+08  9.09e-13 1.14e-13  6.07e-08     0s\n",
      "   8   8.18648032e+08  8.18648032e+08  4.43e-13 9.09e-13  6.07e-11     0s\n",
      "\n",
      "Barrier solved model in 8 iterations and 0.01 seconds (0.00 work units)\n",
      "Optimal objective 8.18648032e+08\n",
      "\n",
      "Objective Value: 818648032.282804\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Step 1: parse the input data\n",
    "print(\"Parsing the config file\")\n",
    "\n",
    "data = parse_config(CONFIG_FILE_NAME)\n",
    "experiment = data[\"experiment\"]\n",
    "outputs_config = data[\"outputs_config\"]\n",
    "\n",
    "print(\"Initializing the solver\")\n",
    "optimizer_name = data[\"optimizer_config\"][\"solver\"]\n",
    "\n",
    "# Determine the optimizer\n",
    "if optimizer_name == HIGHS:\n",
    "    raise NotImplementedError(f\"{optimizer_name}: Not implemented\")\n",
    "elif optimizer_name == GUROBI:\n",
    "    \n",
    "    print(f\"Using {GUROBI}\")\n",
    "    optimizer = \"gurobi_direct\"\n",
    "else:\n",
    "    raise ValueError(f\"{optimizer_name}: Not implemented\")\n",
    "\n",
    "for i, experiment_instance in enumerate(experiment[\"experiments\"]):\n",
    "    # Setup output dataframe\n",
    "    df_res = pd.DataFrame(columns=[\"setup_time\", \"presolve_time\", \"barrier_time\", \"crossover_time\", \"restore_time\", \"objective_value\"])\n",
    "\n",
    "    T, N, G, L, pDemand, pGenAva, pVOLL, pWeight, pRamping, pInvCost, pVarCost, pUnitCap, pExpCap, pImpCap = prep_data(experiment_instance)\n",
    "\n",
    "    T_ranges = [range(i, i + SAMPLE_DURATION, 1) for i in range(1, len(T), SAMPLE_DURATION)]\n",
    "    objective_values = []\n",
    "    times = []\n",
    "    for t in T_ranges[:1]:\n",
    "        # Run one experiment for j repeats\n",
    "        GUROBI_MODEL, solver, time_taken = run_model(experiment_instance, t, N, G, L, pDemand, pGenAva, pVOLL, pWeight, pRamping, pInvCost, pVarCost, pUnitCap, pExpCap, pImpCap)\n",
    "        \n",
    "        # print(\"Print values for all variables\")\n",
    "        # for v in model.component_data_objects(pyo.Var):\n",
    "        #     print(str(v), v.value)\n",
    "\n",
    "        objective_values.append(GUROBI_MODEL.obj())\n",
    "        times.append(time_taken)\n",
    "\n",
    "    # Write the number to the file\n",
    "    # file_path = os.path.join(\"outputs/Gurobi\", f\"samplesize_{str(SAMPLE_DURATION)}_node_{len(N)}_gen_{len(G)}_lines_{len(L)}.txt\")\n",
    "    # with open(file_path, \"w\") as file:\n",
    "    #     file.write(f\"N: {str(N)}\\n\")\n",
    "    #     file.write(f\"G: {str(G)}\\n\")\n",
    "    #     file.write(f\"L: {str(L)}\\n\")\n",
    "    #     file.write(f\"Obj value mean: {str(np.mean(objective_values))}\\n\")\n",
    "    #     file.write(f\"Time taken mean: {str(np.mean(times))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n",
      "Parsing the config file\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "from gep_config_parser import *\n",
    "from data_wrangling import dataframe_to_dict\n",
    "\n",
    "from primal_dual import PrimalDualTrainer\n",
    "from gep_problem import GEPProblem\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "CONFIG_FILE_NAME        = \"config.toml\"\n",
    "VISUALIZATION_FILE_NAME = \"visualization.toml\"\n",
    "\n",
    "## Step 1: parse the input data\n",
    "print(\"Parsing the config file\")\n",
    "\n",
    "data = parse_config(CONFIG_FILE_NAME)\n",
    "experiment = data[\"experiment\"]\n",
    "outputs_config = data[\"outputs_config\"]\n",
    "\n",
    "def run_model(inputs, args):\n",
    "    \n",
    "    if outputs_config[\"terminal\"][\"input_plots\"]:\n",
    "        pass\n",
    "\n",
    "    print(\"Wrangling the input data\")\n",
    "\n",
    "    # Extract sets\n",
    "    T = inputs[\"times\"] # [1, 2, 3, ... 8760] ---> 8760\n",
    "    G = inputs[\"generators\"] # [('Country1', 'EnergySource1'), ...] ---> 107\n",
    "    L = inputs[\"transmission_lines\"] # [('Country1', 'Country2'), ...] ---> 44\n",
    "    N = inputs[\"nodes\"] # ['Country1', 'Country2', ...] ---> 20\n",
    "\n",
    "    ### SET UP CUSTOM CONFIG ###\n",
    "    # N = ['BEL', 'FRA', 'GER', 'NED'] # 4 nodes\n",
    "    N = ['BEL', 'GER', 'NED'] # 3 nodes\n",
    "    # G = [('BEL', 'SunPV'), ('FRA', 'SunPV'), ('GER', 'SunPV'), ('NED', 'SunPV')] # 4 generators\n",
    "    G = [('BEL', 'SunPV'), ('GER', 'SunPV'), ('NED', 'SunPV')] # 3 generators\n",
    "    # L = [('BEL', 'FRA'), ('BEL', 'GER'), ('BEL', 'NED'), ('GER', 'FRA'), ('GER', 'NED')] # 5 lines\n",
    "    L = [('BEL', 'GER'), ('BEL', 'NED'), ('GER', 'NED')] # 3 lines\n",
    "\n",
    "    # Extract time series data\n",
    "    pDemand = dataframe_to_dict(\n",
    "        inputs[\"demand_data\"],\n",
    "        keys=[\"Country\", \"Time\"],\n",
    "        value=\"Demand_MW\"\n",
    "    )\n",
    "    pGenAva = dataframe_to_dict(\n",
    "        inputs[\"generation_availability_data\"],\n",
    "        keys=[\"Country\", \"Technology\", \"Time\"],\n",
    "        value=\"Availability_pu\"\n",
    "    )\n",
    "\n",
    "    # Extract scalar parameters\n",
    "    pVOLL = inputs[\"value_of_lost_load\"]\n",
    "\n",
    "    # WOP\n",
    "    # Scale inversely proportional to times (T)\n",
    "    pWeight = inputs[\"representative_period_weight\"]\n",
    "\n",
    "    pRamping = inputs[\"ramping_value\"]\n",
    "\n",
    "    # Extract generator parameters\n",
    "    pInvCost = dataframe_to_dict(\n",
    "        inputs[\"generation_data\"],\n",
    "        keys=[\"Country\", \"Technology\"],\n",
    "        value=\"InvCost_kEUR_MW_year\"\n",
    "    )\n",
    "    pVarCost = dataframe_to_dict(\n",
    "        inputs[\"generation_data\"],\n",
    "        keys=[\"Country\", \"Technology\"],\n",
    "        value=\"VarCost_kEUR_per_MWh\"\n",
    "    )\n",
    "    pUnitCap = dataframe_to_dict(\n",
    "        inputs[\"generation_data\"],\n",
    "        keys=[\"Country\", \"Technology\"],\n",
    "        value=\"UnitCap_MW\"\n",
    "    )\n",
    "\n",
    "    # Extract line parameters\n",
    "    pExpCap = dataframe_to_dict(\n",
    "        inputs[\"transmission_lines_data\"],\n",
    "        keys=[\"CountryA\", \"CountryB\"],\n",
    "        value=\"ExpCap_MW\"\n",
    "    )\n",
    "    pImpCap = dataframe_to_dict(\n",
    "        inputs[\"transmission_lines_data\"],\n",
    "        keys=[\"CountryA\", \"CountryB\"],\n",
    "        value=\"ImpCap_MW\"\n",
    "    )\n",
    "\n",
    "    # We need to sort the dictionaries for changing to tensors!\n",
    "    pDemand = dict(sorted(pDemand.items()))\n",
    "    pGenAva = dict(sorted(pGenAva.items()))\n",
    "    pInvCost = dict(sorted(pInvCost.items()))\n",
    "    pVarCost = dict(sorted(pVarCost.items()))\n",
    "    pUnitCap = dict(sorted(pUnitCap.items()))\n",
    "    pExpCap = dict(sorted(pExpCap.items()))\n",
    "    pImpCap = dict(sorted(pImpCap.items()))\n",
    "\n",
    "\n",
    "    print(\"Creating problem instance\")\n",
    "    problem = GEPProblem(T, G, L, N, pDemand, pGenAva, pVOLL, pWeight, pRamping, pInvCost, pVarCost, pUnitCap, pExpCap, pImpCap, sample_duration=12)\n",
    "    run_name = \"2024-12-09\"\n",
    "    save_dir = os.path.join('outputs', 'PDL',\n",
    "        run_name + \"-\" + str(time.time()).replace('.', '-'))\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    with open(os.path.join(save_dir, 'args.dict'), 'wb') as f:\n",
    "        pickle.dump(args, f)\n",
    "\n",
    "    # Run PDL\n",
    "    print(\"Training the PDL\")\n",
    "    trainer = PrimalDualTrainer(problem, args, save_dir)\n",
    "    primal_net, dual_net, stats = trainer.train_PDL()\n",
    "\n",
    "    return problem, primal_net, dual_net, stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrangling the input data\n",
      "Creating problem instance\n",
      "Size of train set: 584\n",
      "Size of val set: 73\n",
      "Size of mu: 285\n",
      "Size of lambda: 36\n",
      "Number of variables (size of y): 111\n",
      "Number of inputs (size of X): 72\n",
      "Training the PDL\n",
      "Epoch 0 done. Time taken: 5.493730068206787. Rho: 10000000. Primal LR: 8.600583546412887e-05, Dual LR: 8.016305895390461e-05\n",
      "0: p-loss: 7.6231E+17, obj. val 5.8698E+07, Max eq.: 2.4370E+04, Max ineq.: 1.0455E+05, Mean eq.: 9.8552E+03, Mean ineq.: 7.2903E+03\n",
      "\n",
      "Epoch 1 done. Time taken: 5.368190765380859. Rho: 10000000. Primal LR: 6.825545950103872e-05, Dual LR: 6.361854860638712e-05\n",
      "1: p-loss: 8.8263E+17, obj. val 5.1035E+07, Max eq.: 2.4386E+04, Max ineq.: 1.1304E+05, Mean eq.: 9.8015E+03, Mean ineq.: 7.8341E+03\n",
      "\n",
      "Epoch 2 done. Time taken: 5.08319878578186. Rho: 10000000000.0. Primal LR: 5.639051904523878e-05, Dual LR: 5.099857462495656e-05\n",
      "2: p-loss: 5.0342E+19, obj. val 6.8185E+07, Max eq.: 2.4758E+04, Max ineq.: 3.0893E+04, Mean eq.: 9.8580E+03, Mean ineq.: 1.3113E+03\n",
      "\n",
      "Epoch 3 done. Time taken: 5.182523965835571. Rho: 10000000000.0. Primal LR: 4.475232137638109e-05, Dual LR: 4.04731972678324e-05\n",
      "3: p-loss: 5.0343E+19, obj. val 6.5996E+07, Max eq.: 2.4758E+04, Max ineq.: 3.0893E+04, Mean eq.: 9.8580E+03, Mean ineq.: 1.3114E+03\n",
      "\n",
      "Epoch 4 done. Time taken: 5.873741149902344. Rho: 10000000000000.0. Primal LR: 3.62372017860497e-05, Dual LR: 3.244455298634257e-05\n",
      "4: p-loss: 4.9916E+22, obj. val 6.3531E+07, Max eq.: 2.4596E+04, Max ineq.: 3.0646E+04, Mean eq.: 9.8528E+03, Mean ineq.: 1.3020E+03\n",
      "\n",
      "Epoch 5 done. Time taken: 5.473961114883423. Rho: 1e+16. Primal LR: 2.8758360936686414e-05, Dual LR: 2.6008546137772605e-05\n",
      "5: p-loss: 4.9736E+25, obj. val 6.1327E+07, Max eq.: 2.4533E+04, Max ineq.: 3.0606E+04, Mean eq.: 9.8370E+03, Mean ineq.: 1.2976E+03\n",
      "\n",
      "Epoch 6 done. Time taken: 5.403163909912109. Rho: 1e+19. Primal LR: 2.30535818318526e-05, Dual LR: 2.0849246173476125e-05\n",
      "6: p-loss: 4.9373E+28, obj. val 6.0090E+07, Max eq.: 2.4452E+04, Max ineq.: 3.0434E+04, Mean eq.: 9.8217E+03, Mean ineq.: 1.2905E+03\n",
      "\n",
      "Epoch 7 done. Time taken: 5.487330198287964. Rho: 1.8446744073709552e+19. Primal LR: 1.8295651830906085e-05, Dual LR: 1.6546259566473476e-05\n",
      "7: p-loss: 9.1078E+28, obj. val 5.9268E+07, Max eq.: 2.4452E+04, Max ineq.: 3.0434E+04, Mean eq.: 9.8217E+03, Mean ineq.: 1.2906E+03\n",
      "\n",
      "Epoch 8 done. Time taken: 4.960114002227783. Rho: 1.8446744073709552e+19. Primal LR: 1.4519690621578262e-05, Dual LR: 1.3131347932828827e-05\n",
      "8: p-loss: 9.1079E+28, obj. val 5.8616E+07, Max eq.: 2.4452E+04, Max ineq.: 3.0434E+04, Mean eq.: 9.8217E+03, Mean ineq.: 1.2906E+03\n",
      "\n",
      "Epoch 9 done. Time taken: 5.251954078674316. Rho: 1.8446744073709552e+19. Primal LR: 1.1523033871371338e-05, Dual LR: 1.0526490184835907e-05\n",
      "9: p-loss: 9.1079E+28, obj. val 5.8099E+07, Max eq.: 2.4452E+04, Max ineq.: 3.0434E+04, Mean eq.: 9.8217E+03, Mean ineq.: 1.2907E+03\n",
      "\n",
      "Epoch 10 done. Time taken: 5.610537052154541. Rho: 1.8446744073709552e+19. Primal LR: 9.237216435585796e-06, Dual LR: 8.353972967320516e-06\n",
      "10: p-loss: 9.1080E+28, obj. val 5.7688E+07, Max eq.: 2.4452E+04, Max ineq.: 3.0434E+04, Mean eq.: 9.8217E+03, Mean ineq.: 1.2907E+03\n",
      "\n",
      "Epoch 11 done. Time taken: 5.276869297027588. Rho: 1.8446744073709552e+19. Primal LR: 7.330786904388821e-06, Dual LR: 6.629832272038531e-06\n",
      "11: p-loss: 9.1081E+28, obj. val 5.7361E+07, Max eq.: 2.4452E+04, Max ineq.: 3.0434E+04, Mean eq.: 9.8217E+03, Mean ineq.: 1.2907E+03\n",
      "\n",
      "Epoch 12 done. Time taken: 5.470863103866577. Rho: 1.8446744073709552e+19. Primal LR: 5.817817197670823e-06, Dual LR: 5.261529589251446e-06\n",
      "12: p-loss: 9.1081E+28, obj. val 5.7102E+07, Max eq.: 2.4452E+04, Max ineq.: 3.0434E+04, Mean eq.: 9.8217E+03, Mean ineq.: 1.2907E+03\n",
      "\n",
      "Epoch 13 done. Time taken: 5.550382852554321. Rho: 1.8446744073709552e+19. Primal LR: 4.617102827699269e-06, Dual LR: 4.217803066508772e-06\n",
      "13: p-loss: 9.1082E+28, obj. val 5.6895E+07, Max eq.: 2.4452E+04, Max ineq.: 3.0434E+04, Mean eq.: 9.8217E+03, Mean ineq.: 1.2907E+03\n",
      "\n",
      "Epoch 14 done. Time taken: 5.7554333209991455. Rho: 1.8446744073709552e+19. Primal LR: 3.7012108617309608e-06, Dual LR: 3.347308759177371e-06\n",
      "14: p-loss: 9.1082E+28, obj. val 5.6731E+07, Max eq.: 2.4452E+04, Max ineq.: 3.0434E+04, Mean eq.: 9.8217E+03, Mean ineq.: 1.2907E+03\n",
      "\n",
      "Epoch 15 done. Time taken: 5.695741891860962. Rho: 1.8446744073709552e+19. Primal LR: 2.9373338066467324e-06, Dual LR: 2.656472043048682e-06\n",
      "15: p-loss: 9.1082E+28, obj. val 5.6600E+07, Max eq.: 2.4452E+04, Max ineq.: 3.0434E+04, Mean eq.: 9.8217E+03, Mean ineq.: 1.2908E+03\n",
      "\n",
      "Epoch 16 done. Time taken: 5.431634902954102. Rho: 1.8446744073709552e+19. Primal LR: 2.331110064784238e-06, Dual LR: 2.1295092499631083e-06\n",
      "16: p-loss: 9.1082E+28, obj. val 5.6496E+07, Max eq.: 2.4452E+04, Max ineq.: 3.0434E+04, Mean eq.: 9.8217E+03, Mean ineq.: 1.2908E+03\n",
      "\n",
      "Epoch 17 done. Time taken: 5.387279033660889. Rho: 1.8446744073709552e+19. Primal LR: 1.868689135513392e-06, Dual LR: 1.6900089579220103e-06\n",
      "17: p-loss: 9.1082E+28, obj. val 5.6414E+07, Max eq.: 2.4452E+04, Max ineq.: 3.0434E+04, Mean eq.: 9.8217E+03, Mean ineq.: 1.2908E+03\n",
      "\n",
      "Epoch 18 done. Time taken: 5.567137956619263. Rho: 1.8446744073709552e+19. Primal LR: 1.483018389633142e-06, Dual LR: 1.3412152484926365e-06\n",
      "18: p-loss: 9.1083E+28, obj. val 5.6348E+07, Max eq.: 2.4452E+04, Max ineq.: 3.0434E+04, Mean eq.: 9.8217E+03, Mean ineq.: 1.2908E+03\n",
      "\n",
      "Epoch 19 done. Time taken: 5.5612640380859375. Rho: 1.8446744073709552e+19. Primal LR: 1.1769445769190733e-06, Dual LR: 1.0644075786444312e-06\n",
      "19: p-loss: 9.1083E+28, obj. val 5.6296E+07, Max eq.: 2.4452E+04, Max ineq.: 3.0434E+04, Mean eq.: 9.8217E+03, Mean ineq.: 1.2908E+03\n",
      "\n",
      "Final Obj Value: tensor([50147034.3482], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "        # \"K\": 2,\n",
    "        \"K\": 20,\n",
    "        # \"L\": 10,\n",
    "        \"L\": 250,\n",
    "        \"tau\": 0.1,\n",
    "        \"rho\": 10000000,\n",
    "        # \"rho\": 1e-5,\n",
    "        \"rho_max\": sys.maxsize * 2 + 1,\n",
    "        \"alpha\": 1000,\n",
    "        # \"alpha\": 2,\n",
    "        # \"batch_size\": 584, # Full training set!\n",
    "        \"batch_size\": 10000,\n",
    "        \"hidden_size\": 500,\n",
    "        # \"hidden_size\": 1000,\n",
    "        \"primal_lr\": 1e-4,\n",
    "        \"dual_lr\": 1e-4,\n",
    "        # \"primal_lr\": 1e-5,\n",
    "        # \"dual_lr\": 1e-5,\n",
    "        # \"decay\": 0.99,\n",
    "        \"decay\": 0.99,\n",
    "        \"patience\": 10,\n",
    "        \"corrEps\": 1e-4,\n",
    "}\n",
    "\n",
    "# Train the model:\n",
    "for i, experiment_instance in enumerate(experiment[\"experiments\"]):\n",
    "    # Setup output dataframe\n",
    "    df_res = pd.DataFrame(columns=[\"setup_time\", \"presolve_time\", \"barrier_time\", \"crossover_time\", \"restore_time\", \"objective_value\"])\n",
    "\n",
    "    for j in range(experiment[\"repeats\"]):\n",
    "        # Run one experiment for j repeats\n",
    "        problem, primal_net, dual_net, stats = run_model(experiment_instance, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variable_values_as_list(var):\n",
    "    # Check if the variable is indexed\n",
    "    if var.is_indexed():\n",
    "        return [var[idx].value for idx in var]\n",
    "    else:\n",
    "        # For scalar variables\n",
    "        return [var.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set: 584\n",
      "Size of val set: 73\n",
      "Size of mu: 285\n",
      "Size of lambda: 36\n",
      "Number of variables (size of y): 111\n",
      "Number of inputs (size of X): 72\n",
      "Size of train set: 584\n",
      "Size of val set: 73\n",
      "Size of mu: 285\n",
      "Size of lambda: 36\n",
      "Number of variables (size of y): 111\n",
      "Number of inputs (size of X): 72\n",
      "torch.Size([1, 111])\n",
      "818648032.282804\n",
      "818648032.282804\n",
      "1013178902.5024923\n",
      "818648032.282804\n",
      "1013178902.5024923\n"
     ]
    }
   ],
   "source": [
    "# Y_tensor_path = \"outputs/Gurobi/Y_FIRST_SAMPLE_samplesize_12_node_3_gen_3_lines_3\"\n",
    "# Y_Gurobi = torch.load(Y_tensor_path)\n",
    "# Y_Gurobi = model\n",
    "data = GEPProblem(T, G, L, N, pDemand, pGenAva, pVOLL, pWeight, pRamping, pInvCost, pVarCost, pUnitCap, pExpCap, pImpCap, sample_duration=12)\n",
    "problem = GEPProblem(T, G, L, N, pDemand, pGenAva, pVOLL, pWeight, pRamping, pInvCost, pVarCost, pUnitCap, pExpCap, pImpCap, sample_duration=12)\n",
    "Y_Gurobi = torch.tensor([[*get_variable_values_as_list(GUROBI_MODEL.vGenProd), \\\n",
    "*get_variable_values_as_list(GUROBI_MODEL.vLineFlow),\n",
    "*get_variable_values_as_list(GUROBI_MODEL.vLossLoad),\n",
    "*get_variable_values_as_list(GUROBI_MODEL.vGenInv)]], device=DEVICE)\n",
    "# print(Y_Gurobi.shape)\n",
    "\n",
    "X = problem.trainX[:1]\n",
    "Y_out = primal_net(X).detach()\n",
    "print(Y_out.shape)\n",
    "\n",
    "# print(Y_Gurobi)\n",
    "# print(Y_out)\n",
    "\n",
    "# print(Y_Gurobi - Y_out)\n",
    "print(GUROBI_MODEL.obj())\n",
    "print(problem.obj_fn(Y_Gurobi).item())\n",
    "print(problem.obj_fn(Y_out).item())\n",
    "print(data.obj_fn(Y_Gurobi).item())\n",
    "print(data.obj_fn(Y_out).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
